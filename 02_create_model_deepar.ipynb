{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. サマリーしたデータを読み込んで可視化する\n",
    "前のステップで処理したデータはS3バケットに格納されているので、Notebook内に読み込んで可視化するところから始めます  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'tuki-bkt-misc'\n",
    "prefix = 'data/nyctaxi/daily_w_location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190101.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190102.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190103.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190104.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190105.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190106.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190107.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190108.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190109.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190110.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190111.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190112.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190113.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190114.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190115.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190116.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190117.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190118.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190119.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190120.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190121.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190122.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190123.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190124.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190125.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190126.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190127.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190128.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190129.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190130.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190131.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190201.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190202.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190203.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190204.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190205.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190206.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190207.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190208.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190209.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190210.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190211.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190212.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190213.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190214.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190215.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190216.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190217.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190218.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190219.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190220.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190221.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190222.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190223.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190224.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190225.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190226.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190227.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190228.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190301.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190302.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190303.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190304.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190305.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190306.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190307.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190308.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190309.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190310.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190311.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190312.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190313.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190314.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190315.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190316.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190317.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190318.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190319.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190320.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190321.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190322.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190323.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190324.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190325.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190326.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190327.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190328.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190329.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190330.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190331.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190401.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190402.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190403.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190404.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190405.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190406.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190407.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190408.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190409.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190410.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190411.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190412.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190413.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190414.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190415.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190416.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190417.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190418.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190419.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190420.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190421.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190422.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190423.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190424.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190425.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190426.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190427.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190428.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190429.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190430.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190501.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190502.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190503.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190504.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190505.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190506.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190507.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190508.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190509.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190510.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190511.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190512.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190513.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190514.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190515.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190516.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190517.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190518.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190519.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190520.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190521.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190522.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190523.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190524.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190525.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190526.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190527.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190528.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190529.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190530.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190531.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190601.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190602.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190603.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190604.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190605.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190606.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190607.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190608.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190609.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190610.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190611.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190612.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190613.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190614.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190615.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190616.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190617.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190618.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190619.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190620.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190621.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190622.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190623.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190624.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190625.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190626.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190627.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190628.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190629.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190630.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190701.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190702.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190703.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190704.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190705.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190706.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190707.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190708.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190709.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190710.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190711.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190712.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190713.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190714.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190715.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190716.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190717.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190718.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190719.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190720.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190721.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190722.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190723.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190724.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190725.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190726.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190727.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190728.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190729.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190730.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190731.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190801.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190802.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190803.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190804.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190805.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190806.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190807.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190808.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190809.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190810.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190811.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190812.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190813.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190814.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190815.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190816.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190817.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190818.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190819.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190820.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190821.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190822.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190823.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190824.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190825.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190826.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190827.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190828.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190829.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190830.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190831.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190901.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190902.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190903.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190904.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190905.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190906.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190907.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190908.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190909.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190910.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190911.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190912.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190913.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190914.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190915.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190916.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190917.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190918.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190919.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190920.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190921.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190922.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190923.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190924.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190925.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190926.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190927.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190928.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190929.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20190930.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191001.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191002.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191003.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191004.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191005.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191006.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191007.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191008.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191009.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191010.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191011.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191012.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191013.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191014.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191015.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191016.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191017.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191018.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191019.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191020.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191021.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191022.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191023.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191024.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191025.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191026.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191027.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191028.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191029.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191030.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191031.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191101.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191102.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191103.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191104.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191105.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191106.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191107.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191108.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191109.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191110.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191111.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191112.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191113.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191114.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191115.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191116.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191117.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191118.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191119.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191120.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191121.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191122.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191123.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191124.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191125.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191126.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191127.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191128.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191129.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191130.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191201.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191202.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191203.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191204.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191205.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191206.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191207.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191208.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191209.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191210.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191211.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191212.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191213.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191214.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191215.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191216.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191217.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191218.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191219.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191220.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191221.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191222.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191223.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191224.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191225.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191226.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191227.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191228.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191229.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191230.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20191231.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200101.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200102.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200103.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200104.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200105.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200106.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200107.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200108.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200109.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200110.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200111.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200112.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200113.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200114.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200115.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200116.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200117.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200118.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200119.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200120.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200121.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200122.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200123.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200124.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200125.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200126.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200127.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200128.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200129.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200130.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200131.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200201.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200202.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200203.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200204.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200205.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200206.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200207.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200208.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200209.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200210.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200211.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200212.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200213.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200214.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200215.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200216.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200217.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200218.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200219.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200220.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200221.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200222.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200223.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200224.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200225.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200226.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200227.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200228.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200229.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200301.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200302.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200303.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200304.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200305.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200306.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200307.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200308.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200309.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200310.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200311.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200312.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200313.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200314.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200315.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200316.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200317.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200318.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200319.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200320.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200321.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200322.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200323.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200324.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200325.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200326.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200327.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200328.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200329.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200330.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200331.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200401.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200402.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200403.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200404.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200405.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200406.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200407.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200408.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200409.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200410.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200411.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200412.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200413.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200414.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200415.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200416.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200417.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200418.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200419.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200420.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200421.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200422.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200423.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200424.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200425.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200426.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200427.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200428.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200429.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200430.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200501.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200502.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200503.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200504.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200505.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200506.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200507.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200508.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200509.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200510.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200511.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200512.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200513.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200514.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200515.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200516.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200517.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200518.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200519.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200520.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200521.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200522.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200523.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200524.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200525.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200526.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200527.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200528.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200529.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200530.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200531.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200601.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200602.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200603.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200604.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200605.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200606.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200607.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200608.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200609.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200610.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200611.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200612.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200613.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200614.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200615.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200616.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200617.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200618.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200619.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200620.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200621.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200622.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200623.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200624.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200625.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200626.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200627.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200628.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200629.csv',\n",
       " 'data/nyctaxi/daily_w_location/nyctaxi_tripdata_green_20200630.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "response = s3.list_objects(Bucket=bucket, Prefix=prefix)\n",
    "nyctaxi_summary_files = sorted([x['Key'] for x in response['Contents']])\n",
    "nyctaxi_summary_files = [x for x in nyctaxi_summary_files if ('green' in x) and ('2019' in x or '2020' in x)]\n",
    "nyctaxi_summary_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blog執筆時点では、2019年1月1日から約1年半分のデータが取得できています。読み込み処理には数分かかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame()\n",
    "for file in nyctaxi_summary_files:\n",
    "    df_read = wr.s3.read_csv(f's3://{bucket}/{file}')\n",
    "    df_data = pd.concat([df_data, df_read])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 1157445\n"
     ]
    }
   ],
   "source": [
    "print('Number of records:', df_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、読み込んだデータをプロットします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f76b139c978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_data.groupby(by='pickup_ymdh')['count'].sum().plot(figsize=(16,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2019年1月から漸減傾向ながらもピーク時に1000を超える程度の数値で推移していた「1時間あたりのgreenタクシーピックアップ数」が、2020年の4月前後から顕著に少なくなっていることが読み取れます。COVID-19の影響でNew Yorkにおいてもロックダウンが実施されたため、それによる外出の減少がタクシーの需要にも大きな影響を及ぼしたことがわかります。COVID-19の影響によるデータドリフトが、タクシー需要に現れているとも言えます。  \n",
    "ここからは、タクシー需要を予測するモデルを運用していたときに、Model Monitorによってデータ傾向を監視していたとしたらどのような指標の変化が現れるのか、どのようにして変化を検出できるのか、を見ていきましょう。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. タクシー需要の予測モデルを構築する\n",
    "まず簡易な予測モデルを作成して、タクシー需要を予測します。ここではXGBoostを使用して、自己回帰に近いモデルを作成しています。  \n",
    "ここまでのステップで2019年1月からのデータを取得しているので、「2019年1月から12月までのデータを用いてモデルを構築し、2020年1月からモデルの運用を開始した」とします。\n",
    "つまり、モデルの運用から約3ヶ月間は平常状態で、4ヶ月後にデータドリフトに直面することになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_ymdh</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 02:00:00</td>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 03:00:00</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 04:00:00</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13120</th>\n",
       "      <td>2020-06-30 19:00:00</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13121</th>\n",
       "      <td>2020-06-30 20:00:00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13122</th>\n",
       "      <td>2020-06-30 21:00:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13123</th>\n",
       "      <td>2020-06-30 22:00:00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13124</th>\n",
       "      <td>2020-06-30 23:00:00</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13125 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               pickup_ymdh  count\n",
       "0      2019-01-01 00:00:00   1175\n",
       "1      2019-01-01 01:00:00   1214\n",
       "2      2019-01-01 02:00:00   1074\n",
       "3      2019-01-01 03:00:00    896\n",
       "4      2019-01-01 04:00:00    728\n",
       "...                    ...    ...\n",
       "13120  2020-06-30 19:00:00     81\n",
       "13121  2020-06-30 20:00:00     41\n",
       "13122  2020-06-30 21:00:00     24\n",
       "13123  2020-06-30 22:00:00     25\n",
       "13124  2020-06-30 23:00:00     21\n",
       "\n",
       "[13125 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.groupby(by=['pickup_ymdh'])['count'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# DeepARを利用するために必要な環境変数を設定\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# データ入出力に利用するS3 bucketとパスを設定\n",
    "model_prefix = 'model/nyctaxi-deepar'\n",
    "s3_data_path = \"s3://{}/{}/data\".format(bucket, model_prefix)\n",
    "s3_output_path = \"s3://{}/{}/output\".format(bucket, model_prefix)\n",
    "\n",
    "# SageMakerのDeepARコンテナを指定\n",
    "region = sagemaker_session.boto_region_name\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用する時系列データの周期を宣言する\n",
    "freq = '1H'\n",
    "\n",
    "# 4時間後までの予測を行う\n",
    "prediction_length = 4\n",
    "\n",
    "# we also use 7 days as context length, this is the number of state updates accomplished before making predictions\n",
    "context_length = 2 * 24\n",
    "\n",
    "# 学習に利用するデータの範囲を指定する\n",
    "train_start = pd.Timestamp(\"2019-01-01 00:00:00\", freq=freq)\n",
    "validation_start = pd.Timestamp(\"2019-09-01 00:00:00\", freq=freq)\n",
    "test_start = pd.Timestamp(\"2019-11-01 00:00:00\", freq=freq)\n",
    "test_end = pd.Timestamp(\"2020-01-01 00:00:00\", freq=freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの構築に利用できるのは2019年中のデータなので、2019年1月から8月までのデータをトレーニング、9月と10月のデータをバリデーション, 11月と12月のデータをテスト用に使用します。  \n",
    "Amazon SageMakerが提供するDeepARアルゴリズムはS3からデータを取得して動作するので、分離したデータをS3に保管します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepARの必要フォーマットにあわせてDataFrameからDictに整形する処理\n",
    "# 特徴量抽出も併せて実行している\n",
    "def convert_to_DeepAR_dict(df, label_col, start_dataset):\n",
    "    # 予測対象をリスト化してtargetとしてセット\n",
    "    # JSON形式で学習データを与えるので、欠損値は\"NaN\"文字列に変換する\n",
    "    # 詳細はURLを参照：https://docs.aws.amazon.com/ja_jp/sagemaker/latest/dg/deepar.html#deepar-inputoutput\n",
    "    ts_target = df[label_col].fillna('NaN').tolist()\n",
    "    \n",
    "    # 必要に応じて追加特徴量をdynamic_feat Listにセット\n",
    "    dynamic_feat = []\n",
    "        \n",
    "    # 必要に応じてセルごとの特徴を表すカテゴリ変数を設定する\n",
    "    \n",
    "    # カテゴリ変数をリストにマージ\n",
    "\n",
    "    # DeepARの要求フォーマットに合わせてDictに整形\n",
    "    return {'start': str(start_dataset), 'target': ts_target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data     : 5832  ,Last timestamp: ['2019-08-31T23:00:00.000000000']\n"
     ]
    }
   ],
   "source": [
    "# Pickup locationごとにレコードがあるdf_dataを、日時（YYYYMMDD HH）ごとに1レコードに集約して学習データとして利用する\n",
    "df_summary = df_data.groupby(by=['pickup_ymdh'])['count'].sum().reset_index()\n",
    "df_summary['pickup_ymdh'] = pd.to_datetime(df_summary['pickup_ymdh'])\n",
    "df_summary = df_summary.set_index('pickup_ymdh')\n",
    "\n",
    "# トレーニングデータ期間の開始からバリデーションデータ期間の直前までをトレーニングデータとして切り出す\n",
    "df_train = df_summary[train_start:validation_start - datetime.timedelta(hours=1)]\n",
    "print('Train Data     :', df_train.shape[0], ' ,Last timestamp:', df_train.tail(1).index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training time series: 1\n",
      "length of training time series 0: 5832\n"
     ]
    }
   ],
   "source": [
    "# 学習データをDeepARが必要とする辞書形式に変換する\n",
    "training_data = []\n",
    "training_data.append(convert_to_DeepAR_dict(df_train, 'count', start_dataset))\n",
    "    \n",
    "print('Number of training time series: {}'.format(len(training_data)))\n",
    "for i in range(0,min(len(training_data), 10)):\n",
    "    print('length of training time series {}: {}'.format(i, len(training_data[i]['target'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of VALIDATION time series: 366\n",
      "length of VALIDATION time series 1: 5841\n",
      "length of VALIDATION time series 2: 5845\n",
      "length of VALIDATION time series 3: 5849\n",
      "length of VALIDATION time series 4: 5853\n",
      "length of VALIDATION time series 5: 5857\n",
      "length of VALIDATION time series 6: 5861\n",
      "length of VALIDATION time series 7: 5865\n",
      "length of VALIDATION time series 8: 5869\n",
      "length of VALIDATION time series 9: 5873\n"
     ]
    }
   ],
   "source": [
    "# 61日間のバリデーションデータを予測期間（例：24時間、4時間、1時間）に即して複数のテストデータに分割する\n",
    "num_test_windows = int(61 * 24 / prediction_length)\n",
    "\n",
    "# DeepARの必要フォーマットにあわせてバリデーションデータを変形する\n",
    "validation_data = []\n",
    "validation_data_info = []\n",
    "\n",
    "# 処理中のメッシュコードを抽出し、学習データとして与える範囲に絞ってから時系列データとしてリサンプル\n",
    "\n",
    "# バリデーションデータ期間をprediction_lengthで割った分だけ時系列を生成する\n",
    "for k in range(1, num_test_windows + 1):\n",
    "    df_validation = df_summary[train_start:validation_start + datetime.timedelta(hours= k * prediction_length)].copy().asfreq(freq)\n",
    "    validation_data.append(convert_to_DeepAR_dict(df_validation, 'count', train_start))\n",
    "\n",
    "    # テストデータの情報は精度評価時に利用するため補完する\n",
    "    validation_data_info.append({'pred_start_time':validation_start + datetime.timedelta(hours= (k-1) * prediction_length)})\n",
    "\n",
    "print('Number of VALIDATION time series: {}'.format(len(validation_data)))\n",
    "for i in range(1,min(len(validation_data), 10)):\n",
    "    print('length of VALIDATION time series {}: {}'.format(i, len(validation_data[i]['target'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作成したデータをディスクに保存し、S3にコピーする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "def copy_to_s3(local_file, s3_path, override=False):\n",
    "    assert s3_path.startswith('s3://')\n",
    "    split = s3_path.split('/')\n",
    "    bucket = split[2]\n",
    "    path = '/'.join(split[3:])\n",
    "    buk = s3.Bucket(bucket)\n",
    "    \n",
    "    if len(list(buk.objects.filter(Prefix=path))) > 0:\n",
    "        if not override:\n",
    "            print('File s3://{}/{} already exists.\\nSet override to upload anyway.\\n'.format(s3_bucket, s3_path))\n",
    "            return\n",
    "        else:\n",
    "            print('Overwriting existing file')\n",
    "    with open(local_file, 'rb') as data:\n",
    "        print('Uploading file to {}'.format(s3_path))\n",
    "        buk.put_object(Key=path, Body=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_header='DeepAR_test_shot02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file\n",
      "Uploading file to s3://tuki-bkt-misc/model/nyctaxi-deepar/data/train/train.json\n",
      "Overwriting existing file\n",
      "Uploading file to s3://tuki-bkt-misc/model/nyctaxi-deepar/data/validation/validation.json\n",
      "CPU times: user 317 ms, sys: 60.3 ms, total: 377 ms\n",
      "Wall time: 2.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# データをSageMakerのEBSに保存する\n",
    "write_dicts_to_file(\"result/{}_train.json\".format(case_header), training_data)\n",
    "write_dicts_to_file(\"result/{}_validation.json\".format(case_header), validation_data)\n",
    "\n",
    "# 保存したデータをS3にコピーする\n",
    "copy_to_s3(\"result/{}_train.json\".format(case_header), s3_data_path + \"/train/train.json\", override=True)\n",
    "copy_to_s3(\"result/{}_validation.json\".format(case_header), s3_data_path + \"/validation/validation.json\", override=True)\n",
    "\n",
    "data_channels = {\n",
    "    \"train\": \"{}/train/\".format(s3_data_path),\n",
    "    \"test\": \"{}/validation/\".format(s3_data_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのトレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c5.2xlarge',\n",
    "    base_job_name='deepar-nyctaxi',\n",
    "    output_path=s3_output_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": freq,\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"50\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length)\n",
    "}\n",
    "\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-04 09:15:18 Starting - Starting the training job...\n",
      "2020-10-04 09:15:20 Starting - Launching requested ML instances......\n",
      "2020-10-04 09:16:23 Starting - Preparing the instances for training...\n",
      "2020-10-04 09:17:00 Downloading - Downloading input data...\n",
      "2020-10-04 09:17:48 Training - Training image download completed. Training in progress..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'4', u'epochs': u'400', u'time_freq': u'1H', u'context_length': u'48', u'mini_batch_size': u'64', u'early_stopping_patience': u'50'}\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'4', u'time_freq': u'1H', u'context_length': u'48', u'_kvstore': u'auto', u'early_stopping_patience': u'50'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Using early stopping with patience 50\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Training set statistics:\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Integer time series\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] number of time series: 1\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] number of observations: 5832\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] mean target length: 5832\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] min/mean/max target: 5.0/698.121056241/1841.0\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] mean abs(target): 698.121056241\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] contains missing values: no\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Small number of time series. Doing 640 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Test set statistics:\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Integer time series\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] number of time series: 366\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] number of observations: 2403522\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] mean target length: 6567\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] min/mean/max target: 5.0/679.058909384/1841.0\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] mean abs(target): 679.058909384\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] contains missing values: no\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] nvidia-smi took: 0.0251150131226 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:50 INFO 139827261196096] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 243.32618713378906, \"sum\": 243.32618713378906, \"min\": 243.32618713378906}}, \"EndTime\": 1601803071.027687, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803070.78362}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:51 INFO 139827261196096] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 430.448055267334, \"sum\": 430.448055267334, \"min\": 430.448055267334}}, \"EndTime\": 1601803071.214171, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803071.027758}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:51 INFO 139827261196096] Epoch[0] Batch[0] avg_epoch_loss=7.794024\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=7.79402399063\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:52 INFO 139827261196096] Epoch[0] Batch[5] avg_epoch_loss=7.527369\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=7.5273689429\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:52 INFO 139827261196096] Epoch[0] Batch [5]#011Speed: 984.23 samples/sec#011loss=7.527369\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:52 INFO 139827261196096] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 1222.7239608764648, \"sum\": 1222.7239608764648, \"min\": 1222.7239608764648}}, \"EndTime\": 1601803072.437034, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803071.214224}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:52 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=509.472610098 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:52 INFO 139827261196096] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=0, train loss <loss>=7.4489177227\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:52 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:52 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_7f751f87-8e5d-4f12-8061-a3b5282e2ab9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 24.094104766845703, \"sum\": 24.094104766845703, \"min\": 24.094104766845703}}, \"EndTime\": 1601803072.461613, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803072.437113}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] Epoch[1] Batch[0] avg_epoch_loss=7.162582\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=7.16258192062\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] Epoch[1] Batch[5] avg_epoch_loss=7.089251\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=7.08925088247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] Epoch[1] Batch [5]#011Speed: 835.71 samples/sec#011loss=7.089251\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1259.5059871673584, \"sum\": 1259.5059871673584, \"min\": 1259.5059871673584}}, \"EndTime\": 1601803073.721232, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803072.46167}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=479.518062091 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=1, train loss <loss>=7.0651301384\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:53 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_9b74b260-413f-45b4-9b17-d92ae1522c5a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.242950439453125, \"sum\": 23.242950439453125, \"min\": 23.242950439453125}}, \"EndTime\": 1601803073.744893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803073.721295}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] Epoch[2] Batch[0] avg_epoch_loss=6.704040\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=6.70404005051\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] Epoch[2] Batch[5] avg_epoch_loss=6.724866\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=6.72486575445\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] Epoch[2] Batch [5]#011Speed: 969.10 samples/sec#011loss=6.724866\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1180.7448863983154, \"sum\": 1180.7448863983154, \"min\": 1180.7448863983154}}, \"EndTime\": 1601803074.925752, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803073.744951}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=520.817471382 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=2, train loss <loss>=6.68523330688\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:54 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_c7d4797e-232a-4c56-8a69-05294e65f0ca-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.23682403564453, \"sum\": 22.23682403564453, \"min\": 22.23682403564453}}, \"EndTime\": 1601803074.948401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803074.925813}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:55 INFO 139827261196096] Epoch[3] Batch[0] avg_epoch_loss=6.562232\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=6.56223249435\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:55 INFO 139827261196096] Epoch[3] Batch[5] avg_epoch_loss=6.481807\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=6.4818072319\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:55 INFO 139827261196096] Epoch[3] Batch [5]#011Speed: 979.58 samples/sec#011loss=6.481807\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] Epoch[3] Batch[10] avg_epoch_loss=6.434136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=6.37693099976\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] Epoch[3] Batch [10]#011Speed: 870.71 samples/sec#011loss=6.376931\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1261.6050243377686, \"sum\": 1261.6050243377686, \"min\": 1261.6050243377686}}, \"EndTime\": 1601803076.210108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803074.948453}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=527.070775175 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=3, train loss <loss>=6.43413621729\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_90423949-4a39-4c1f-aab4-e6a9d853954e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.318124771118164, \"sum\": 22.318124771118164, \"min\": 22.318124771118164}}, \"EndTime\": 1601803076.232772, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803076.210165}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] Epoch[4] Batch[0] avg_epoch_loss=6.390494\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=6.39049386978\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] Epoch[4] Batch[5] avg_epoch_loss=6.354187\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=6.35418669383\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] Epoch[4] Batch [5]#011Speed: 1014.88 samples/sec#011loss=6.354187\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1103.985071182251, \"sum\": 1103.985071182251, \"min\": 1103.985071182251}}, \"EndTime\": 1601803077.336869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803076.232828}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=570.609243208 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=4, train loss <loss>=6.34179167747\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_d2108110-7c2f-47b3-80b7-726e1ce65293-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.781972885131836, \"sum\": 17.781972885131836, \"min\": 17.781972885131836}}, \"EndTime\": 1601803077.355135, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803077.336935}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] Epoch[5] Batch[0] avg_epoch_loss=6.322004\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=6.32200431824\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] Epoch[5] Batch[5] avg_epoch_loss=6.237685\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=6.23768496513\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] Epoch[5] Batch [5]#011Speed: 1020.33 samples/sec#011loss=6.237685\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] Epoch[5] Batch[10] avg_epoch_loss=6.208024\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=6.17243080139\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] Epoch[5] Batch [10]#011Speed: 1007.03 samples/sec#011loss=6.172431\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1158.444881439209, \"sum\": 1158.444881439209, \"min\": 1158.444881439209}}, \"EndTime\": 1601803078.513684, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803077.35519}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=565.37117087 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=5, train loss <loss>=6.20802398161\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:58 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_f60b9c68-51bf-4ee3-9ccf-84bba10c18b4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.78614044189453, \"sum\": 22.78614044189453, \"min\": 22.78614044189453}}, \"EndTime\": 1601803078.536892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803078.513744}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] Epoch[6] Batch[0] avg_epoch_loss=6.135117\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=6.13511705399\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] Epoch[6] Batch[5] avg_epoch_loss=6.140792\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=6.14079157511\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] Epoch[6] Batch [5]#011Speed: 897.31 samples/sec#011loss=6.140792\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] Epoch[6] Batch[10] avg_epoch_loss=6.073503\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=5.99275693893\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] Epoch[6] Batch [10]#011Speed: 972.63 samples/sec#011loss=5.992757\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1233.5450649261475, \"sum\": 1233.5450649261475, \"min\": 1233.5450649261475}}, \"EndTime\": 1601803079.770536, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803078.536943}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=529.33297695 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=6, train loss <loss>=6.07350310412\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:17:59 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_a53c750f-12ab-48c9-908c-1c5a1bedb599-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.414995193481445, \"sum\": 21.414995193481445, \"min\": 21.414995193481445}}, \"EndTime\": 1601803079.792303, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803079.770591}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:00 INFO 139827261196096] Epoch[7] Batch[0] avg_epoch_loss=6.095911\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=6.095911026\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:00 INFO 139827261196096] Epoch[7] Batch[5] avg_epoch_loss=6.087946\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=6.08794601758\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:00 INFO 139827261196096] Epoch[7] Batch [5]#011Speed: 971.95 samples/sec#011loss=6.087946\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] Epoch[7] Batch[10] avg_epoch_loss=6.025187\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=5.94987697601\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] Epoch[7] Batch [10]#011Speed: 952.14 samples/sec#011loss=5.949877\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1208.7030410766602, \"sum\": 1208.7030410766602, \"min\": 1208.7030410766602}}, \"EndTime\": 1601803081.001109, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803079.792356}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=530.284621473 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=7, train loss <loss>=6.02518736232\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_b9e0f1c5-d1ff-418e-89ee-949440355a4e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.224000930786133, \"sum\": 18.224000930786133, \"min\": 18.224000930786133}}, \"EndTime\": 1601803081.019713, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803081.001165}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] Epoch[8] Batch[0] avg_epoch_loss=6.001003\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=6.00100278854\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] Epoch[8] Batch[5] avg_epoch_loss=6.011819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=6.01181864738\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:01 INFO 139827261196096] Epoch[8] Batch [5]#011Speed: 1007.08 samples/sec#011loss=6.011819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] Epoch[8] Batch[10] avg_epoch_loss=6.001515\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=5.98915061951\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] Epoch[8] Batch [10]#011Speed: 900.01 samples/sec#011loss=5.989151\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1207.7991962432861, \"sum\": 1207.7991962432861, \"min\": 1207.7991962432861}}, \"EndTime\": 1601803082.227626, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803081.019771}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=533.991642311 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=8, train loss <loss>=6.00151499835\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_c17380d0-f61e-4503-8c12-ffbeb81d0565-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.620967864990234, \"sum\": 18.620967864990234, \"min\": 18.620967864990234}}, \"EndTime\": 1601803082.246651, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803082.227681}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] Epoch[9] Batch[0] avg_epoch_loss=5.967537\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=5.96753692627\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] Epoch[9] Batch[5] avg_epoch_loss=5.992004\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=5.99200423559\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] Epoch[9] Batch [5]#011Speed: 998.08 samples/sec#011loss=5.992004\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1152.5251865386963, \"sum\": 1152.5251865386963, \"min\": 1152.5251865386963}}, \"EndTime\": 1601803083.399276, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803082.246699}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=542.247564691 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=9, train loss <loss>=5.95933914185\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_b3cc969c-76f0-422f-a238-89b1d86a024a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.147945404052734, \"sum\": 18.147945404052734, \"min\": 18.147945404052734}}, \"EndTime\": 1601803083.417876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803083.399335}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] Epoch[10] Batch[0] avg_epoch_loss=5.877421\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=5.87742090225\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:04 INFO 139827261196096] Epoch[10] Batch[5] avg_epoch_loss=5.862730\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=5.86273002625\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:04 INFO 139827261196096] Epoch[10] Batch [5]#011Speed: 924.02 samples/sec#011loss=5.862730\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:04 INFO 139827261196096] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1165.050983428955, \"sum\": 1165.050983428955, \"min\": 1165.050983428955}}, \"EndTime\": 1601803084.583035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803083.417931}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:04 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=523.542166979 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:04 INFO 139827261196096] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=10, train loss <loss>=5.84119143486\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:04 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:04 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_22500abe-abf2-4be1-b0b9-faf07e0bded0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.22299575805664, \"sum\": 22.22299575805664, \"min\": 22.22299575805664}}, \"EndTime\": 1601803084.605659, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803084.583096}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] Epoch[11] Batch[0] avg_epoch_loss=5.807062\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=5.80706167221\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] Epoch[11] Batch[5] avg_epoch_loss=5.802136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=5.80213618279\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] Epoch[11] Batch [5]#011Speed: 978.63 samples/sec#011loss=5.802136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1147.9580402374268, \"sum\": 1147.9580402374268, \"min\": 1147.9580402374268}}, \"EndTime\": 1601803085.753724, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803084.605712}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=535.691032902 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=11, train loss <loss>=5.79241862297\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:05 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_1fa93d3f-0ea1-41be-81c9-57993eecf889-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.208980560302734, \"sum\": 18.208980560302734, \"min\": 18.208980560302734}}, \"EndTime\": 1601803085.772441, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803085.753785}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] Epoch[12] Batch[0] avg_epoch_loss=5.898026\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=5.89802646637\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] Epoch[12] Batch[5] avg_epoch_loss=5.834177\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=5.83417725563\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] Epoch[12] Batch [5]#011Speed: 975.02 samples/sec#011loss=5.834177\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] Epoch[12] Batch[10] avg_epoch_loss=5.776459\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=5.7071978569\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] Epoch[12] Batch [10]#011Speed: 952.64 samples/sec#011loss=5.707198\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1225.3060340881348, \"sum\": 1225.3060340881348, \"min\": 1225.3060340881348}}, \"EndTime\": 1601803086.997868, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803085.772504}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=536.969309586 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=12, train loss <loss>=5.77645934712\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:06 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:07 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_e37c5f81-79ad-47ac-870a-b99eb2b0b614-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.930145263671875, \"sum\": 22.930145263671875, \"min\": 22.930145263671875}}, \"EndTime\": 1601803087.021197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803086.997928}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:07 INFO 139827261196096] Epoch[13] Batch[0] avg_epoch_loss=5.879985\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=5.87998485565\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:07 INFO 139827261196096] Epoch[13] Batch[5] avg_epoch_loss=5.808273\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=5.80827275912\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:07 INFO 139827261196096] Epoch[13] Batch [5]#011Speed: 1011.79 samples/sec#011loss=5.808273\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:08 INFO 139827261196096] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1132.544994354248, \"sum\": 1132.544994354248, \"min\": 1132.544994354248}}, \"EndTime\": 1601803088.153859, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803087.021258}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:08 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=561.526546753 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:08 INFO 139827261196096] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=13, train loss <loss>=5.79811782837\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:08 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:08 INFO 139827261196096] Epoch[14] Batch[0] avg_epoch_loss=5.740268\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=5.74026823044\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:08 INFO 139827261196096] Epoch[14] Batch[5] avg_epoch_loss=5.707234\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=5.70723366737\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:09 INFO 139827261196096] Epoch[14] Batch [5]#011Speed: 1017.49 samples/sec#011loss=5.707234\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:09 INFO 139827261196096] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1108.384132385254, \"sum\": 1108.384132385254, \"min\": 1108.384132385254}}, \"EndTime\": 1601803089.262672, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803088.153912}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:09 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=560.229158874 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:09 INFO 139827261196096] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=14, train loss <loss>=5.73603496552\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:09 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:09 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_c1f909f3-b3d7-4640-a260-21745f1dd6a4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.966032028198242, \"sum\": 17.966032028198242, \"min\": 17.966032028198242}}, \"EndTime\": 1601803089.281103, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803089.262735}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:09 INFO 139827261196096] Epoch[15] Batch[0] avg_epoch_loss=5.651010\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=5.65101003647\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] Epoch[15] Batch[5] avg_epoch_loss=5.718015\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=5.71801527341\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] Epoch[15] Batch [5]#011Speed: 1023.35 samples/sec#011loss=5.718015\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1109.4920635223389, \"sum\": 1109.4920635223389, \"min\": 1109.4920635223389}}, \"EndTime\": 1601803090.390693, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803089.281148}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=557.868243545 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=15, train loss <loss>=5.71388502121\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_419eb8c5-97ac-4637-9d8d-827993477786-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.084049224853516, \"sum\": 18.084049224853516, \"min\": 18.084049224853516}}, \"EndTime\": 1601803090.409191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803090.390749}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] Epoch[16] Batch[0] avg_epoch_loss=5.698789\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=5.69878864288\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] Epoch[16] Batch[5] avg_epoch_loss=5.665924\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=5.66592431068\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] Epoch[16] Batch [5]#011Speed: 985.66 samples/sec#011loss=5.665924\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] Epoch[16] Batch[10] avg_epoch_loss=5.680490\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=5.69796924591\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] Epoch[16] Batch [10]#011Speed: 1000.21 samples/sec#011loss=5.697969\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1179.2800426483154, \"sum\": 1179.2800426483154, \"min\": 1179.2800426483154}}, \"EndTime\": 1601803091.588579, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803090.409248}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=566.406995011 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=16, train loss <loss>=5.68049019033\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:11 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_a43a9d6a-d134-4b55-8a33-8ab7910c0f80-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.82083511352539, \"sum\": 17.82083511352539, \"min\": 17.82083511352539}}, \"EndTime\": 1601803091.606787, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803091.588637}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] Epoch[17] Batch[0] avg_epoch_loss=5.729356\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=5.72935581207\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] Epoch[17] Batch[5] avg_epoch_loss=5.675508\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=5.67550786336\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] Epoch[17] Batch [5]#011Speed: 985.81 samples/sec#011loss=5.675508\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1104.1810512542725, \"sum\": 1104.1810512542725, \"min\": 1104.1810512542725}}, \"EndTime\": 1601803092.71107, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803091.60684}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=579.568912955 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=17, train loss <loss>=5.64680762291\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:12 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_259b5419-fb15-460b-86bd-e33912f3eca1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.259048461914062, \"sum\": 18.259048461914062, \"min\": 18.259048461914062}}, \"EndTime\": 1601803092.729775, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803092.711132}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:13 INFO 139827261196096] Epoch[18] Batch[0] avg_epoch_loss=5.609387\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=5.60938692093\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:13 INFO 139827261196096] Epoch[18] Batch[5] avg_epoch_loss=5.676024\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=5.67602380117\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:13 INFO 139827261196096] Epoch[18] Batch [5]#011Speed: 1011.44 samples/sec#011loss=5.676024\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:13 INFO 139827261196096] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1099.207878112793, \"sum\": 1099.207878112793, \"min\": 1099.207878112793}}, \"EndTime\": 1601803093.82907, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803092.729816}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:13 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=559.454126551 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:13 INFO 139827261196096] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=18, train loss <loss>=5.65825157166\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:13 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:14 INFO 139827261196096] Epoch[19] Batch[0] avg_epoch_loss=5.642372\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=5.64237213135\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:14 INFO 139827261196096] Epoch[19] Batch[5] avg_epoch_loss=5.651305\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=5.65130480131\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:14 INFO 139827261196096] Epoch[19] Batch [5]#011Speed: 973.95 samples/sec#011loss=5.651305\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] Epoch[19] Batch[10] avg_epoch_loss=5.649297\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=5.64688873291\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] Epoch[19] Batch [10]#011Speed: 995.88 samples/sec#011loss=5.646889\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1185.995101928711, \"sum\": 1185.995101928711, \"min\": 1185.995101928711}}, \"EndTime\": 1601803095.015481, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803093.829122}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=558.141562153 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=19, train loss <loss>=5.64929749749\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] Epoch[20] Batch[0] avg_epoch_loss=5.683512\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=5.68351173401\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] Epoch[20] Batch[5] avg_epoch_loss=5.622052\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=5.62205163638\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:15 INFO 139827261196096] Epoch[20] Batch [5]#011Speed: 1010.07 samples/sec#011loss=5.622052\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] Epoch[20] Batch[10] avg_epoch_loss=5.620166\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=5.6179022789\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] Epoch[20] Batch [10]#011Speed: 995.20 samples/sec#011loss=5.617902\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1171.9820499420166, \"sum\": 1171.9820499420166, \"min\": 1171.9820499420166}}, \"EndTime\": 1601803096.187844, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803095.015539}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.896095902 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=20, train loss <loss>=5.6201655648\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_0edd7e18-b595-4adf-ad45-9d494374cdb0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.642974853515625, \"sum\": 17.642974853515625, \"min\": 17.642974853515625}}, \"EndTime\": 1601803096.205881, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803096.187902}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] Epoch[21] Batch[0] avg_epoch_loss=5.628529\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=5.62852907181\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:17 INFO 139827261196096] Epoch[21] Batch[5] avg_epoch_loss=5.603450\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=5.60345037778\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:17 INFO 139827261196096] Epoch[21] Batch [5]#011Speed: 1021.36 samples/sec#011loss=5.603450\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:17 INFO 139827261196096] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1102.599859237671, \"sum\": 1102.599859237671, \"min\": 1102.599859237671}}, \"EndTime\": 1601803097.308581, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803096.20593}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:17 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=545.03527562 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:17 INFO 139827261196096] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=21, train loss <loss>=5.62039322853\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:17 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:17 INFO 139827261196096] Epoch[22] Batch[0] avg_epoch_loss=5.559433\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=5.5594329834\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] Epoch[22] Batch[5] avg_epoch_loss=5.596467\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=5.59646717707\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] Epoch[22] Batch [5]#011Speed: 988.27 samples/sec#011loss=5.596467\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1106.687068939209, \"sum\": 1106.687068939209, \"min\": 1106.687068939209}}, \"EndTime\": 1601803098.415695, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803097.308632}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=552.044380347 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=22, train loss <loss>=5.59992046356\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_80e0034e-8755-4dd6-a60c-849d45fe685f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.906904220581055, \"sum\": 17.906904220581055, \"min\": 17.906904220581055}}, \"EndTime\": 1601803098.434085, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803098.41577}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] Epoch[23] Batch[0] avg_epoch_loss=5.544155\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=5.54415464401\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] Epoch[23] Batch[5] avg_epoch_loss=5.555215\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=5.55521519979\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] Epoch[23] Batch [5]#011Speed: 1013.17 samples/sec#011loss=5.555215\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] Epoch[23] Batch[10] avg_epoch_loss=5.562756\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=5.57180500031\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] Epoch[23] Batch [10]#011Speed: 930.61 samples/sec#011loss=5.571805\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1197.6900100708008, \"sum\": 1197.6900100708008, \"min\": 1197.6900100708008}}, \"EndTime\": 1601803099.63187, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803098.434131}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=573.56593391 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=23, train loss <loss>=5.56275601821\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:19 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_d7f19f0f-60ab-4c1f-b4d2-810a5200ed07-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.467063903808594, \"sum\": 23.467063903808594, \"min\": 23.467063903808594}}, \"EndTime\": 1601803099.655739, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803099.631923}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] Epoch[24] Batch[0] avg_epoch_loss=5.610735\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=5.61073541641\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] Epoch[24] Batch[5] avg_epoch_loss=5.540965\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=5.54096452395\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] Epoch[24] Batch [5]#011Speed: 981.66 samples/sec#011loss=5.540965\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1118.6609268188477, \"sum\": 1118.6609268188477, \"min\": 1118.6609268188477}}, \"EndTime\": 1601803100.774501, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803099.655792}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=557.768881592 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=24, train loss <loss>=5.52682976723\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:20 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_5555f874-c17d-4dd0-b18b-e2c703635fe2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.44389533996582, \"sum\": 17.44389533996582, \"min\": 17.44389533996582}}, \"EndTime\": 1601803100.792398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803100.774557}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:21 INFO 139827261196096] Epoch[25] Batch[0] avg_epoch_loss=5.553465\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=5.55346536636\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:21 INFO 139827261196096] Epoch[25] Batch[5] avg_epoch_loss=5.559850\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=5.55985029538\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:21 INFO 139827261196096] Epoch[25] Batch [5]#011Speed: 999.86 samples/sec#011loss=5.559850\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:21 INFO 139827261196096] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1113.671064376831, \"sum\": 1113.671064376831, \"min\": 1113.671064376831}}, \"EndTime\": 1601803101.906181, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803100.792455}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:21 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=568.342999894 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:21 INFO 139827261196096] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=25, train loss <loss>=5.56043953896\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:21 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:22 INFO 139827261196096] Epoch[26] Batch[0] avg_epoch_loss=5.486032\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=5.48603200912\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:22 INFO 139827261196096] Epoch[26] Batch[5] avg_epoch_loss=5.504920\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=5.50492040316\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:22 INFO 139827261196096] Epoch[26] Batch [5]#011Speed: 957.69 samples/sec#011loss=5.504920\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1148.503065109253, \"sum\": 1148.503065109253, \"min\": 1148.503065109253}}, \"EndTime\": 1601803103.055064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803101.906243}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=541.529669107 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=26, train loss <loss>=5.52642130852\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_4b785e47-8333-4dde-b723-1a5ed3b7a858-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.34196662902832, \"sum\": 22.34196662902832, \"min\": 22.34196662902832}}, \"EndTime\": 1601803103.077809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803103.055128}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] Epoch[27] Batch[0] avg_epoch_loss=5.563216\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=5.56321620941\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] Epoch[27] Batch[5] avg_epoch_loss=5.553715\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=5.55371451378\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:23 INFO 139827261196096] Epoch[27] Batch [5]#011Speed: 983.38 samples/sec#011loss=5.553715\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:24 INFO 139827261196096] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1156.2800407409668, \"sum\": 1156.2800407409668, \"min\": 1156.2800407409668}}, \"EndTime\": 1601803104.234193, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803103.077861}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:24 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=543.944031572 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:24 INFO 139827261196096] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=27, train loss <loss>=5.54056310654\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:24 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:24 INFO 139827261196096] Epoch[28] Batch[0] avg_epoch_loss=5.468024\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=5.46802377701\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] Epoch[28] Batch[5] avg_epoch_loss=5.505674\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=5.50567396482\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] Epoch[28] Batch [5]#011Speed: 963.36 samples/sec#011loss=5.505674\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] Epoch[28] Batch[10] avg_epoch_loss=5.493718\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=5.47937049866\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] Epoch[28] Batch [10]#011Speed: 947.38 samples/sec#011loss=5.479370\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1231.1320304870605, \"sum\": 1231.1320304870605, \"min\": 1231.1320304870605}}, \"EndTime\": 1601803105.465787, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803104.234253}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=525.492388757 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=28, train loss <loss>=5.49371784384\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:25 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_84e89acd-b5a6-4df4-8c68-2ce3b0ad01c1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.4609375, \"sum\": 22.4609375, \"min\": 22.4609375}}, \"EndTime\": 1601803105.488624, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803105.465846}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:26 INFO 139827261196096] Epoch[29] Batch[0] avg_epoch_loss=5.568492\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=5.56849193573\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:26 INFO 139827261196096] Epoch[29] Batch[5] avg_epoch_loss=5.574299\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=5.5742986997\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:26 INFO 139827261196096] Epoch[29] Batch [5]#011Speed: 968.36 samples/sec#011loss=5.574299\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:26 INFO 139827261196096] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1153.108835220337, \"sum\": 1153.108835220337, \"min\": 1153.108835220337}}, \"EndTime\": 1601803106.641834, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803105.488675}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:26 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=547.174030772 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:26 INFO 139827261196096] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=29, train loss <loss>=5.56095452309\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:26 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] Epoch[30] Batch[0] avg_epoch_loss=5.590744\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=5.59074401855\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] Epoch[30] Batch[5] avg_epoch_loss=5.541471\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=5.54147108396\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] Epoch[30] Batch [5]#011Speed: 945.91 samples/sec#011loss=5.541471\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] Epoch[30] Batch[10] avg_epoch_loss=5.501859\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=5.45432395935\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] Epoch[30] Batch [10]#011Speed: 941.43 samples/sec#011loss=5.454324\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1223.1850624084473, \"sum\": 1223.1850624084473, \"min\": 1223.1850624084473}}, \"EndTime\": 1601803107.865427, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803106.641894}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=534.629900413 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=30, train loss <loss>=5.50185875459\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:27 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:28 INFO 139827261196096] Epoch[31] Batch[0] avg_epoch_loss=5.571736\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=5.57173585892\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:28 INFO 139827261196096] Epoch[31] Batch[5] avg_epoch_loss=5.505116\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=5.50511550903\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:28 INFO 139827261196096] Epoch[31] Batch [5]#011Speed: 959.79 samples/sec#011loss=5.505116\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:29 INFO 139827261196096] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1144.9840068817139, \"sum\": 1144.9840068817139, \"min\": 1144.9840068817139}}, \"EndTime\": 1601803109.010749, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803107.865488}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:29 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=528.35007326 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:29 INFO 139827261196096] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=31, train loss <loss>=5.50597305298\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:29 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:29 INFO 139827261196096] Epoch[32] Batch[0] avg_epoch_loss=5.604418\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=5.60441827774\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:29 INFO 139827261196096] Epoch[32] Batch[5] avg_epoch_loss=5.517232\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=5.51723186175\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:29 INFO 139827261196096] Epoch[32] Batch [5]#011Speed: 974.58 samples/sec#011loss=5.517232\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:30 INFO 139827261196096] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1179.3088912963867, \"sum\": 1179.3088912963867, \"min\": 1179.3088912963867}}, \"EndTime\": 1601803110.190422, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803109.010812}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:30 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=524.843579573 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:30 INFO 139827261196096] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=32, train loss <loss>=5.4895816803\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:30 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:30 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_43f55f9c-5eac-4bba-914f-63f9b6ce569f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.19586753845215, \"sum\": 18.19586753845215, \"min\": 18.19586753845215}}, \"EndTime\": 1601803110.209105, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803110.190485}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:30 INFO 139827261196096] Epoch[33] Batch[0] avg_epoch_loss=5.454984\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=5.45498371124\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] Epoch[33] Batch[5] avg_epoch_loss=5.506180\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=5.50617988904\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] Epoch[33] Batch [5]#011Speed: 1006.10 samples/sec#011loss=5.506180\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] Epoch[33] Batch[10] avg_epoch_loss=5.496980\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=5.48593988419\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] Epoch[33] Batch [10]#011Speed: 949.90 samples/sec#011loss=5.485940\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1220.418930053711, \"sum\": 1220.418930053711, \"min\": 1220.418930053711}}, \"EndTime\": 1601803111.429625, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803110.209151}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=559.606284791 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=33, train loss <loss>=5.49697988684\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] Epoch[34] Batch[0] avg_epoch_loss=5.452165\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=5.4521651268\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:32 INFO 139827261196096] Epoch[34] Batch[5] avg_epoch_loss=5.465911\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=5.46591083209\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:32 INFO 139827261196096] Epoch[34] Batch [5]#011Speed: 1009.11 samples/sec#011loss=5.465911\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:32 INFO 139827261196096] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1102.4141311645508, \"sum\": 1102.4141311645508, \"min\": 1102.4141311645508}}, \"EndTime\": 1601803112.532416, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803111.429679}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:32 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=568.699139846 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:32 INFO 139827261196096] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=34, train loss <loss>=5.46438221931\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:32 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:32 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_46eb4099-bf66-4224-b1a2-ac3ae842459f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.828941345214844, \"sum\": 17.828941345214844, \"min\": 17.828941345214844}}, \"EndTime\": 1601803112.550665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803112.532473}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] Epoch[35] Batch[0] avg_epoch_loss=5.480134\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=5.48013401031\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] Epoch[35] Batch[5] avg_epoch_loss=5.489492\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=5.48949170113\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] Epoch[35] Batch [5]#011Speed: 1012.47 samples/sec#011loss=5.489492\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] processed a total of 594 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1138.084888458252, \"sum\": 1138.084888458252, \"min\": 1138.084888458252}}, \"EndTime\": 1601803113.688849, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803112.550714}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=521.887230878 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=35, train loss <loss>=5.4452753067\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:33 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_f5828d45-c25d-4da1-b4b1-0e9aa0c6bc5a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.181987762451172, \"sum\": 22.181987762451172, \"min\": 22.181987762451172}}, \"EndTime\": 1601803113.711442, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803113.688912}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:34 INFO 139827261196096] Epoch[36] Batch[0] avg_epoch_loss=5.351998\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=5.35199785233\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:34 INFO 139827261196096] Epoch[36] Batch[5] avg_epoch_loss=5.419577\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=5.41957656542\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:34 INFO 139827261196096] Epoch[36] Batch [5]#011Speed: 926.42 samples/sec#011loss=5.419577\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:34 INFO 139827261196096] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1154.360055923462, \"sum\": 1154.360055923462, \"min\": 1154.360055923462}}, \"EndTime\": 1601803114.865909, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803113.711496}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:34 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=548.312172225 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:34 INFO 139827261196096] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=36, train loss <loss>=5.44892749786\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:34 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:35 INFO 139827261196096] Epoch[37] Batch[0] avg_epoch_loss=5.532591\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=5.53259086609\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:35 INFO 139827261196096] Epoch[37] Batch[5] avg_epoch_loss=5.488424\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=5.4884241422\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:35 INFO 139827261196096] Epoch[37] Batch [5]#011Speed: 968.46 samples/sec#011loss=5.488424\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] Epoch[37] Batch[10] avg_epoch_loss=5.482351\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=5.47506275177\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] Epoch[37] Batch [10]#011Speed: 952.94 samples/sec#011loss=5.475063\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1208.509922027588, \"sum\": 1208.509922027588, \"min\": 1208.509922027588}}, \"EndTime\": 1601803116.074813, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803114.86597}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=532.847062797 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=37, train loss <loss>=5.48235078291\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] Epoch[38] Batch[0] avg_epoch_loss=5.468058\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=5.46805763245\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] Epoch[38] Batch[5] avg_epoch_loss=5.458019\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=5.4580189387\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:36 INFO 139827261196096] Epoch[38] Batch [5]#011Speed: 1015.71 samples/sec#011loss=5.458019\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:37 INFO 139827261196096] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1103.6181449890137, \"sum\": 1103.6181449890137, \"min\": 1103.6181449890137}}, \"EndTime\": 1601803117.178815, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803116.074875}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:37 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=559.025138018 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:37 INFO 139827261196096] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=38, train loss <loss>=5.44268984795\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:37 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:37 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_53f6f5e3-15d7-444a-aabb-48d273607206-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.246173858642578, \"sum\": 18.246173858642578, \"min\": 18.246173858642578}}, \"EndTime\": 1601803117.19752, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803117.178876}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:37 INFO 139827261196096] Epoch[39] Batch[0] avg_epoch_loss=5.413755\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=5.41375541687\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:38 INFO 139827261196096] Epoch[39] Batch[5] avg_epoch_loss=5.460321\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=5.46032055219\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:38 INFO 139827261196096] Epoch[39] Batch [5]#011Speed: 1011.55 samples/sec#011loss=5.460321\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:38 INFO 139827261196096] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1112.5400066375732, \"sum\": 1112.5400066375732, \"min\": 1112.5400066375732}}, \"EndTime\": 1601803118.310169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803117.197576}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:38 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=572.516321003 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:38 INFO 139827261196096] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=39, train loss <loss>=5.45135540962\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:38 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:38 INFO 139827261196096] Epoch[40] Batch[0] avg_epoch_loss=5.411566\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=5.41156625748\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:39 INFO 139827261196096] Epoch[40] Batch[5] avg_epoch_loss=5.421325\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=5.42132488887\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:39 INFO 139827261196096] Epoch[40] Batch [5]#011Speed: 960.25 samples/sec#011loss=5.421325\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:39 INFO 139827261196096] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1171.321153640747, \"sum\": 1171.321153640747, \"min\": 1171.321153640747}}, \"EndTime\": 1601803119.481851, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803118.310233}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:39 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=530.130425712 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:39 INFO 139827261196096] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=40, train loss <loss>=5.4144985199\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:39 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:39 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_6a6516ed-6677-4b73-98b1-f8c9a1cd053f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.63498306274414, \"sum\": 22.63498306274414, \"min\": 22.63498306274414}}, \"EndTime\": 1601803119.504904, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803119.481912}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] Epoch[41] Batch[0] avg_epoch_loss=5.453188\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=5.45318841934\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] Epoch[41] Batch[5] avg_epoch_loss=5.449613\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=5.44961325328\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] Epoch[41] Batch [5]#011Speed: 941.86 samples/sec#011loss=5.449613\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] Epoch[41] Batch[10] avg_epoch_loss=5.418339\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=5.38081045151\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] Epoch[41] Batch [10]#011Speed: 942.53 samples/sec#011loss=5.380810\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1258.368968963623, \"sum\": 1258.368968963623, \"min\": 1258.368968963623}}, \"EndTime\": 1601803120.763409, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803119.504987}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=552.265826502 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=41, train loss <loss>=5.41833925247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:40 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] Epoch[42] Batch[0] avg_epoch_loss=5.434901\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=5.43490123749\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] Epoch[42] Batch[5] avg_epoch_loss=5.430988\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=5.4309879144\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] Epoch[42] Batch [5]#011Speed: 988.30 samples/sec#011loss=5.430988\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] Epoch[42] Batch[10] avg_epoch_loss=5.404801\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=5.37337770462\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] Epoch[42] Batch [10]#011Speed: 983.83 samples/sec#011loss=5.373378\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1193.5079097747803, \"sum\": 1193.5079097747803, \"min\": 1193.5079097747803}}, \"EndTime\": 1601803121.957232, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803120.763465}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=549.599200529 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=42, train loss <loss>=5.40480145541\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:41 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_a2790ffa-f855-47bd-b238-ae9be92032f1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.828941345214844, \"sum\": 17.828941345214844, \"min\": 17.828941345214844}}, \"EndTime\": 1601803121.975497, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803121.957293}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:42 INFO 139827261196096] Epoch[43] Batch[0] avg_epoch_loss=5.430360\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=5.43035984039\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:42 INFO 139827261196096] Epoch[43] Batch[5] avg_epoch_loss=5.401238\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=5.40123772621\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:42 INFO 139827261196096] Epoch[43] Batch [5]#011Speed: 1022.21 samples/sec#011loss=5.401238\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1098.1590747833252, \"sum\": 1098.1590747833252, \"min\": 1098.1590747833252}}, \"EndTime\": 1601803123.073753, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803121.975545}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=576.373047654 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=43, train loss <loss>=5.40188646317\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_0a3fc229-f47f-4eda-8c96-73eaa8e365e3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.879009246826172, \"sum\": 17.879009246826172, \"min\": 17.879009246826172}}, \"EndTime\": 1601803123.092103, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803123.073813}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] Epoch[44] Batch[0] avg_epoch_loss=5.468315\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=5.46831512451\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] Epoch[44] Batch[5] avg_epoch_loss=5.389019\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=5.38901925087\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:43 INFO 139827261196096] Epoch[44] Batch [5]#011Speed: 981.28 samples/sec#011loss=5.389019\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:44 INFO 139827261196096] Epoch[44] Batch[10] avg_epoch_loss=5.414888\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=5.44593029022\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:44 INFO 139827261196096] Epoch[44] Batch [10]#011Speed: 984.22 samples/sec#011loss=5.445930\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:44 INFO 139827261196096] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1180.9329986572266, \"sum\": 1180.9329986572266, \"min\": 1180.9329986572266}}, \"EndTime\": 1601803124.273137, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803123.092153}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:44 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=545.292779473 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:44 INFO 139827261196096] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=44, train loss <loss>=5.41488790512\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:44 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:44 INFO 139827261196096] Epoch[45] Batch[0] avg_epoch_loss=5.432503\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=5.43250322342\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:45 INFO 139827261196096] Epoch[45] Batch[5] avg_epoch_loss=5.419823\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=5.41982269287\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:45 INFO 139827261196096] Epoch[45] Batch [5]#011Speed: 994.17 samples/sec#011loss=5.419823\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:45 INFO 139827261196096] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1129.6358108520508, \"sum\": 1129.6358108520508, \"min\": 1129.6358108520508}}, \"EndTime\": 1601803125.403087, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803124.273194}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:45 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=559.428189625 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:45 INFO 139827261196096] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=45, train loss <loss>=5.41131148338\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:45 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:45 INFO 139827261196096] Epoch[46] Batch[0] avg_epoch_loss=5.404098\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=5.40409755707\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] Epoch[46] Batch[5] avg_epoch_loss=5.367453\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=5.36745262146\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] Epoch[46] Batch [5]#011Speed: 1001.56 samples/sec#011loss=5.367453\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] Epoch[46] Batch[10] avg_epoch_loss=5.394881\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=5.42779436111\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] Epoch[46] Batch [10]#011Speed: 991.68 samples/sec#011loss=5.427794\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1173.9280223846436, \"sum\": 1173.9280223846436, \"min\": 1173.9280223846436}}, \"EndTime\": 1601803126.577383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803125.403147}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=565.580945588 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=46, train loss <loss>=5.39488068494\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:46 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_7d1f1915-d3a9-4c12-a469-1392adffaa26-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.89491081237793, \"sum\": 18.89491081237793, \"min\": 18.89491081237793}}, \"EndTime\": 1601803126.596704, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803126.57744}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] Epoch[47] Batch[0] avg_epoch_loss=5.401335\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=5.40133476257\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] Epoch[47] Batch[5] avg_epoch_loss=5.399112\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=5.3991115888\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] Epoch[47] Batch [5]#011Speed: 948.53 samples/sec#011loss=5.399112\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] Epoch[47] Batch[10] avg_epoch_loss=5.390885\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=5.38101348877\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] Epoch[47] Batch [10]#011Speed: 1001.05 samples/sec#011loss=5.381013\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1177.7310371398926, \"sum\": 1177.7310371398926, \"min\": 1177.7310371398926}}, \"EndTime\": 1601803127.774532, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803126.596748}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=560.359667813 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=47, train loss <loss>=5.39088517969\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:47 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_ee8f0dc8-2e2b-4937-9ef6-b7e6cddb56ec-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.92001724243164, \"sum\": 17.92001724243164, \"min\": 17.92001724243164}}, \"EndTime\": 1601803127.792858, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803127.774586}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] Epoch[48] Batch[0] avg_epoch_loss=5.396049\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=5.39604902267\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] Epoch[48] Batch[5] avg_epoch_loss=5.389453\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=5.38945301374\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] Epoch[48] Batch [5]#011Speed: 999.39 samples/sec#011loss=5.389453\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1091.2961959838867, \"sum\": 1091.2961959838867, \"min\": 1091.2961959838867}}, \"EndTime\": 1601803128.884263, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803127.792913}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=573.578279982 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=48, train loss <loss>=5.38788542747\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:48 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_42d2afc1-c336-4858-9541-b1790badeab1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.763137817382812, \"sum\": 17.763137817382812, \"min\": 17.763137817382812}}, \"EndTime\": 1601803128.902511, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803128.884329}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:49 INFO 139827261196096] Epoch[49] Batch[0] avg_epoch_loss=5.439238\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=5.4392375946\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:49 INFO 139827261196096] Epoch[49] Batch[5] avg_epoch_loss=5.397416\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=5.3974164327\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:49 INFO 139827261196096] Epoch[49] Batch [5]#011Speed: 973.76 samples/sec#011loss=5.397416\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] Epoch[49] Batch[10] avg_epoch_loss=5.383480\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=5.36675605774\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] Epoch[49] Batch [10]#011Speed: 985.25 samples/sec#011loss=5.366756\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1177.0119667053223, \"sum\": 1177.0119667053223, \"min\": 1177.0119667053223}}, \"EndTime\": 1601803130.079628, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803128.902567}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=578.539454144 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=49, train loss <loss>=5.38347989863\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_432cbb1e-de14-4a49-8590-a834ffa92e6e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.12016487121582, \"sum\": 23.12016487121582, \"min\": 23.12016487121582}}, \"EndTime\": 1601803130.103121, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803130.07969}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] Epoch[50] Batch[0] avg_epoch_loss=5.467573\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=5.46757268906\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] Epoch[50] Batch[5] avg_epoch_loss=5.392464\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=5.39246376355\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:50 INFO 139827261196096] Epoch[50] Batch [5]#011Speed: 1013.79 samples/sec#011loss=5.392464\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:51 INFO 139827261196096] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1090.2810096740723, \"sum\": 1090.2810096740723, \"min\": 1090.2810096740723}}, \"EndTime\": 1601803131.193505, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803130.103176}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:51 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=572.284461432 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:51 INFO 139827261196096] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=50, train loss <loss>=5.36080150604\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:51 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:51 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_2ab3124c-e800-462c-bae0-42919d20fb62-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.358064651489258, \"sum\": 17.358064651489258, \"min\": 17.358064651489258}}, \"EndTime\": 1601803131.211304, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803131.193564}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:51 INFO 139827261196096] Epoch[51] Batch[0] avg_epoch_loss=5.386098\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=5.38609838486\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] Epoch[51] Batch[5] avg_epoch_loss=5.394635\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=5.39463456472\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] Epoch[51] Batch [5]#011Speed: 976.78 samples/sec#011loss=5.394635\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1113.8567924499512, \"sum\": 1113.8567924499512, \"min\": 1113.8567924499512}}, \"EndTime\": 1601803132.325271, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803131.211363}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=536.83172867 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=51, train loss <loss>=5.35202379227\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_f714e53f-fa4f-40f5-a6a5-18a572f2cbd0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.555952072143555, \"sum\": 17.555952072143555, \"min\": 17.555952072143555}}, \"EndTime\": 1601803132.3433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803132.325328}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] Epoch[52] Batch[0] avg_epoch_loss=5.275831\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=5.2758307457\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:53 INFO 139827261196096] Epoch[52] Batch[5] avg_epoch_loss=5.359069\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=5.35906926791\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:53 INFO 139827261196096] Epoch[52] Batch [5]#011Speed: 959.57 samples/sec#011loss=5.359069\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:53 INFO 139827261196096] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1134.9461078643799, \"sum\": 1134.9461078643799, \"min\": 1134.9461078643799}}, \"EndTime\": 1601803133.478353, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803132.343352}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:53 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=544.475097018 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:53 INFO 139827261196096] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=52, train loss <loss>=5.34648270607\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:53 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:53 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_14f73bba-8a5a-4433-bf29-cb2e4d69d175-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.407054901123047, \"sum\": 22.407054901123047, \"min\": 22.407054901123047}}, \"EndTime\": 1601803133.501159, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803133.478414}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] Epoch[53] Batch[0] avg_epoch_loss=5.435747\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=5.43574666977\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] Epoch[53] Batch[5] avg_epoch_loss=5.376388\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=5.37638831139\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] Epoch[53] Batch [5]#011Speed: 976.39 samples/sec#011loss=5.376388\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1143.517017364502, \"sum\": 1143.517017364502, \"min\": 1143.517017364502}}, \"EndTime\": 1601803134.644782, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803133.501211}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=538.642359819 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=53, train loss <loss>=5.3430287838\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:54 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_1d2b5678-5126-42b9-a3e8-71398fdc2b47-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.35379409790039, \"sum\": 20.35379409790039, \"min\": 20.35379409790039}}, \"EndTime\": 1601803134.665653, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803134.644849}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:55 INFO 139827261196096] Epoch[54] Batch[0] avg_epoch_loss=5.270774\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=5.27077436447\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:55 INFO 139827261196096] Epoch[54] Batch[5] avg_epoch_loss=5.343829\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=5.34382939339\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:55 INFO 139827261196096] Epoch[54] Batch [5]#011Speed: 945.55 samples/sec#011loss=5.343829\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:55 INFO 139827261196096] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1172.8520393371582, \"sum\": 1172.8520393371582, \"min\": 1172.8520393371582}}, \"EndTime\": 1601803135.838633, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803134.665721}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:55 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=541.365854789 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:55 INFO 139827261196096] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=54, train loss <loss>=5.35430583954\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:55 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:56 INFO 139827261196096] Epoch[55] Batch[0] avg_epoch_loss=5.329251\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=5.32925128937\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:56 INFO 139827261196096] Epoch[55] Batch[5] avg_epoch_loss=5.354798\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=5.3547976017\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:56 INFO 139827261196096] Epoch[55] Batch [5]#011Speed: 941.32 samples/sec#011loss=5.354798\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1167.1650409698486, \"sum\": 1167.1650409698486, \"min\": 1167.1650409698486}}, \"EndTime\": 1601803137.006257, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803135.838707}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=517.451155194 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=55, train loss <loss>=5.33209905624\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_a7dbd852-aa41-4cff-8af4-546f0514b923-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.821903228759766, \"sum\": 22.821903228759766, \"min\": 22.821903228759766}}, \"EndTime\": 1601803137.029477, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803137.006321}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] Epoch[56] Batch[0] avg_epoch_loss=5.458782\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=5.45878219604\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] Epoch[56] Batch[5] avg_epoch_loss=5.406037\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=5.40603701274\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:57 INFO 139827261196096] Epoch[56] Batch [5]#011Speed: 971.80 samples/sec#011loss=5.406037\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:58 INFO 139827261196096] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1145.923137664795, \"sum\": 1145.923137664795, \"min\": 1145.923137664795}}, \"EndTime\": 1601803138.175513, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803137.029534}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:58 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=541.000891867 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:58 INFO 139827261196096] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=56, train loss <loss>=5.39787063599\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:58 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:58 INFO 139827261196096] Epoch[57] Batch[0] avg_epoch_loss=5.299691\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=5.29969120026\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:59 INFO 139827261196096] Epoch[57] Batch[5] avg_epoch_loss=5.327318\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=5.32731787364\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:59 INFO 139827261196096] Epoch[57] Batch [5]#011Speed: 973.65 samples/sec#011loss=5.327318\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:59 INFO 139827261196096] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1147.1118927001953, \"sum\": 1147.1118927001953, \"min\": 1147.1118927001953}}, \"EndTime\": 1601803139.323069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803138.175582}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:59 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=554.394751286 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:59 INFO 139827261196096] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=57, train loss <loss>=5.33607077599\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:59 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:59 INFO 139827261196096] Epoch[58] Batch[0] avg_epoch_loss=5.327748\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:18:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=5.32774829865\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] Epoch[58] Batch[5] avg_epoch_loss=5.337723\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=5.33772301674\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] Epoch[58] Batch [5]#011Speed: 965.87 samples/sec#011loss=5.337723\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] Epoch[58] Batch[10] avg_epoch_loss=5.298962\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=5.25244865417\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] Epoch[58] Batch [10]#011Speed: 961.95 samples/sec#011loss=5.252449\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1221.073865890503, \"sum\": 1221.073865890503, \"min\": 1221.073865890503}}, \"EndTime\": 1601803140.544596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803139.323126}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=525.732638772 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=58, train loss <loss>=5.29896194285\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:00 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_57d4e82a-3e55-4469-88dd-8eddde92876d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.476009368896484, \"sum\": 18.476009368896484, \"min\": 18.476009368896484}}, \"EndTime\": 1601803140.563485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803140.544647}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] Epoch[59] Batch[0] avg_epoch_loss=5.404199\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=5.40419864655\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] Epoch[59] Batch[5] avg_epoch_loss=5.393890\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=5.39388950666\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] Epoch[59] Batch [5]#011Speed: 909.64 samples/sec#011loss=5.393890\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] Epoch[59] Batch[10] avg_epoch_loss=5.370649\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=5.34276018143\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] Epoch[59] Batch [10]#011Speed: 894.88 samples/sec#011loss=5.342760\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1264.2719745635986, \"sum\": 1264.2719745635986, \"min\": 1264.2719745635986}}, \"EndTime\": 1601803141.827878, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803140.563546}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=512.510249511 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=59, train loss <loss>=5.37064890428\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:01 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:02 INFO 139827261196096] Epoch[60] Batch[0] avg_epoch_loss=5.275341\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=5.27534103394\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:02 INFO 139827261196096] Epoch[60] Batch[5] avg_epoch_loss=5.365048\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=5.36504824956\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:02 INFO 139827261196096] Epoch[60] Batch [5]#011Speed: 930.20 samples/sec#011loss=5.365048\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:03 INFO 139827261196096] Epoch[60] Batch[10] avg_epoch_loss=5.363655\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=5.36198205948\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:03 INFO 139827261196096] Epoch[60] Batch [10]#011Speed: 914.96 samples/sec#011loss=5.361982\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:03 INFO 139827261196096] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1262.341022491455, \"sum\": 1262.341022491455, \"min\": 1262.341022491455}}, \"EndTime\": 1601803143.090621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803141.827939}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:03 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=511.712719332 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:03 INFO 139827261196096] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=60, train loss <loss>=5.3636545268\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:03 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:03 INFO 139827261196096] Epoch[61] Batch[0] avg_epoch_loss=5.353821\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=5.35382080078\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] Epoch[61] Batch[5] avg_epoch_loss=5.339389\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=5.33938916524\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] Epoch[61] Batch [5]#011Speed: 883.90 samples/sec#011loss=5.339389\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] Epoch[61] Batch[10] avg_epoch_loss=5.320082\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=5.29691324234\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] Epoch[61] Batch [10]#011Speed: 974.54 samples/sec#011loss=5.296913\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1265.9001350402832, \"sum\": 1265.9001350402832, \"min\": 1265.9001350402832}}, \"EndTime\": 1601803144.356838, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803143.090679}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=522.124756564 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=61, train loss <loss>=5.32008192756\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] Epoch[62] Batch[0] avg_epoch_loss=5.442485\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=5.44248485565\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] Epoch[62] Batch[5] avg_epoch_loss=5.349332\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=5.34933185577\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] Epoch[62] Batch [5]#011Speed: 1011.63 samples/sec#011loss=5.349332\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] Epoch[62] Batch[10] avg_epoch_loss=5.318788\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=5.28213558197\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] Epoch[62] Batch [10]#011Speed: 1024.58 samples/sec#011loss=5.282136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] processed a total of 717 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1243.602991104126, \"sum\": 1243.602991104126, \"min\": 1243.602991104126}}, \"EndTime\": 1601803145.600812, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803144.356894}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=576.508448882 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=62, train loss <loss>=5.32545801004\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:05 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:06 INFO 139827261196096] Epoch[63] Batch[0] avg_epoch_loss=5.337952\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=5.33795166016\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:06 INFO 139827261196096] Epoch[63] Batch[5] avg_epoch_loss=5.343041\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=5.34304141998\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:06 INFO 139827261196096] Epoch[63] Batch [5]#011Speed: 964.15 samples/sec#011loss=5.343041\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:06 INFO 139827261196096] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1122.3218441009521, \"sum\": 1122.3218441009521, \"min\": 1122.3218441009521}}, \"EndTime\": 1601803146.723573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803145.600876}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:06 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=553.275140371 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:06 INFO 139827261196096] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=63, train loss <loss>=5.33010578156\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:06 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] Epoch[64] Batch[0] avg_epoch_loss=5.287797\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=5.28779697418\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] Epoch[64] Batch[5] avg_epoch_loss=5.335520\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=5.33552018801\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] Epoch[64] Batch [5]#011Speed: 991.99 samples/sec#011loss=5.335520\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] Epoch[64] Batch[10] avg_epoch_loss=5.301024\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=5.25962905884\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] Epoch[64] Batch [10]#011Speed: 927.59 samples/sec#011loss=5.259629\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1205.137014389038, \"sum\": 1205.137014389038, \"min\": 1205.137014389038}}, \"EndTime\": 1601803147.929204, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803146.723628}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=550.931752357 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=64, train loss <loss>=5.30102422021\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:07 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:08 INFO 139827261196096] Epoch[65] Batch[0] avg_epoch_loss=5.230755\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=5.23075485229\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:08 INFO 139827261196096] Epoch[65] Batch[5] avg_epoch_loss=5.290277\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=5.29027660688\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:08 INFO 139827261196096] Epoch[65] Batch [5]#011Speed: 997.08 samples/sec#011loss=5.290277\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1113.6131286621094, \"sum\": 1113.6131286621094, \"min\": 1113.6131286621094}}, \"EndTime\": 1601803149.04321, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803147.929267}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=570.173009669 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=65, train loss <loss>=5.29809484482\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_a1c0df92-b79d-48cd-8174-995dcf01abdd-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.43602752685547, \"sum\": 17.43602752685547, \"min\": 17.43602752685547}}, \"EndTime\": 1601803149.061073, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803149.043266}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] Epoch[66] Batch[0] avg_epoch_loss=5.328309\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=5.32830905914\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] Epoch[66] Batch[5] avg_epoch_loss=5.301238\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=5.30123782158\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:09 INFO 139827261196096] Epoch[66] Batch [5]#011Speed: 949.64 samples/sec#011loss=5.301238\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:10 INFO 139827261196096] processed a total of 579 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1130.807876586914, \"sum\": 1130.807876586914, \"min\": 1130.807876586914}}, \"EndTime\": 1601803150.19199, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803149.061129}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:10 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=511.979815131 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:10 INFO 139827261196096] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=66, train loss <loss>=5.31606354713\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:10 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:10 INFO 139827261196096] Epoch[67] Batch[0] avg_epoch_loss=5.202092\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=5.20209169388\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] Epoch[67] Batch[5] avg_epoch_loss=5.282542\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=5.28254175186\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] Epoch[67] Batch [5]#011Speed: 1009.55 samples/sec#011loss=5.282542\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] Epoch[67] Batch[10] avg_epoch_loss=5.286925\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=5.29218568802\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] Epoch[67] Batch [10]#011Speed: 976.73 samples/sec#011loss=5.292186\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1201.219081878662, \"sum\": 1201.219081878662, \"min\": 1201.219081878662}}, \"EndTime\": 1601803151.393601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803150.192056}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=551.892948599 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=67, train loss <loss>=5.28692535921\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_2ccd97e7-17b6-4ef4-ae1c-2dbc29d72b0e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.90308952331543, \"sum\": 17.90308952331543, \"min\": 17.90308952331543}}, \"EndTime\": 1601803151.411894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803151.393671}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] Epoch[68] Batch[0] avg_epoch_loss=5.260733\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=5.26073312759\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] Epoch[68] Batch[5] avg_epoch_loss=5.313100\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=5.31310002009\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] Epoch[68] Batch [5]#011Speed: 976.43 samples/sec#011loss=5.313100\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] Epoch[68] Batch[10] avg_epoch_loss=5.350351\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=5.39505290985\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] Epoch[68] Batch [10]#011Speed: 958.70 samples/sec#011loss=5.395053\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1201.673984527588, \"sum\": 1201.673984527588, \"min\": 1201.673984527588}}, \"EndTime\": 1601803152.613671, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803151.411944}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=550.027585151 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=68, train loss <loss>=5.35035133362\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:12 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] Epoch[69] Batch[0] avg_epoch_loss=5.413818\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=5.41381788254\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] Epoch[69] Batch[5] avg_epoch_loss=5.315102\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=5.3151020209\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] Epoch[69] Batch [5]#011Speed: 985.49 samples/sec#011loss=5.315102\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] Epoch[69] Batch[10] avg_epoch_loss=5.323935\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=5.33453416824\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] Epoch[69] Batch [10]#011Speed: 984.33 samples/sec#011loss=5.334534\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1185.547113418579, \"sum\": 1185.547113418579, \"min\": 1185.547113418579}}, \"EndTime\": 1601803153.79953, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803152.613727}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=557.509582754 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=69, train loss <loss>=5.32393481515\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:13 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:14 INFO 139827261196096] Epoch[70] Batch[0] avg_epoch_loss=5.239636\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=5.2396364212\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:14 INFO 139827261196096] Epoch[70] Batch[5] avg_epoch_loss=5.286032\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=5.28603212039\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:14 INFO 139827261196096] Epoch[70] Batch [5]#011Speed: 1026.60 samples/sec#011loss=5.286032\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] Epoch[70] Batch[10] avg_epoch_loss=5.276597\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=5.26527576447\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] Epoch[70] Batch [10]#011Speed: 902.19 samples/sec#011loss=5.265276\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1206.7439556121826, \"sum\": 1206.7439556121826, \"min\": 1206.7439556121826}}, \"EndTime\": 1601803155.006601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803153.799585}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=531.140100892 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=70, train loss <loss>=5.27659741315\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_ea8c0546-33c5-4464-adf8-e3ea3b4aee84-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 47.24001884460449, \"sum\": 47.24001884460449, \"min\": 47.24001884460449}}, \"EndTime\": 1601803155.054193, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803155.006658}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] Epoch[71] Batch[0] avg_epoch_loss=5.356277\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=5.35627651215\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] Epoch[71] Batch[5] avg_epoch_loss=5.310786\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=5.31078624725\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:15 INFO 139827261196096] Epoch[71] Batch [5]#011Speed: 971.30 samples/sec#011loss=5.310786\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:16 INFO 139827261196096] Epoch[71] Batch[10] avg_epoch_loss=5.279705\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=71, batch=10 train loss <loss>=5.24240760803\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:16 INFO 139827261196096] Epoch[71] Batch [10]#011Speed: 942.42 samples/sec#011loss=5.242408\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:16 INFO 139827261196096] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1207.914113998413, \"sum\": 1207.914113998413, \"min\": 1207.914113998413}}, \"EndTime\": 1601803156.2622, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803155.054244}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:16 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=536.425665453 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:16 INFO 139827261196096] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=71, train loss <loss>=5.27970504761\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:16 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:16 INFO 139827261196096] Epoch[72] Batch[0] avg_epoch_loss=5.313177\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=5.31317710876\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] Epoch[72] Batch[5] avg_epoch_loss=5.285338\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=5.28533832232\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] Epoch[72] Batch [5]#011Speed: 959.44 samples/sec#011loss=5.285338\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] Epoch[72] Batch[10] avg_epoch_loss=5.278422\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=5.27012166977\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] Epoch[72] Batch [10]#011Speed: 961.37 samples/sec#011loss=5.270122\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1207.6640129089355, \"sum\": 1207.6640129089355, \"min\": 1207.6640129089355}}, \"EndTime\": 1601803157.47018, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803156.262257}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=553.923420488 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=72, train loss <loss>=5.27842166207\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:17 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:18 INFO 139827261196096] Epoch[73] Batch[0] avg_epoch_loss=5.314133\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=5.31413269043\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:18 INFO 139827261196096] Epoch[73] Batch[5] avg_epoch_loss=5.297010\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=5.29700994492\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:18 INFO 139827261196096] Epoch[73] Batch [5]#011Speed: 978.57 samples/sec#011loss=5.297010\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:18 INFO 139827261196096] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1142.5960063934326, \"sum\": 1142.5960063934326, \"min\": 1142.5960063934326}}, \"EndTime\": 1601803158.613091, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803157.470237}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:18 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=525.953263421 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:18 INFO 139827261196096] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=73, train loss <loss>=5.31206727028\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:18 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] Epoch[74] Batch[0] avg_epoch_loss=5.293458\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=5.29345798492\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] Epoch[74] Batch[5] avg_epoch_loss=5.300966\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=5.30096578598\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] Epoch[74] Batch [5]#011Speed: 987.32 samples/sec#011loss=5.300966\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] Epoch[74] Batch[10] avg_epoch_loss=5.294066\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=5.28578567505\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] Epoch[74] Batch [10]#011Speed: 928.88 samples/sec#011loss=5.285786\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1213.3080959320068, \"sum\": 1213.3080959320068, \"min\": 1213.3080959320068}}, \"EndTime\": 1601803159.826839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803158.613153}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=538.158986056 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=74, train loss <loss>=5.29406573556\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:19 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:20 INFO 139827261196096] Epoch[75] Batch[0] avg_epoch_loss=5.425133\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=5.42513275146\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:20 INFO 139827261196096] Epoch[75] Batch[5] avg_epoch_loss=5.324852\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=5.32485206922\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:20 INFO 139827261196096] Epoch[75] Batch [5]#011Speed: 946.86 samples/sec#011loss=5.324852\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:20 INFO 139827261196096] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1160.6199741363525, \"sum\": 1160.6199741363525, \"min\": 1160.6199741363525}}, \"EndTime\": 1601803160.987863, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803159.826896}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:20 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=541.047662105 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:20 INFO 139827261196096] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=75, train loss <loss>=5.32119493484\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:20 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:21 INFO 139827261196096] Epoch[76] Batch[0] avg_epoch_loss=5.331725\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=5.33172512054\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:21 INFO 139827261196096] Epoch[76] Batch[5] avg_epoch_loss=5.314479\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=5.31447863579\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:21 INFO 139827261196096] Epoch[76] Batch [5]#011Speed: 987.86 samples/sec#011loss=5.314479\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:22 INFO 139827261196096] Epoch[76] Batch[10] avg_epoch_loss=5.297368\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=5.27683496475\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:22 INFO 139827261196096] Epoch[76] Batch [10]#011Speed: 978.53 samples/sec#011loss=5.276835\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:22 INFO 139827261196096] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1198.4891891479492, \"sum\": 1198.4891891479492, \"min\": 1198.4891891479492}}, \"EndTime\": 1601803162.186714, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803160.987925}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:22 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.480967537 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:22 INFO 139827261196096] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=76, train loss <loss>=5.29736787623\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:22 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:22 INFO 139827261196096] Epoch[77] Batch[0] avg_epoch_loss=5.369115\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=5.36911487579\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] Epoch[77] Batch[5] avg_epoch_loss=5.323007\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=5.32300678889\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] Epoch[77] Batch [5]#011Speed: 996.67 samples/sec#011loss=5.323007\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] Epoch[77] Batch[10] avg_epoch_loss=5.320453\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=5.31738929749\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] Epoch[77] Batch [10]#011Speed: 1006.46 samples/sec#011loss=5.317389\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1165.2469635009766, \"sum\": 1165.2469635009766, \"min\": 1165.2469635009766}}, \"EndTime\": 1601803163.352296, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803162.186776}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=565.50404122 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=77, train loss <loss>=5.32045338371\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] Epoch[78] Batch[0] avg_epoch_loss=5.288644\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=5.28864383698\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] Epoch[78] Batch[5] avg_epoch_loss=5.345985\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=5.34598533312\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] Epoch[78] Batch [5]#011Speed: 1022.19 samples/sec#011loss=5.345985\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] Epoch[78] Batch[10] avg_epoch_loss=5.313832\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=5.27524747849\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] Epoch[78] Batch [10]#011Speed: 1006.77 samples/sec#011loss=5.275247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1152.4951457977295, \"sum\": 1152.4951457977295, \"min\": 1152.4951457977295}}, \"EndTime\": 1601803164.505129, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803163.352354}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=566.555959409 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=78, train loss <loss>=5.31383176283\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:24 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] Epoch[79] Batch[0] avg_epoch_loss=5.317588\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=5.31758785248\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] Epoch[79] Batch[5] avg_epoch_loss=5.292058\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=5.29205822945\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] Epoch[79] Batch [5]#011Speed: 992.24 samples/sec#011loss=5.292058\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] Epoch[79] Batch[10] avg_epoch_loss=5.262470\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=79, batch=10 train loss <loss>=5.22696456909\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] Epoch[79] Batch [10]#011Speed: 982.58 samples/sec#011loss=5.226965\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1170.3670024871826, \"sum\": 1170.3670024871826, \"min\": 1170.3670024871826}}, \"EndTime\": 1601803165.675826, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803164.505184}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=551.92302509 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=79, train loss <loss>=5.26247020201\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:25 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_08ce8c2b-567f-49e2-9078-7fb5f3ec52fb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.25208282470703, \"sum\": 22.25208282470703, \"min\": 22.25208282470703}}, \"EndTime\": 1601803165.698428, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803165.675884}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:26 INFO 139827261196096] Epoch[80] Batch[0] avg_epoch_loss=5.347889\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=5.34788894653\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:26 INFO 139827261196096] Epoch[80] Batch[5] avg_epoch_loss=5.314451\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=5.31445113818\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:26 INFO 139827261196096] Epoch[80] Batch [5]#011Speed: 1020.71 samples/sec#011loss=5.314451\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:26 INFO 139827261196096] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1086.8799686431885, \"sum\": 1086.8799686431885, \"min\": 1086.8799686431885}}, \"EndTime\": 1601803166.785414, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803165.698482}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:26 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=572.229216567 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:26 INFO 139827261196096] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=80, train loss <loss>=5.32455029488\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:26 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] Epoch[81] Batch[0] avg_epoch_loss=5.285988\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=5.285987854\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] Epoch[81] Batch[5] avg_epoch_loss=5.273890\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=5.2738904953\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] Epoch[81] Batch [5]#011Speed: 1028.84 samples/sec#011loss=5.273890\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] Epoch[81] Batch[10] avg_epoch_loss=5.264342\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=5.25288295746\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] Epoch[81] Batch [10]#011Speed: 999.62 samples/sec#011loss=5.252883\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1151.1950492858887, \"sum\": 1151.1950492858887, \"min\": 1151.1950492858887}}, \"EndTime\": 1601803167.937034, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803166.785482}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=566.323163059 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=81, train loss <loss>=5.26434161446\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:27 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:28 INFO 139827261196096] Epoch[82] Batch[0] avg_epoch_loss=5.346439\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=5.34643936157\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:28 INFO 139827261196096] Epoch[82] Batch[5] avg_epoch_loss=5.282307\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=5.28230683009\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:28 INFO 139827261196096] Epoch[82] Batch [5]#011Speed: 985.96 samples/sec#011loss=5.282307\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:29 INFO 139827261196096] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1106.2378883361816, \"sum\": 1106.2378883361816, \"min\": 1106.2378883361816}}, \"EndTime\": 1601803169.04365, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803167.937094}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:29 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=567.642608082 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:29 INFO 139827261196096] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=82, train loss <loss>=5.27924332619\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:29 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:29 INFO 139827261196096] Epoch[83] Batch[0] avg_epoch_loss=5.239944\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=5.23994398117\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:29 INFO 139827261196096] Epoch[83] Batch[5] avg_epoch_loss=5.269522\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=5.26952179273\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:29 INFO 139827261196096] Epoch[83] Batch [5]#011Speed: 1024.86 samples/sec#011loss=5.269522\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:30 INFO 139827261196096] Epoch[83] Batch[10] avg_epoch_loss=5.266515\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=83, batch=10 train loss <loss>=5.2629070282\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:30 INFO 139827261196096] Epoch[83] Batch [10]#011Speed: 952.11 samples/sec#011loss=5.262907\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:30 INFO 139827261196096] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1206.5129280090332, \"sum\": 1206.5129280090332, \"min\": 1206.5129280090332}}, \"EndTime\": 1601803170.250516, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803169.043712}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:30 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=542.023844842 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:30 INFO 139827261196096] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=83, train loss <loss>=5.26651508158\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:30 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:30 INFO 139827261196096] Epoch[84] Batch[0] avg_epoch_loss=5.295859\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=5.29585886002\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] Epoch[84] Batch[5] avg_epoch_loss=5.280570\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=5.2805703481\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] Epoch[84] Batch [5]#011Speed: 1019.59 samples/sec#011loss=5.280570\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1106.863021850586, \"sum\": 1106.863021850586, \"min\": 1106.863021850586}}, \"EndTime\": 1601803171.357769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803170.250568}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=567.304569045 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=84, train loss <loss>=5.24138894081\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_3aa2460a-485b-4bbb-ba22-1570cd99f7e6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.210960388183594, \"sum\": 17.210960388183594, \"min\": 17.210960388183594}}, \"EndTime\": 1601803171.375572, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803171.357834}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] Epoch[85] Batch[0] avg_epoch_loss=5.272709\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=5.27270936966\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] Epoch[85] Batch[5] avg_epoch_loss=5.267039\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=5.26703929901\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] Epoch[85] Batch [5]#011Speed: 1010.10 samples/sec#011loss=5.267039\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] Epoch[85] Batch[10] avg_epoch_loss=5.208519\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=85, batch=10 train loss <loss>=5.13829517365\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] Epoch[85] Batch [10]#011Speed: 994.44 samples/sec#011loss=5.138295\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1174.562931060791, \"sum\": 1174.562931060791, \"min\": 1174.562931060791}}, \"EndTime\": 1601803172.550231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803171.375615}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=548.244207436 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=85, train loss <loss>=5.20851924203\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:32 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_cf3c8ab7-9cfc-4662-80cd-31a4de97aab3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.80414581298828, \"sum\": 17.80414581298828, \"min\": 17.80414581298828}}, \"EndTime\": 1601803172.568454, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803172.550296}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:33 INFO 139827261196096] Epoch[86] Batch[0] avg_epoch_loss=5.262906\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=5.26290559769\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:33 INFO 139827261196096] Epoch[86] Batch[5] avg_epoch_loss=5.264551\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=5.26455068588\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:33 INFO 139827261196096] Epoch[86] Batch [5]#011Speed: 998.45 samples/sec#011loss=5.264551\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:33 INFO 139827261196096] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1093.3749675750732, \"sum\": 1093.3749675750732, \"min\": 1093.3749675750732}}, \"EndTime\": 1601803173.661918, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803172.5685}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:33 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=551.459016779 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:33 INFO 139827261196096] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=86, train loss <loss>=5.2517768383\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:33 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] Epoch[87] Batch[0] avg_epoch_loss=5.373304\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=5.37330389023\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] Epoch[87] Batch[5] avg_epoch_loss=5.269487\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=5.2694867452\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] Epoch[87] Batch [5]#011Speed: 1015.76 samples/sec#011loss=5.269487\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] Epoch[87] Batch[10] avg_epoch_loss=5.253315\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=5.23390884399\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] Epoch[87] Batch [10]#011Speed: 1000.65 samples/sec#011loss=5.233909\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1175.232172012329, \"sum\": 1175.232172012329, \"min\": 1175.232172012329}}, \"EndTime\": 1601803174.837554, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803173.661981}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=579.421650448 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=87, train loss <loss>=5.25331497192\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:34 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:35 INFO 139827261196096] Epoch[88] Batch[0] avg_epoch_loss=5.193779\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=5.1937789917\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:35 INFO 139827261196096] Epoch[88] Batch[5] avg_epoch_loss=5.216416\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=5.21641588211\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:35 INFO 139827261196096] Epoch[88] Batch [5]#011Speed: 964.18 samples/sec#011loss=5.216416\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] Epoch[88] Batch[10] avg_epoch_loss=5.205822\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=5.19310932159\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] Epoch[88] Batch [10]#011Speed: 964.40 samples/sec#011loss=5.193109\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1203.8099765777588, \"sum\": 1203.8099765777588, \"min\": 1203.8099765777588}}, \"EndTime\": 1601803176.041696, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803174.837606}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=536.590330079 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=88, train loss <loss>=5.20582199097\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_1734e17d-c14c-460b-827c-4ff95fd41275-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.602081298828125, \"sum\": 22.602081298828125, \"min\": 22.602081298828125}}, \"EndTime\": 1601803176.064681, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803176.041755}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] Epoch[89] Batch[0] avg_epoch_loss=5.198617\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=5.19861745834\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] Epoch[89] Batch[5] avg_epoch_loss=5.275078\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=5.27507758141\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:36 INFO 139827261196096] Epoch[89] Batch [5]#011Speed: 985.71 samples/sec#011loss=5.275078\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:37 INFO 139827261196096] Epoch[89] Batch[10] avg_epoch_loss=5.291665\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=5.31157035828\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:37 INFO 139827261196096] Epoch[89] Batch [10]#011Speed: 917.46 samples/sec#011loss=5.311570\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:37 INFO 139827261196096] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1215.8539295196533, \"sum\": 1215.8539295196533, \"min\": 1215.8539295196533}}, \"EndTime\": 1601803177.280644, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803176.064737}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:37 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=539.499881765 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:37 INFO 139827261196096] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=89, train loss <loss>=5.29166520726\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:37 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:37 INFO 139827261196096] Epoch[90] Batch[0] avg_epoch_loss=5.313156\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=5.31315612793\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:38 INFO 139827261196096] Epoch[90] Batch[5] avg_epoch_loss=5.233700\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=5.23370019595\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:38 INFO 139827261196096] Epoch[90] Batch [5]#011Speed: 967.77 samples/sec#011loss=5.233700\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:38 INFO 139827261196096] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1142.6880359649658, \"sum\": 1142.6880359649658, \"min\": 1142.6880359649658}}, \"EndTime\": 1601803178.423666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803177.280703}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:38 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=545.160288577 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:38 INFO 139827261196096] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=90, train loss <loss>=5.25748906136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:38 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:38 INFO 139827261196096] Epoch[91] Batch[0] avg_epoch_loss=5.248650\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=5.24864959717\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] Epoch[91] Batch[5] avg_epoch_loss=5.225856\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=5.22585550944\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] Epoch[91] Batch [5]#011Speed: 983.25 samples/sec#011loss=5.225856\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] Epoch[91] Batch[10] avg_epoch_loss=5.251973\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=5.28331422806\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] Epoch[91] Batch [10]#011Speed: 986.14 samples/sec#011loss=5.283314\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1185.1739883422852, \"sum\": 1185.1739883422852, \"min\": 1185.1739883422852}}, \"EndTime\": 1601803179.60922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803178.423732}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=561.90347207 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=91, train loss <loss>=5.25197310881\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:39 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] Epoch[92] Batch[0] avg_epoch_loss=5.168092\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=5.16809177399\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] Epoch[92] Batch[5] avg_epoch_loss=5.246230\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=5.24622964859\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] Epoch[92] Batch [5]#011Speed: 949.32 samples/sec#011loss=5.246230\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] Epoch[92] Batch[10] avg_epoch_loss=5.230886\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=5.21247386932\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] Epoch[92] Batch [10]#011Speed: 957.91 samples/sec#011loss=5.212474\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1219.9208736419678, \"sum\": 1219.9208736419678, \"min\": 1219.9208736419678}}, \"EndTime\": 1601803180.829458, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803179.609277}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=539.341614625 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=92, train loss <loss>=5.23088611256\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:40 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:41 INFO 139827261196096] Epoch[93] Batch[0] avg_epoch_loss=5.177535\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=5.17753458023\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:41 INFO 139827261196096] Epoch[93] Batch[5] avg_epoch_loss=5.236886\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=5.236885945\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:41 INFO 139827261196096] Epoch[93] Batch [5]#011Speed: 979.14 samples/sec#011loss=5.236886\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] Epoch[93] Batch[10] avg_epoch_loss=5.241262\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=5.24651231766\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] Epoch[93] Batch [10]#011Speed: 967.23 samples/sec#011loss=5.246512\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1214.9229049682617, \"sum\": 1214.9229049682617, \"min\": 1214.9229049682617}}, \"EndTime\": 1601803182.044703, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803180.829517}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=545.673589959 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=93, train loss <loss>=5.24126156894\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] Epoch[94] Batch[0] avg_epoch_loss=5.189839\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=5.1898393631\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] Epoch[94] Batch[5] avg_epoch_loss=5.232822\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=5.23282202085\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:42 INFO 139827261196096] Epoch[94] Batch [5]#011Speed: 975.52 samples/sec#011loss=5.232822\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:43 INFO 139827261196096] Epoch[94] Batch[10] avg_epoch_loss=5.221259\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=5.2073841095\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:43 INFO 139827261196096] Epoch[94] Batch [10]#011Speed: 957.20 samples/sec#011loss=5.207384\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:43 INFO 139827261196096] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1207.0698738098145, \"sum\": 1207.0698738098145, \"min\": 1207.0698738098145}}, \"EndTime\": 1601803183.252186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803182.044766}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:43 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=535.969145156 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:43 INFO 139827261196096] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=94, train loss <loss>=5.22125933387\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:43 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:43 INFO 139827261196096] Epoch[95] Batch[0] avg_epoch_loss=5.202663\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=5.20266294479\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] Epoch[95] Batch[5] avg_epoch_loss=5.220063\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=5.22006344795\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] Epoch[95] Batch [5]#011Speed: 979.26 samples/sec#011loss=5.220063\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] Epoch[95] Batch[10] avg_epoch_loss=5.194376\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=5.16355199814\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] Epoch[95] Batch [10]#011Speed: 946.87 samples/sec#011loss=5.163552\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1211.7209434509277, \"sum\": 1211.7209434509277, \"min\": 1211.7209434509277}}, \"EndTime\": 1601803184.464261, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803183.252243}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=542.163723876 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=95, train loss <loss>=5.19437642531\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:44 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_5c89c88d-d6d5-4b15-b989-e6c2910b1290-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.234968185424805, \"sum\": 18.234968185424805, \"min\": 18.234968185424805}}, \"EndTime\": 1601803184.482896, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803184.464325}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] Epoch[96] Batch[0] avg_epoch_loss=5.293789\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=5.29378938675\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] Epoch[96] Batch[5] avg_epoch_loss=5.250901\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=5.25090114276\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] Epoch[96] Batch [5]#011Speed: 919.72 samples/sec#011loss=5.250901\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] Epoch[96] Batch[10] avg_epoch_loss=5.242325\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=5.23203344345\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] Epoch[96] Batch [10]#011Speed: 968.00 samples/sec#011loss=5.232033\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1221.4679718017578, \"sum\": 1221.4679718017578, \"min\": 1221.4679718017578}}, \"EndTime\": 1601803185.704463, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803184.482944}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=531.291801241 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=96, train loss <loss>=5.2423249158\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:45 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:46 INFO 139827261196096] Epoch[97] Batch[0] avg_epoch_loss=5.303178\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=5.30317783356\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:46 INFO 139827261196096] Epoch[97] Batch[5] avg_epoch_loss=5.281692\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=5.28169210752\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:46 INFO 139827261196096] Epoch[97] Batch [5]#011Speed: 944.12 samples/sec#011loss=5.281692\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:46 INFO 139827261196096] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1154.7329425811768, \"sum\": 1154.7329425811768, \"min\": 1154.7329425811768}}, \"EndTime\": 1601803186.85957, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803185.70452}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:46 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=541.207555319 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:46 INFO 139827261196096] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=97, train loss <loss>=5.20383238792\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:46 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:47 INFO 139827261196096] Epoch[98] Batch[0] avg_epoch_loss=5.222343\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=5.22234296799\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:47 INFO 139827261196096] Epoch[98] Batch[5] avg_epoch_loss=5.223220\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=5.22321995099\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:47 INFO 139827261196096] Epoch[98] Batch [5]#011Speed: 1004.08 samples/sec#011loss=5.223220\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] Epoch[98] Batch[10] avg_epoch_loss=5.269710\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=5.32549886703\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] Epoch[98] Batch [10]#011Speed: 987.30 samples/sec#011loss=5.325499\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1203.042984008789, \"sum\": 1203.042984008789, \"min\": 1203.042984008789}}, \"EndTime\": 1601803188.062979, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803186.859632}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=533.607746036 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=98, train loss <loss>=5.26971036738\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] Epoch[99] Batch[0] avg_epoch_loss=5.181235\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=5.18123483658\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] Epoch[99] Batch[5] avg_epoch_loss=5.229247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=5.22924701373\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:48 INFO 139827261196096] Epoch[99] Batch [5]#011Speed: 986.22 samples/sec#011loss=5.229247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:49 INFO 139827261196096] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1125.1568794250488, \"sum\": 1125.1568794250488, \"min\": 1125.1568794250488}}, \"EndTime\": 1601803189.188476, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803188.063041}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:49 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=558.098741513 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:49 INFO 139827261196096] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=99, train loss <loss>=5.23282341957\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:49 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:49 INFO 139827261196096] Epoch[100] Batch[0] avg_epoch_loss=5.200867\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=5.20086669922\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:50 INFO 139827261196096] Epoch[100] Batch[5] avg_epoch_loss=5.191427\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=5.19142683347\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:50 INFO 139827261196096] Epoch[100] Batch [5]#011Speed: 956.57 samples/sec#011loss=5.191427\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:50 INFO 139827261196096] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1141.8609619140625, \"sum\": 1141.8609619140625, \"min\": 1141.8609619140625}}, \"EndTime\": 1601803190.3307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803189.188538}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:50 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.431273562 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:50 INFO 139827261196096] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=100, train loss <loss>=5.20909738541\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:50 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:50 INFO 139827261196096] Epoch[101] Batch[0] avg_epoch_loss=5.205677\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=5.20567703247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:51 INFO 139827261196096] Epoch[101] Batch[5] avg_epoch_loss=5.195247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=5.19524733226\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:51 INFO 139827261196096] Epoch[101] Batch [5]#011Speed: 978.54 samples/sec#011loss=5.195247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:51 INFO 139827261196096] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1134.0420246124268, \"sum\": 1134.0420246124268, \"min\": 1134.0420246124268}}, \"EndTime\": 1601803191.465131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803190.330765}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:51 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=562.543728977 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:51 INFO 139827261196096] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=101, train loss <loss>=5.19975709915\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:51 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:52 INFO 139827261196096] Epoch[102] Batch[0] avg_epoch_loss=5.188809\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=5.18880939484\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:52 INFO 139827261196096] Epoch[102] Batch[5] avg_epoch_loss=5.215480\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=5.21547969182\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:52 INFO 139827261196096] Epoch[102] Batch [5]#011Speed: 963.18 samples/sec#011loss=5.215480\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:52 INFO 139827261196096] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1151.1650085449219, \"sum\": 1151.1650085449219, \"min\": 1151.1650085449219}}, \"EndTime\": 1601803192.616666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803191.465194}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:52 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=539.410829955 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:52 INFO 139827261196096] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=102, train loss <loss>=5.19933390617\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:52 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:53 INFO 139827261196096] Epoch[103] Batch[0] avg_epoch_loss=5.312083\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=5.31208276749\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:53 INFO 139827261196096] Epoch[103] Batch[5] avg_epoch_loss=5.258646\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=5.25864609083\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:53 INFO 139827261196096] Epoch[103] Batch [5]#011Speed: 953.48 samples/sec#011loss=5.258646\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:53 INFO 139827261196096] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1150.4430770874023, \"sum\": 1150.4430770874023, \"min\": 1150.4430770874023}}, \"EndTime\": 1601803193.767483, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803192.616729}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:53 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=536.267650006 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:53 INFO 139827261196096] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=103, train loss <loss>=5.23472185135\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:53 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] Epoch[104] Batch[0] avg_epoch_loss=5.332114\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=5.33211421967\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] Epoch[104] Batch[5] avg_epoch_loss=5.282151\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=5.28215066592\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] Epoch[104] Batch [5]#011Speed: 980.09 samples/sec#011loss=5.282151\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] Epoch[104] Batch[10] avg_epoch_loss=5.250668\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=5.21288862228\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] Epoch[104] Batch [10]#011Speed: 964.64 samples/sec#011loss=5.212889\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1201.8342018127441, \"sum\": 1201.8342018127441, \"min\": 1201.8342018127441}}, \"EndTime\": 1601803194.969717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803193.76755}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=537.471655551 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=104, train loss <loss>=5.25066791881\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:54 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:55 INFO 139827261196096] Epoch[105] Batch[0] avg_epoch_loss=5.156978\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=5.1569776535\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:55 INFO 139827261196096] Epoch[105] Batch[5] avg_epoch_loss=5.219797\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=5.21979721387\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:55 INFO 139827261196096] Epoch[105] Batch [5]#011Speed: 985.81 samples/sec#011loss=5.219797\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] Epoch[105] Batch[10] avg_epoch_loss=5.207075\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=105, batch=10 train loss <loss>=5.19180870056\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] Epoch[105] Batch [10]#011Speed: 991.77 samples/sec#011loss=5.191809\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] processed a total of 711 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1284.1598987579346, \"sum\": 1284.1598987579346, \"min\": 1284.1598987579346}}, \"EndTime\": 1601803196.25433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803194.969782}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=553.62753399 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=105, train loss <loss>=5.18006487687\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_4633f839-b230-46dd-9745-6cb2e9c37312-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.265962600708008, \"sum\": 18.265962600708008, \"min\": 18.265962600708008}}, \"EndTime\": 1601803196.273063, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803196.254392}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] Epoch[106] Batch[0] avg_epoch_loss=5.249408\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=5.24940824509\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] Epoch[106] Batch[5] avg_epoch_loss=5.208982\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=5.20898230871\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] Epoch[106] Batch [5]#011Speed: 991.93 samples/sec#011loss=5.208982\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] Epoch[106] Batch[10] avg_epoch_loss=5.201499\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=106, batch=10 train loss <loss>=5.19251890182\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] Epoch[106] Batch [10]#011Speed: 959.83 samples/sec#011loss=5.192519\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1211.210012435913, \"sum\": 1211.210012435913, \"min\": 1211.210012435913}}, \"EndTime\": 1601803197.484383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803196.273118}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=564.685844058 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=106, train loss <loss>=5.20149894194\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:57 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] Epoch[107] Batch[0] avg_epoch_loss=5.266799\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=5.26679897308\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] Epoch[107] Batch[5] avg_epoch_loss=5.202228\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=5.20222798983\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] Epoch[107] Batch [5]#011Speed: 987.92 samples/sec#011loss=5.202228\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] Epoch[107] Batch[10] avg_epoch_loss=5.239867\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=5.28503274918\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] Epoch[107] Batch [10]#011Speed: 962.76 samples/sec#011loss=5.285033\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1203.3600807189941, \"sum\": 1203.3600807189941, \"min\": 1203.3600807189941}}, \"EndTime\": 1601803198.688132, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803197.484436}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=553.408965585 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=107, train loss <loss>=5.23986651681\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:58 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] Epoch[108] Batch[0] avg_epoch_loss=5.262819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=5.26281929016\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] Epoch[108] Batch[5] avg_epoch_loss=5.195999\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=5.19599906603\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] Epoch[108] Batch [5]#011Speed: 977.39 samples/sec#011loss=5.195999\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] Epoch[108] Batch[10] avg_epoch_loss=5.188441\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=5.1793718338\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] Epoch[108] Batch [10]#011Speed: 969.74 samples/sec#011loss=5.179372\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1201.3859748840332, \"sum\": 1201.3859748840332, \"min\": 1201.3859748840332}}, \"EndTime\": 1601803199.889908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803198.688196}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=533.51082917 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=108, train loss <loss>=5.1884412332\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:19:59 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:00 INFO 139827261196096] Epoch[109] Batch[0] avg_epoch_loss=5.218597\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=5.21859693527\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:00 INFO 139827261196096] Epoch[109] Batch[5] avg_epoch_loss=5.249104\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=5.24910442034\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:00 INFO 139827261196096] Epoch[109] Batch [5]#011Speed: 928.39 samples/sec#011loss=5.249104\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:01 INFO 139827261196096] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1148.3409404754639, \"sum\": 1148.3409404754639, \"min\": 1148.3409404754639}}, \"EndTime\": 1601803201.038696, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803199.889967}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:01 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=528.547728979 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:01 INFO 139827261196096] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=109, train loss <loss>=5.24658575058\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:01 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:01 INFO 139827261196096] Epoch[110] Batch[0] avg_epoch_loss=5.257977\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=5.25797653198\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:01 INFO 139827261196096] Epoch[110] Batch[5] avg_epoch_loss=5.250575\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=5.25057530403\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:01 INFO 139827261196096] Epoch[110] Batch [5]#011Speed: 967.34 samples/sec#011loss=5.250575\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:02 INFO 139827261196096] Epoch[110] Batch[10] avg_epoch_loss=5.233060\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=5.21204156876\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:02 INFO 139827261196096] Epoch[110] Batch [10]#011Speed: 931.75 samples/sec#011loss=5.212042\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:02 INFO 139827261196096] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1232.4450016021729, \"sum\": 1232.4450016021729, \"min\": 1232.4450016021729}}, \"EndTime\": 1601803202.271543, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803201.038756}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:02 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=543.596002645 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:02 INFO 139827261196096] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=110, train loss <loss>=5.23305996982\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:02 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:02 INFO 139827261196096] Epoch[111] Batch[0] avg_epoch_loss=5.213213\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=5.21321296692\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:03 INFO 139827261196096] Epoch[111] Batch[5] avg_epoch_loss=5.226684\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=5.22668377558\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:03 INFO 139827261196096] Epoch[111] Batch [5]#011Speed: 952.10 samples/sec#011loss=5.226684\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:03 INFO 139827261196096] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1168.3390140533447, \"sum\": 1168.3390140533447, \"min\": 1168.3390140533447}}, \"EndTime\": 1601803203.440314, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803202.271605}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:03 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.88487211 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:03 INFO 139827261196096] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=111, train loss <loss>=5.23279352188\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:03 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] Epoch[112] Batch[0] avg_epoch_loss=5.242986\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=5.2429857254\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] Epoch[112] Batch[5] avg_epoch_loss=5.222996\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=5.22299639384\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] Epoch[112] Batch [5]#011Speed: 944.21 samples/sec#011loss=5.222996\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] Epoch[112] Batch[10] avg_epoch_loss=5.173775\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=112, batch=10 train loss <loss>=5.11470870972\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] Epoch[112] Batch [10]#011Speed: 966.97 samples/sec#011loss=5.114709\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1254.122018814087, \"sum\": 1254.122018814087, \"min\": 1254.122018814087}}, \"EndTime\": 1601803204.694801, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803203.440378}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=529.418133472 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=112, train loss <loss>=5.17377471924\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:04 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_f5a70033-65cd-43ff-b7d8-1a08c2005b40-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.28081703186035, \"sum\": 17.28081703186035, \"min\": 17.28081703186035}}, \"EndTime\": 1601803204.712468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803204.694859}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:05 INFO 139827261196096] Epoch[113] Batch[0] avg_epoch_loss=5.219513\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=5.21951293945\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:05 INFO 139827261196096] Epoch[113] Batch[5] avg_epoch_loss=5.193513\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=5.19351275762\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:05 INFO 139827261196096] Epoch[113] Batch [5]#011Speed: 961.04 samples/sec#011loss=5.193513\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:05 INFO 139827261196096] processed a total of 581 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1121.5779781341553, \"sum\": 1121.5779781341553, \"min\": 1121.5779781341553}}, \"EndTime\": 1601803205.834146, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803204.712512}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:05 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=517.976333562 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:05 INFO 139827261196096] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=113, train loss <loss>=5.17856507301\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:05 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:06 INFO 139827261196096] Epoch[114] Batch[0] avg_epoch_loss=5.106819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=5.10681867599\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:06 INFO 139827261196096] Epoch[114] Batch[5] avg_epoch_loss=5.197822\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=5.19782249133\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:06 INFO 139827261196096] Epoch[114] Batch [5]#011Speed: 992.62 samples/sec#011loss=5.197822\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] Epoch[114] Batch[10] avg_epoch_loss=5.183940\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=5.16728067398\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] Epoch[114] Batch [10]#011Speed: 994.18 samples/sec#011loss=5.167281\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1194.0770149230957, \"sum\": 1194.0770149230957, \"min\": 1194.0770149230957}}, \"EndTime\": 1601803207.028586, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803205.83421}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.822444058 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=114, train loss <loss>=5.18393984708\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] Epoch[115] Batch[0] avg_epoch_loss=5.220509\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=5.22050905228\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] Epoch[115] Batch[5] avg_epoch_loss=5.209348\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=5.20934812228\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:07 INFO 139827261196096] Epoch[115] Batch [5]#011Speed: 1012.65 samples/sec#011loss=5.209348\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:08 INFO 139827261196096] Epoch[115] Batch[10] avg_epoch_loss=5.250009\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=115, batch=10 train loss <loss>=5.29880199432\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:08 INFO 139827261196096] Epoch[115] Batch [10]#011Speed: 980.59 samples/sec#011loss=5.298802\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:08 INFO 139827261196096] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1172.4460124969482, \"sum\": 1172.4460124969482, \"min\": 1172.4460124969482}}, \"EndTime\": 1601803208.201421, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803207.028652}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:08 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=556.907831495 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:08 INFO 139827261196096] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=115, train loss <loss>=5.25000897321\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:08 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:08 INFO 139827261196096] Epoch[116] Batch[0] avg_epoch_loss=5.243562\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=5.24356174469\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] Epoch[116] Batch[5] avg_epoch_loss=5.206258\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=5.20625797908\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] Epoch[116] Batch [5]#011Speed: 998.76 samples/sec#011loss=5.206258\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] Epoch[116] Batch[10] avg_epoch_loss=5.185219\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=5.15997142792\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] Epoch[116] Batch [10]#011Speed: 977.31 samples/sec#011loss=5.159971\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1179.8410415649414, \"sum\": 1179.8410415649414, \"min\": 1179.8410415649414}}, \"EndTime\": 1601803209.381666, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803208.20149}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=572.070275718 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=116, train loss <loss>=5.18521863764\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] Epoch[117] Batch[0] avg_epoch_loss=5.227920\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=5.22792005539\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] Epoch[117] Batch[5] avg_epoch_loss=5.174774\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=5.1747739315\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] Epoch[117] Batch [5]#011Speed: 967.95 samples/sec#011loss=5.174774\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] Epoch[117] Batch[10] avg_epoch_loss=5.157366\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=117, batch=10 train loss <loss>=5.13647689819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] Epoch[117] Batch [10]#011Speed: 964.18 samples/sec#011loss=5.136477\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1194.6330070495605, \"sum\": 1194.6330070495605, \"min\": 1194.6330070495605}}, \"EndTime\": 1601803210.576697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803209.381722}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=548.247022654 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=117, train loss <loss>=5.15736618909\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:10 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_cd523fb2-bbfd-4027-9a7e-0e4bea4c39b1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.95196533203125, \"sum\": 17.95196533203125, \"min\": 17.95196533203125}}, \"EndTime\": 1601803210.595044, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803210.576753}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:11 INFO 139827261196096] Epoch[118] Batch[0] avg_epoch_loss=5.176131\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=5.17613077164\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:11 INFO 139827261196096] Epoch[118] Batch[5] avg_epoch_loss=5.192000\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=5.19199999173\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:11 INFO 139827261196096] Epoch[118] Batch [5]#011Speed: 1008.85 samples/sec#011loss=5.192000\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:11 INFO 139827261196096] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1103.8119792938232, \"sum\": 1103.8119792938232, \"min\": 1103.8119792938232}}, \"EndTime\": 1601803211.698953, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803210.595096}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:11 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=563.454788645 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:11 INFO 139827261196096] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=118, train loss <loss>=5.20154218674\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:11 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] Epoch[119] Batch[0] avg_epoch_loss=5.263444\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=5.26344442368\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] Epoch[119] Batch[5] avg_epoch_loss=5.213079\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=5.21307929357\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] Epoch[119] Batch [5]#011Speed: 1005.22 samples/sec#011loss=5.213079\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] Epoch[119] Batch[10] avg_epoch_loss=5.228494\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=119, batch=10 train loss <loss>=5.24699068069\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] Epoch[119] Batch [10]#011Speed: 965.57 samples/sec#011loss=5.246991\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1174.1411685943604, \"sum\": 1174.1411685943604, \"min\": 1174.1411685943604}}, \"EndTime\": 1601803212.873515, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803211.699018}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=548.445468683 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=119, train loss <loss>=5.22849356044\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:12 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:13 INFO 139827261196096] Epoch[120] Batch[0] avg_epoch_loss=5.303963\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=5.30396318436\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:13 INFO 139827261196096] Epoch[120] Batch[5] avg_epoch_loss=5.230592\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=5.23059177399\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:13 INFO 139827261196096] Epoch[120] Batch [5]#011Speed: 931.39 samples/sec#011loss=5.230592\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:14 INFO 139827261196096] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1133.5289478302002, \"sum\": 1133.5289478302002, \"min\": 1133.5289478302002}}, \"EndTime\": 1601803214.007413, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803212.873573}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:14 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=545.15621378 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:14 INFO 139827261196096] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=120, train loss <loss>=5.19816112518\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:14 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:14 INFO 139827261196096] Epoch[121] Batch[0] avg_epoch_loss=5.264441\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=5.26444149017\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:14 INFO 139827261196096] Epoch[121] Batch[5] avg_epoch_loss=5.249961\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=5.24996058146\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:14 INFO 139827261196096] Epoch[121] Batch [5]#011Speed: 940.99 samples/sec#011loss=5.249961\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:15 INFO 139827261196096] processed a total of 599 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1143.913984298706, \"sum\": 1143.913984298706, \"min\": 1143.913984298706}}, \"EndTime\": 1601803215.151686, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803214.007475}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:15 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=523.599082593 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:15 INFO 139827261196096] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=121, train loss <loss>=5.23446507454\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:15 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:15 INFO 139827261196096] Epoch[122] Batch[0] avg_epoch_loss=5.107695\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=5.10769510269\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] Epoch[122] Batch[5] avg_epoch_loss=5.192971\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=5.1929713885\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] Epoch[122] Batch [5]#011Speed: 976.52 samples/sec#011loss=5.192971\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] Epoch[122] Batch[10] avg_epoch_loss=5.208422\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=5.22696170807\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] Epoch[122] Batch [10]#011Speed: 956.68 samples/sec#011loss=5.226962\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1236.2611293792725, \"sum\": 1236.2611293792725, \"min\": 1236.2611293792725}}, \"EndTime\": 1601803216.388315, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803215.151747}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=563.75401647 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=122, train loss <loss>=5.20842153376\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] Epoch[123] Batch[0] avg_epoch_loss=5.192874\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=5.19287395477\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] Epoch[123] Batch[5] avg_epoch_loss=5.219329\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=5.21932888031\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] Epoch[123] Batch [5]#011Speed: 986.28 samples/sec#011loss=5.219329\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] Epoch[123] Batch[10] avg_epoch_loss=5.276633\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=5.34539766312\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] Epoch[123] Batch [10]#011Speed: 949.62 samples/sec#011loss=5.345398\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1221.587896347046, \"sum\": 1221.587896347046, \"min\": 1221.587896347046}}, \"EndTime\": 1601803217.610293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803216.38838}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=538.603453609 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=123, train loss <loss>=5.27663287249\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:17 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:18 INFO 139827261196096] Epoch[124] Batch[0] avg_epoch_loss=5.251513\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=5.25151252747\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:18 INFO 139827261196096] Epoch[124] Batch[5] avg_epoch_loss=5.202653\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=5.20265301069\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:18 INFO 139827261196096] Epoch[124] Batch [5]#011Speed: 985.90 samples/sec#011loss=5.202653\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:18 INFO 139827261196096] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1125.8339881896973, \"sum\": 1125.8339881896973, \"min\": 1125.8339881896973}}, \"EndTime\": 1601803218.736466, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803217.610353}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:18 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=555.093702131 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:18 INFO 139827261196096] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=124, train loss <loss>=5.20703163147\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:18 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] Epoch[125] Batch[0] avg_epoch_loss=5.210103\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=5.21010255814\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] Epoch[125] Batch[5] avg_epoch_loss=5.190976\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=5.19097598394\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] Epoch[125] Batch [5]#011Speed: 987.18 samples/sec#011loss=5.190976\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] Epoch[125] Batch[10] avg_epoch_loss=5.195241\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=5.20035982132\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] Epoch[125] Batch [10]#011Speed: 976.18 samples/sec#011loss=5.200360\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1220.6621170043945, \"sum\": 1220.6621170043945, \"min\": 1220.6621170043945}}, \"EndTime\": 1601803219.957507, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803218.736538}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=531.643874619 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=125, train loss <loss>=5.19524136457\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:19 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:20 INFO 139827261196096] Epoch[126] Batch[0] avg_epoch_loss=5.191981\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=5.19198131561\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:20 INFO 139827261196096] Epoch[126] Batch[5] avg_epoch_loss=5.216408\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=5.21640825272\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:20 INFO 139827261196096] Epoch[126] Batch [5]#011Speed: 980.00 samples/sec#011loss=5.216408\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:21 INFO 139827261196096] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1106.3711643218994, \"sum\": 1106.3711643218994, \"min\": 1106.3711643218994}}, \"EndTime\": 1601803221.064255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803219.957559}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:21 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=577.511714599 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:21 INFO 139827261196096] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=126, train loss <loss>=5.21289138794\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:21 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:21 INFO 139827261196096] Epoch[127] Batch[0] avg_epoch_loss=5.210832\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=5.21083211899\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:21 INFO 139827261196096] Epoch[127] Batch[5] avg_epoch_loss=5.207988\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=5.20798802376\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:21 INFO 139827261196096] Epoch[127] Batch [5]#011Speed: 973.49 samples/sec#011loss=5.207988\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:22 INFO 139827261196096] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1105.0198078155518, \"sum\": 1105.0198078155518, \"min\": 1105.0198078155518}}, \"EndTime\": 1601803222.169708, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803221.064322}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:22 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=561.933470545 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:22 INFO 139827261196096] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=127, train loss <loss>=5.16896224022\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:22 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:22 INFO 139827261196096] Epoch[128] Batch[0] avg_epoch_loss=5.123214\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=5.12321376801\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:23 INFO 139827261196096] Epoch[128] Batch[5] avg_epoch_loss=5.189755\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=5.18975543976\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:23 INFO 139827261196096] Epoch[128] Batch [5]#011Speed: 982.74 samples/sec#011loss=5.189755\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:23 INFO 139827261196096] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1108.963966369629, \"sum\": 1108.963966369629, \"min\": 1108.963966369629}}, \"EndTime\": 1601803223.2791, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803222.169767}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:23 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=567.149976245 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:23 INFO 139827261196096] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=128, train loss <loss>=5.18919358253\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:23 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:23 INFO 139827261196096] Epoch[129] Batch[0] avg_epoch_loss=5.233891\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=5.23389053345\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:24 INFO 139827261196096] Epoch[129] Batch[5] avg_epoch_loss=5.222389\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=5.22238914172\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:24 INFO 139827261196096] Epoch[129] Batch [5]#011Speed: 1005.36 samples/sec#011loss=5.222389\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:24 INFO 139827261196096] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1132.025957107544, \"sum\": 1132.025957107544, \"min\": 1132.025957107544}}, \"EndTime\": 1601803224.411504, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803223.279161}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:24 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=549.410270428 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:24 INFO 139827261196096] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=129, train loss <loss>=5.197600317\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:24 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:24 INFO 139827261196096] Epoch[130] Batch[0] avg_epoch_loss=5.215654\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=5.21565437317\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] Epoch[130] Batch[5] avg_epoch_loss=5.180056\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=5.18005633354\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] Epoch[130] Batch [5]#011Speed: 1006.68 samples/sec#011loss=5.180056\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] Epoch[130] Batch[10] avg_epoch_loss=5.169532\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=5.15690355301\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] Epoch[130] Batch [10]#011Speed: 922.62 samples/sec#011loss=5.156904\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1198.518991470337, \"sum\": 1198.518991470337, \"min\": 1198.518991470337}}, \"EndTime\": 1601803225.610413, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803224.411571}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=553.143000815 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=130, train loss <loss>=5.16953234239\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:25 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:26 INFO 139827261196096] Epoch[131] Batch[0] avg_epoch_loss=5.119279\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=5.11927890778\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:26 INFO 139827261196096] Epoch[131] Batch[5] avg_epoch_loss=5.187343\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=5.18734288216\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:26 INFO 139827261196096] Epoch[131] Batch [5]#011Speed: 1005.65 samples/sec#011loss=5.187343\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:26 INFO 139827261196096] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1132.779836654663, \"sum\": 1132.779836654663, \"min\": 1132.779836654663}}, \"EndTime\": 1601803226.743509, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803225.610471}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:26 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=554.337879678 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:26 INFO 139827261196096] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=131, train loss <loss>=5.19170928001\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:26 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] Epoch[132] Batch[0] avg_epoch_loss=5.153923\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=5.15392255783\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] Epoch[132] Batch[5] avg_epoch_loss=5.131034\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=5.13103397687\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] Epoch[132] Batch [5]#011Speed: 986.25 samples/sec#011loss=5.131034\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1170.954942703247, \"sum\": 1170.954942703247, \"min\": 1170.954942703247}}, \"EndTime\": 1601803227.914916, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803226.743579}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=519.192674686 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=132, train loss <loss>=5.1551428318\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:27 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_35966fba-7ef4-4fb9-a83f-6bd4d9aa72ab-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.420883178710938, \"sum\": 22.420883178710938, \"min\": 22.420883178710938}}, \"EndTime\": 1601803227.937736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803227.91498}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:28 INFO 139827261196096] Epoch[133] Batch[0] avg_epoch_loss=5.135927\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=5.13592720032\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:28 INFO 139827261196096] Epoch[133] Batch[5] avg_epoch_loss=5.177447\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=5.17744700114\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:28 INFO 139827261196096] Epoch[133] Batch [5]#011Speed: 975.32 samples/sec#011loss=5.177447\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:29 INFO 139827261196096] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1110.1257801055908, \"sum\": 1110.1257801055908, \"min\": 1110.1257801055908}}, \"EndTime\": 1601803229.047975, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803227.937796}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:29 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=550.346359693 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:29 INFO 139827261196096] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=133, train loss <loss>=5.21253547668\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:29 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:29 INFO 139827261196096] Epoch[134] Batch[0] avg_epoch_loss=5.192340\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=5.19233989716\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:29 INFO 139827261196096] Epoch[134] Batch[5] avg_epoch_loss=5.191199\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=5.19119906425\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:29 INFO 139827261196096] Epoch[134] Batch [5]#011Speed: 1003.83 samples/sec#011loss=5.191199\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:30 INFO 139827261196096] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1094.0420627593994, \"sum\": 1094.0420627593994, \"min\": 1094.0420627593994}}, \"EndTime\": 1601803230.142407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803229.048033}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:30 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=584.932728547 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:30 INFO 139827261196096] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=134, train loss <loss>=5.18371844292\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:30 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:30 INFO 139827261196096] Epoch[135] Batch[0] avg_epoch_loss=5.136620\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=5.13661956787\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] Epoch[135] Batch[5] avg_epoch_loss=5.158978\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=5.15897750854\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] Epoch[135] Batch [5]#011Speed: 946.84 samples/sec#011loss=5.158978\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1138.9708518981934, \"sum\": 1138.9708518981934, \"min\": 1138.9708518981934}}, \"EndTime\": 1601803231.28179, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803230.142473}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=548.698039419 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=135, train loss <loss>=5.14906253815\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_ffb0a3b2-df89-42c1-9a51-5e61e5a36463-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.130136489868164, \"sum\": 17.130136489868164, \"min\": 17.130136489868164}}, \"EndTime\": 1601803231.299402, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803231.281851}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] Epoch[136] Batch[0] avg_epoch_loss=5.186528\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=5.18652772903\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] Epoch[136] Batch[5] avg_epoch_loss=5.118250\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=5.11825021108\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] Epoch[136] Batch [5]#011Speed: 989.53 samples/sec#011loss=5.118250\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] processed a total of 597 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1110.8078956604004, \"sum\": 1110.8078956604004, \"min\": 1110.8078956604004}}, \"EndTime\": 1601803232.410307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803231.299448}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=537.403065258 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=136, train loss <loss>=5.12808799744\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_6dd69f35-2445-4279-98c8-51392196a4bf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.372961044311523, \"sum\": 22.372961044311523, \"min\": 22.372961044311523}}, \"EndTime\": 1601803232.433081, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803232.410369}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] Epoch[137] Batch[0] avg_epoch_loss=5.219372\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=5.21937179565\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] Epoch[137] Batch[5] avg_epoch_loss=5.187912\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=5.18791246414\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] Epoch[137] Batch [5]#011Speed: 969.34 samples/sec#011loss=5.187912\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] Epoch[137] Batch[10] avg_epoch_loss=5.169715\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=5.14787807465\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] Epoch[137] Batch [10]#011Speed: 984.41 samples/sec#011loss=5.147878\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1186.643123626709, \"sum\": 1186.643123626709, \"min\": 1186.643123626709}}, \"EndTime\": 1601803233.619831, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803232.433135}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=552.779973569 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=137, train loss <loss>=5.16971501437\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:33 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] Epoch[138] Batch[0] avg_epoch_loss=5.222256\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=5.22225618362\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] Epoch[138] Batch[5] avg_epoch_loss=5.181422\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=5.181422472\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] Epoch[138] Batch [5]#011Speed: 944.09 samples/sec#011loss=5.181422\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] Epoch[138] Batch[10] avg_epoch_loss=5.195077\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=138, batch=10 train loss <loss>=5.21146268845\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] Epoch[138] Batch [10]#011Speed: 985.41 samples/sec#011loss=5.211463\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1199.7549533843994, \"sum\": 1199.7549533843994, \"min\": 1199.7549533843994}}, \"EndTime\": 1601803234.819901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803233.619888}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=534.237018485 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=138, train loss <loss>=5.19507711584\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:34 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:35 INFO 139827261196096] Epoch[139] Batch[0] avg_epoch_loss=5.199859\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=5.19985866547\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:35 INFO 139827261196096] Epoch[139] Batch[5] avg_epoch_loss=5.183334\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=5.18333403269\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:35 INFO 139827261196096] Epoch[139] Batch [5]#011Speed: 930.48 samples/sec#011loss=5.183334\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:35 INFO 139827261196096] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1143.1488990783691, \"sum\": 1143.1488990783691, \"min\": 1143.1488990783691}}, \"EndTime\": 1601803235.963367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803234.81996}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:35 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=530.070558087 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:35 INFO 139827261196096] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=139, train loss <loss>=5.19656052589\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:35 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:36 INFO 139827261196096] Epoch[140] Batch[0] avg_epoch_loss=5.172106\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=5.17210626602\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:36 INFO 139827261196096] Epoch[140] Batch[5] avg_epoch_loss=5.156215\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=5.15621542931\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:36 INFO 139827261196096] Epoch[140] Batch [5]#011Speed: 979.37 samples/sec#011loss=5.156215\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:37 INFO 139827261196096] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1117.767095565796, \"sum\": 1117.767095565796, \"min\": 1117.767095565796}}, \"EndTime\": 1601803237.081495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803235.963433}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:37 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=560.898598494 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:37 INFO 139827261196096] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=140, train loss <loss>=5.16050753593\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:37 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:37 INFO 139827261196096] Epoch[141] Batch[0] avg_epoch_loss=5.192921\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=5.19292116165\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:37 INFO 139827261196096] Epoch[141] Batch[5] avg_epoch_loss=5.156741\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=5.15674058596\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:37 INFO 139827261196096] Epoch[141] Batch [5]#011Speed: 961.24 samples/sec#011loss=5.156741\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:38 INFO 139827261196096] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1127.701997756958, \"sum\": 1127.701997756958, \"min\": 1127.701997756958}}, \"EndTime\": 1601803238.209601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803237.081552}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:38 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=561.273650335 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:38 INFO 139827261196096] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=141, train loss <loss>=5.17210421562\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:38 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:38 INFO 139827261196096] Epoch[142] Batch[0] avg_epoch_loss=5.099701\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=5.09970140457\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:39 INFO 139827261196096] Epoch[142] Batch[5] avg_epoch_loss=5.137929\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=5.13792896271\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:39 INFO 139827261196096] Epoch[142] Batch [5]#011Speed: 958.94 samples/sec#011loss=5.137929\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:39 INFO 139827261196096] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1135.2479457855225, \"sum\": 1135.2479457855225, \"min\": 1135.2479457855225}}, \"EndTime\": 1601803239.345221, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803238.209662}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:39 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.091014032 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:39 INFO 139827261196096] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=142, train loss <loss>=5.14808821678\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:39 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:39 INFO 139827261196096] Epoch[143] Batch[0] avg_epoch_loss=5.160913\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=5.16091346741\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] Epoch[143] Batch[5] avg_epoch_loss=5.163390\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=5.16338992119\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] Epoch[143] Batch [5]#011Speed: 983.12 samples/sec#011loss=5.163390\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] Epoch[143] Batch[10] avg_epoch_loss=5.181010\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=143, batch=10 train loss <loss>=5.20215330124\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] Epoch[143] Batch [10]#011Speed: 922.97 samples/sec#011loss=5.202153\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1223.066806793213, \"sum\": 1223.066806793213, \"min\": 1223.066806793213}}, \"EndTime\": 1601803240.568742, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803239.34528}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=528.144538399 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=143, train loss <loss>=5.18100963939\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:40 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] Epoch[144] Batch[0] avg_epoch_loss=5.146319\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=5.14631891251\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] Epoch[144] Batch[5] avg_epoch_loss=5.185567\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=5.1855665048\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] Epoch[144] Batch [5]#011Speed: 982.10 samples/sec#011loss=5.185567\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] Epoch[144] Batch[10] avg_epoch_loss=5.180626\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=5.17469797134\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] Epoch[144] Batch [10]#011Speed: 961.10 samples/sec#011loss=5.174698\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] processed a total of 718 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1289.504051208496, \"sum\": 1289.504051208496, \"min\": 1289.504051208496}}, \"EndTime\": 1601803241.858607, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803240.568798}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=556.763478659 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=144, train loss <loss>=5.17723699411\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:41 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:42 INFO 139827261196096] Epoch[145] Batch[0] avg_epoch_loss=5.188483\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=5.18848276138\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:42 INFO 139827261196096] Epoch[145] Batch[5] avg_epoch_loss=5.167216\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=5.16721630096\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:42 INFO 139827261196096] Epoch[145] Batch [5]#011Speed: 967.13 samples/sec#011loss=5.167216\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] Epoch[145] Batch[10] avg_epoch_loss=5.148443\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=145, batch=10 train loss <loss>=5.12591609955\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] Epoch[145] Batch [10]#011Speed: 968.72 samples/sec#011loss=5.125916\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1239.4521236419678, \"sum\": 1239.4521236419678, \"min\": 1239.4521236419678}}, \"EndTime\": 1601803243.098421, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803241.858668}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=530.039574792 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=145, train loss <loss>=5.14844348214\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] Epoch[146] Batch[0] avg_epoch_loss=5.169546\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=5.16954565048\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] Epoch[146] Batch[5] avg_epoch_loss=5.166819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=5.16681869825\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:43 INFO 139827261196096] Epoch[146] Batch [5]#011Speed: 999.70 samples/sec#011loss=5.166819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:44 INFO 139827261196096] Epoch[146] Batch[10] avg_epoch_loss=5.164017\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=146, batch=10 train loss <loss>=5.1606546402\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:44 INFO 139827261196096] Epoch[146] Batch [10]#011Speed: 997.53 samples/sec#011loss=5.160655\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:44 INFO 139827261196096] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1165.0030612945557, \"sum\": 1165.0030612945557, \"min\": 1165.0030612945557}}, \"EndTime\": 1601803244.263777, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803243.098472}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:44 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=563.905470665 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:44 INFO 139827261196096] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=146, train loss <loss>=5.16401685368\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:44 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:44 INFO 139827261196096] Epoch[147] Batch[0] avg_epoch_loss=5.176841\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=5.176841259\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] Epoch[147] Batch[5] avg_epoch_loss=5.161485\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=5.16148487727\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] Epoch[147] Batch [5]#011Speed: 1000.78 samples/sec#011loss=5.161485\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] Epoch[147] Batch[10] avg_epoch_loss=5.136674\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=5.10690193176\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] Epoch[147] Batch [10]#011Speed: 984.10 samples/sec#011loss=5.106902\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1171.2348461151123, \"sum\": 1171.2348461151123, \"min\": 1171.2348461151123}}, \"EndTime\": 1601803245.435444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803244.263835}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=547.21690034 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=147, train loss <loss>=5.13667444749\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] Epoch[148] Batch[0] avg_epoch_loss=5.235529\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=5.23552894592\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] Epoch[148] Batch[5] avg_epoch_loss=5.197118\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=5.19711820285\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] Epoch[148] Batch [5]#011Speed: 1021.16 samples/sec#011loss=5.197118\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] Epoch[148] Batch[10] avg_epoch_loss=5.194512\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=148, batch=10 train loss <loss>=5.19138422012\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] Epoch[148] Batch [10]#011Speed: 999.68 samples/sec#011loss=5.191384\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1180.408000946045, \"sum\": 1180.408000946045, \"min\": 1180.408000946045}}, \"EndTime\": 1601803246.616444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803245.435508}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=543.839210205 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=148, train loss <loss>=5.19451184706\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:46 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:47 INFO 139827261196096] Epoch[149] Batch[0] avg_epoch_loss=5.238458\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=5.23845767975\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:47 INFO 139827261196096] Epoch[149] Batch[5] avg_epoch_loss=5.183008\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=5.18300771713\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:47 INFO 139827261196096] Epoch[149] Batch [5]#011Speed: 989.70 samples/sec#011loss=5.183008\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:47 INFO 139827261196096] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1155.311107635498, \"sum\": 1155.311107635498, \"min\": 1155.311107635498}}, \"EndTime\": 1601803247.772097, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803246.616505}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:47 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=548.727242487 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:47 INFO 139827261196096] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=149, train loss <loss>=5.18152542114\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:47 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] Epoch[150] Batch[0] avg_epoch_loss=5.152100\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=5.15209960938\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] Epoch[150] Batch[5] avg_epoch_loss=5.156650\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=5.15664990743\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] Epoch[150] Batch [5]#011Speed: 982.73 samples/sec#011loss=5.156650\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] Epoch[150] Batch[10] avg_epoch_loss=5.155604\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=150, batch=10 train loss <loss>=5.15434789658\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] Epoch[150] Batch [10]#011Speed: 988.30 samples/sec#011loss=5.154348\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1189.1260147094727, \"sum\": 1189.1260147094727, \"min\": 1189.1260147094727}}, \"EndTime\": 1601803248.961594, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803247.772159}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=552.467190279 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=150, train loss <loss>=5.15560353886\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:48 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:49 INFO 139827261196096] Epoch[151] Batch[0] avg_epoch_loss=5.116045\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=5.11604547501\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:49 INFO 139827261196096] Epoch[151] Batch[5] avg_epoch_loss=5.194292\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=5.1942923069\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:49 INFO 139827261196096] Epoch[151] Batch [5]#011Speed: 1021.06 samples/sec#011loss=5.194292\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] Epoch[151] Batch[10] avg_epoch_loss=5.167239\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=151, batch=10 train loss <loss>=5.13477478027\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] Epoch[151] Batch [10]#011Speed: 985.50 samples/sec#011loss=5.134775\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1175.7500171661377, \"sum\": 1175.7500171661377, \"min\": 1175.7500171661377}}, \"EndTime\": 1601803250.137656, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803248.961651}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=570.659738022 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=151, train loss <loss>=5.16723888571\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] Epoch[152] Batch[0] avg_epoch_loss=5.185390\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=5.18539047241\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] Epoch[152] Batch[5] avg_epoch_loss=5.164745\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=5.16474541028\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:50 INFO 139827261196096] Epoch[152] Batch [5]#011Speed: 1021.55 samples/sec#011loss=5.164745\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:51 INFO 139827261196096] Epoch[152] Batch[10] avg_epoch_loss=5.172025\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=5.18076133728\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:51 INFO 139827261196096] Epoch[152] Batch [10]#011Speed: 923.64 samples/sec#011loss=5.180761\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:51 INFO 139827261196096] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1195.2040195465088, \"sum\": 1195.2040195465088, \"min\": 1195.2040195465088}}, \"EndTime\": 1601803251.333171, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803250.137711}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:51 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=537.10907386 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:51 INFO 139827261196096] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=152, train loss <loss>=5.1720253771\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:51 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:51 INFO 139827261196096] Epoch[153] Batch[0] avg_epoch_loss=5.157048\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=5.15704774857\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] Epoch[153] Batch[5] avg_epoch_loss=5.208182\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=5.20818193754\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] Epoch[153] Batch [5]#011Speed: 956.65 samples/sec#011loss=5.208182\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] Epoch[153] Batch[10] avg_epoch_loss=5.176080\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=153, batch=10 train loss <loss>=5.13755836487\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] Epoch[153] Batch [10]#011Speed: 949.36 samples/sec#011loss=5.137558\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1214.735984802246, \"sum\": 1214.735984802246, \"min\": 1214.735984802246}}, \"EndTime\": 1601803252.548218, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803251.333228}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=531.766898069 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=153, train loss <loss>=5.1760803136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:52 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] Epoch[154] Batch[0] avg_epoch_loss=5.221877\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=5.22187662125\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] Epoch[154] Batch[5] avg_epoch_loss=5.187913\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=5.18791294098\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] Epoch[154] Batch [5]#011Speed: 934.59 samples/sec#011loss=5.187913\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] Epoch[154] Batch[10] avg_epoch_loss=5.143321\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=5.08981142044\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] Epoch[154] Batch [10]#011Speed: 958.47 samples/sec#011loss=5.089811\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1230.9420108795166, \"sum\": 1230.9420108795166, \"min\": 1230.9420108795166}}, \"EndTime\": 1601803253.779475, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803252.548275}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=525.575232849 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=154, train loss <loss>=5.14332134073\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:53 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:54 INFO 139827261196096] Epoch[155] Batch[0] avg_epoch_loss=5.235348\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=5.2353477478\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:54 INFO 139827261196096] Epoch[155] Batch[5] avg_epoch_loss=5.182139\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=5.18213868141\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:54 INFO 139827261196096] Epoch[155] Batch [5]#011Speed: 983.02 samples/sec#011loss=5.182139\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:54 INFO 139827261196096] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1128.5550594329834, \"sum\": 1128.5550594329834, \"min\": 1128.5550594329834}}, \"EndTime\": 1601803254.908408, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803253.779537}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:54 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=541.352795718 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:54 INFO 139827261196096] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=155, train loss <loss>=5.17850017548\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:54 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:55 INFO 139827261196096] Epoch[156] Batch[0] avg_epoch_loss=5.193100\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=5.19310045242\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:55 INFO 139827261196096] Epoch[156] Batch[5] avg_epoch_loss=5.164744\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=5.16474429766\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:55 INFO 139827261196096] Epoch[156] Batch [5]#011Speed: 954.57 samples/sec#011loss=5.164744\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] Epoch[156] Batch[10] avg_epoch_loss=5.153448\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=156, batch=10 train loss <loss>=5.13989219666\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] Epoch[156] Batch [10]#011Speed: 953.38 samples/sec#011loss=5.139892\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1215.245008468628, \"sum\": 1215.245008468628, \"min\": 1215.245008468628}}, \"EndTime\": 1601803256.124117, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803254.908474}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=527.426641064 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=156, train loss <loss>=5.15344788811\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] Epoch[157] Batch[0] avg_epoch_loss=5.189193\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=5.18919277191\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] Epoch[157] Batch[5] avg_epoch_loss=5.144964\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=5.14496445656\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:56 INFO 139827261196096] Epoch[157] Batch [5]#011Speed: 982.04 samples/sec#011loss=5.144964\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:57 INFO 139827261196096] Epoch[157] Batch[10] avg_epoch_loss=5.142681\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=5.13994083405\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:57 INFO 139827261196096] Epoch[157] Batch [10]#011Speed: 952.10 samples/sec#011loss=5.139941\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:57 INFO 139827261196096] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1208.754062652588, \"sum\": 1208.754062652588, \"min\": 1208.754062652588}}, \"EndTime\": 1601803257.333247, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803256.124173}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:57 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=532.74344083 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:57 INFO 139827261196096] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=157, train loss <loss>=5.14268099178\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:57 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:57 INFO 139827261196096] Epoch[158] Batch[0] avg_epoch_loss=5.196464\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=5.1964635849\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] Epoch[158] Batch[5] avg_epoch_loss=5.179862\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=5.17986194293\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] Epoch[158] Batch [5]#011Speed: 976.89 samples/sec#011loss=5.179862\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] Epoch[158] Batch[10] avg_epoch_loss=5.198883\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=158, batch=10 train loss <loss>=5.2217083931\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] Epoch[158] Batch [10]#011Speed: 952.79 samples/sec#011loss=5.221708\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1211.2431526184082, \"sum\": 1211.2431526184082, \"min\": 1211.2431526184082}}, \"EndTime\": 1601803258.544876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803257.333302}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=552.285533095 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=158, train loss <loss>=5.19888305664\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:58 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] Epoch[159] Batch[0] avg_epoch_loss=5.132335\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=5.132335186\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] Epoch[159] Batch[5] avg_epoch_loss=5.141973\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=5.14197309812\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] Epoch[159] Batch [5]#011Speed: 976.94 samples/sec#011loss=5.141973\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] Epoch[159] Batch[10] avg_epoch_loss=5.177018\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=159, batch=10 train loss <loss>=5.21907110214\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] Epoch[159] Batch [10]#011Speed: 958.07 samples/sec#011loss=5.219071\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1214.372158050537, \"sum\": 1214.372158050537, \"min\": 1214.372158050537}}, \"EndTime\": 1601803259.759567, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803258.544933}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=534.393408168 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=159, train loss <loss>=5.1770176454\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:20:59 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:00 INFO 139827261196096] Epoch[160] Batch[0] avg_epoch_loss=5.359725\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=5.35972452164\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:00 INFO 139827261196096] Epoch[160] Batch[5] avg_epoch_loss=5.227356\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=5.22735571861\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:00 INFO 139827261196096] Epoch[160] Batch [5]#011Speed: 943.36 samples/sec#011loss=5.227356\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:00 INFO 139827261196096] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1142.8048610687256, \"sum\": 1142.8048610687256, \"min\": 1142.8048610687256}}, \"EndTime\": 1601803260.90277, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803259.759626}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:00 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=559.979472913 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:00 INFO 139827261196096] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=160, train loss <loss>=5.21955962181\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:00 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:01 INFO 139827261196096] Epoch[161] Batch[0] avg_epoch_loss=5.164299\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=5.16429948807\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:01 INFO 139827261196096] Epoch[161] Batch[5] avg_epoch_loss=5.191115\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=5.1911145846\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:01 INFO 139827261196096] Epoch[161] Batch [5]#011Speed: 971.83 samples/sec#011loss=5.191115\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:02 INFO 139827261196096] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1158.4951877593994, \"sum\": 1158.4951877593994, \"min\": 1158.4951877593994}}, \"EndTime\": 1601803262.061697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803260.902837}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:02 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=551.535833795 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:02 INFO 139827261196096] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=161, train loss <loss>=5.18337497711\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:02 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:02 INFO 139827261196096] Epoch[162] Batch[0] avg_epoch_loss=5.179419\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=5.17941904068\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:02 INFO 139827261196096] Epoch[162] Batch[5] avg_epoch_loss=5.163158\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=5.16315801938\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:02 INFO 139827261196096] Epoch[162] Batch [5]#011Speed: 973.49 samples/sec#011loss=5.163158\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:03 INFO 139827261196096] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1169.217824935913, \"sum\": 1169.217824935913, \"min\": 1169.217824935913}}, \"EndTime\": 1601803263.231378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803262.061753}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:03 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=543.055373691 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:03 INFO 139827261196096] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=162, train loss <loss>=5.14916467667\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:03 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:03 INFO 139827261196096] Epoch[163] Batch[0] avg_epoch_loss=5.139028\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=5.13902807236\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:04 INFO 139827261196096] Epoch[163] Batch[5] avg_epoch_loss=5.155796\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=5.1557961305\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:04 INFO 139827261196096] Epoch[163] Batch [5]#011Speed: 954.10 samples/sec#011loss=5.155796\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:04 INFO 139827261196096] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1185.8680248260498, \"sum\": 1185.8680248260498, \"min\": 1185.8680248260498}}, \"EndTime\": 1601803264.417732, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803263.231443}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:04 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=532.899341374 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:04 INFO 139827261196096] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=163, train loss <loss>=5.15764508247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:04 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] Epoch[164] Batch[0] avg_epoch_loss=5.145575\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=5.14557504654\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] Epoch[164] Batch[5] avg_epoch_loss=5.129149\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=5.12914880117\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] Epoch[164] Batch [5]#011Speed: 991.51 samples/sec#011loss=5.129149\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] Epoch[164] Batch[10] avg_epoch_loss=5.135039\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=164, batch=10 train loss <loss>=5.14210767746\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] Epoch[164] Batch [10]#011Speed: 973.91 samples/sec#011loss=5.142108\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1240.4730319976807, \"sum\": 1240.4730319976807, \"min\": 1240.4730319976807}}, \"EndTime\": 1601803265.658601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803264.417798}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=539.270386314 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=164, train loss <loss>=5.13503919948\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:05 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] Epoch[165] Batch[0] avg_epoch_loss=5.104931\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=5.10493135452\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] Epoch[165] Batch[5] avg_epoch_loss=5.145826\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=5.14582641919\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] Epoch[165] Batch [5]#011Speed: 996.56 samples/sec#011loss=5.145826\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] Epoch[165] Batch[10] avg_epoch_loss=5.141239\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=165, batch=10 train loss <loss>=5.1357334137\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] Epoch[165] Batch [10]#011Speed: 983.57 samples/sec#011loss=5.135733\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1171.8249320983887, \"sum\": 1171.8249320983887, \"min\": 1171.8249320983887}}, \"EndTime\": 1601803266.830797, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803265.658664}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.969418079 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=165, train loss <loss>=5.14123868942\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:06 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:07 INFO 139827261196096] Epoch[166] Batch[0] avg_epoch_loss=5.155193\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=5.15519332886\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:07 INFO 139827261196096] Epoch[166] Batch[5] avg_epoch_loss=5.146644\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=5.14664371808\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:07 INFO 139827261196096] Epoch[166] Batch [5]#011Speed: 1001.42 samples/sec#011loss=5.146644\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] Epoch[166] Batch[10] avg_epoch_loss=5.154729\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=166, batch=10 train loss <loss>=5.16443061829\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] Epoch[166] Batch [10]#011Speed: 991.59 samples/sec#011loss=5.164431\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1221.3401794433594, \"sum\": 1221.3401794433594, \"min\": 1221.3401794433594}}, \"EndTime\": 1601803268.052451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803266.830855}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=569.826312452 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=166, train loss <loss>=5.15472867272\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] Epoch[167] Batch[0] avg_epoch_loss=5.165493\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=5.16549253464\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] Epoch[167] Batch[5] avg_epoch_loss=5.154080\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=5.15408023198\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:08 INFO 139827261196096] Epoch[167] Batch [5]#011Speed: 1015.43 samples/sec#011loss=5.154080\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:09 INFO 139827261196096] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1097.7001190185547, \"sum\": 1097.7001190185547, \"min\": 1097.7001190185547}}, \"EndTime\": 1601803269.150468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803268.052509}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:09 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=538.357251696 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:09 INFO 139827261196096] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=167, train loss <loss>=5.19814743996\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:09 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:09 INFO 139827261196096] Epoch[168] Batch[0] avg_epoch_loss=5.180277\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=5.18027687073\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:09 INFO 139827261196096] Epoch[168] Batch[5] avg_epoch_loss=5.174270\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=5.17426983515\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:09 INFO 139827261196096] Epoch[168] Batch [5]#011Speed: 1025.98 samples/sec#011loss=5.174270\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:10 INFO 139827261196096] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1092.4930572509766, \"sum\": 1092.4930572509766, \"min\": 1092.4930572509766}}, \"EndTime\": 1601803270.243363, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803269.150523}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:10 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=572.033084628 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:10 INFO 139827261196096] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=168, train loss <loss>=5.15582427979\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:10 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:10 INFO 139827261196096] Epoch[169] Batch[0] avg_epoch_loss=5.099540\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=5.09953975677\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] Epoch[169] Batch[5] avg_epoch_loss=5.141949\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=5.14194925626\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] Epoch[169] Batch [5]#011Speed: 1006.92 samples/sec#011loss=5.141949\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] Epoch[169] Batch[10] avg_epoch_loss=5.129566\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=169, batch=10 train loss <loss>=5.11470575333\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] Epoch[169] Batch [10]#011Speed: 978.43 samples/sec#011loss=5.114706\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1173.9718914031982, \"sum\": 1173.9718914031982, \"min\": 1173.9718914031982}}, \"EndTime\": 1601803271.417783, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803270.243431}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.81905305 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=169, train loss <loss>=5.12956584584\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] Epoch[170] Batch[0] avg_epoch_loss=5.108027\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=5.10802745819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] Epoch[170] Batch[5] avg_epoch_loss=5.146976\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=5.14697575569\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] Epoch[170] Batch [5]#011Speed: 963.03 samples/sec#011loss=5.146976\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] Epoch[170] Batch[10] avg_epoch_loss=5.124783\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=170, batch=10 train loss <loss>=5.09815244675\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] Epoch[170] Batch [10]#011Speed: 996.12 samples/sec#011loss=5.098152\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1181.8649768829346, \"sum\": 1181.8649768829346, \"min\": 1181.8649768829346}}, \"EndTime\": 1601803272.600093, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803271.417844}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=543.167841558 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=170, train loss <loss>=5.12478334253\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:12 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_e74d536e-aede-4706-846e-23cb03cf3333-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.347978591918945, \"sum\": 18.347978591918945, \"min\": 18.347978591918945}}, \"EndTime\": 1601803272.618813, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803272.600153}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] Epoch[171] Batch[0] avg_epoch_loss=5.085540\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=5.08554029465\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] Epoch[171] Batch[5] avg_epoch_loss=5.149608\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=5.14960805575\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] Epoch[171] Batch [5]#011Speed: 1001.20 samples/sec#011loss=5.149608\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] Epoch[171] Batch[10] avg_epoch_loss=5.103210\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=5.04753217697\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] Epoch[171] Batch [10]#011Speed: 985.11 samples/sec#011loss=5.047532\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1173.9099025726318, \"sum\": 1173.9099025726318, \"min\": 1173.9099025726318}}, \"EndTime\": 1601803273.79282, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803272.618858}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=547.702049676 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=171, train loss <loss>=5.10320992903\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:13 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_7963ed32-454b-4b1f-ad06-f5b933e9b224-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.92401885986328, \"sum\": 21.92401885986328, \"min\": 21.92401885986328}}, \"EndTime\": 1601803273.815088, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803273.792878}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:14 INFO 139827261196096] Epoch[172] Batch[0] avg_epoch_loss=5.171448\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=5.17144775391\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:14 INFO 139827261196096] Epoch[172] Batch[5] avg_epoch_loss=5.162958\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=5.16295822461\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:14 INFO 139827261196096] Epoch[172] Batch [5]#011Speed: 960.56 samples/sec#011loss=5.162958\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] Epoch[172] Batch[10] avg_epoch_loss=5.164133\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=172, batch=10 train loss <loss>=5.16554346085\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] Epoch[172] Batch [10]#011Speed: 962.18 samples/sec#011loss=5.165543\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1201.7979621887207, \"sum\": 1201.7979621887207, \"min\": 1201.7979621887207}}, \"EndTime\": 1601803275.016985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803273.815135}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=544.147512125 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=172, train loss <loss>=5.16413333199\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] Epoch[173] Batch[0] avg_epoch_loss=5.223129\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=5.22312927246\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] Epoch[173] Batch[5] avg_epoch_loss=5.174392\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=5.17439182599\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:15 INFO 139827261196096] Epoch[173] Batch [5]#011Speed: 966.19 samples/sec#011loss=5.174392\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:16 INFO 139827261196096] Epoch[173] Batch[10] avg_epoch_loss=5.166187\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=173, batch=10 train loss <loss>=5.15634021759\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:16 INFO 139827261196096] Epoch[173] Batch [10]#011Speed: 957.55 samples/sec#011loss=5.156340\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:16 INFO 139827261196096] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1202.9249668121338, \"sum\": 1202.9249668121338, \"min\": 1202.9249668121338}}, \"EndTime\": 1601803276.22022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803275.017042}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:16 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.961876497 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:16 INFO 139827261196096] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=173, train loss <loss>=5.16618654945\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:16 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:16 INFO 139827261196096] Epoch[174] Batch[0] avg_epoch_loss=5.064377\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=5.06437683105\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:17 INFO 139827261196096] Epoch[174] Batch[5] avg_epoch_loss=5.137089\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=5.13708901405\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:17 INFO 139827261196096] Epoch[174] Batch [5]#011Speed: 890.87 samples/sec#011loss=5.137089\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:17 INFO 139827261196096] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1189.4011497497559, \"sum\": 1189.4011497497559, \"min\": 1189.4011497497559}}, \"EndTime\": 1601803277.409928, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803276.220277}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:17 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=505.250521831 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:17 INFO 139827261196096] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=174, train loss <loss>=5.15944824219\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:17 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:17 INFO 139827261196096] Epoch[175] Batch[0] avg_epoch_loss=5.172162\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=5.17216205597\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] Epoch[175] Batch[5] avg_epoch_loss=5.140893\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=5.14089258512\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] Epoch[175] Batch [5]#011Speed: 975.16 samples/sec#011loss=5.140893\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] Epoch[175] Batch[10] avg_epoch_loss=5.148618\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=5.15788755417\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] Epoch[175] Batch [10]#011Speed: 932.09 samples/sec#011loss=5.157888\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1231.9579124450684, \"sum\": 1231.9579124450684, \"min\": 1231.9579124450684}}, \"EndTime\": 1601803278.642282, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803277.410009}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=532.45027605 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=175, train loss <loss>=5.14861757105\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:18 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] Epoch[176] Batch[0] avg_epoch_loss=5.098194\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=5.09819364548\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] Epoch[176] Batch[5] avg_epoch_loss=5.144316\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=5.14431587855\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] Epoch[176] Batch [5]#011Speed: 984.04 samples/sec#011loss=5.144316\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] Epoch[176] Batch[10] avg_epoch_loss=5.124935\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=176, batch=10 train loss <loss>=5.10167808533\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] Epoch[176] Batch [10]#011Speed: 963.77 samples/sec#011loss=5.101678\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1194.762945175171, \"sum\": 1194.762945175171, \"min\": 1194.762945175171}}, \"EndTime\": 1601803279.837355, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803278.642339}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=538.983351794 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=176, train loss <loss>=5.12493506345\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:19 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:20 INFO 139827261196096] Epoch[177] Batch[0] avg_epoch_loss=5.226285\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=5.22628450394\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:20 INFO 139827261196096] Epoch[177] Batch[5] avg_epoch_loss=5.169002\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=5.1690018177\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:20 INFO 139827261196096] Epoch[177] Batch [5]#011Speed: 971.65 samples/sec#011loss=5.169002\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:20 INFO 139827261196096] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1120.0251579284668, \"sum\": 1120.0251579284668, \"min\": 1120.0251579284668}}, \"EndTime\": 1601803280.957744, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803279.83741}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:20 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=554.406395251 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:20 INFO 139827261196096] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=177, train loss <loss>=5.15075287819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:20 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:21 INFO 139827261196096] Epoch[178] Batch[0] avg_epoch_loss=5.155701\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=5.15570068359\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:21 INFO 139827261196096] Epoch[178] Batch[5] avg_epoch_loss=5.173656\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=5.17365590731\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:21 INFO 139827261196096] Epoch[178] Batch [5]#011Speed: 997.65 samples/sec#011loss=5.173656\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:22 INFO 139827261196096] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1119.2371845245361, \"sum\": 1119.2371845245361, \"min\": 1119.2371845245361}}, \"EndTime\": 1601803282.077371, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803280.957809}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:22 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=562.837212017 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:22 INFO 139827261196096] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=178, train loss <loss>=5.1565279007\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:22 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:22 INFO 139827261196096] Epoch[179] Batch[0] avg_epoch_loss=5.152637\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=5.15263748169\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:22 INFO 139827261196096] Epoch[179] Batch[5] avg_epoch_loss=5.128612\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=5.12861227989\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:22 INFO 139827261196096] Epoch[179] Batch [5]#011Speed: 969.87 samples/sec#011loss=5.128612\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:23 INFO 139827261196096] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1134.8071098327637, \"sum\": 1134.8071098327637, \"min\": 1134.8071098327637}}, \"EndTime\": 1601803283.212543, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803282.077435}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:23 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=547.185303872 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:23 INFO 139827261196096] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=179, train loss <loss>=5.14202299118\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:23 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:23 INFO 139827261196096] Epoch[180] Batch[0] avg_epoch_loss=5.109606\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=5.10960626602\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:24 INFO 139827261196096] Epoch[180] Batch[5] avg_epoch_loss=5.137544\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=5.13754431407\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:24 INFO 139827261196096] Epoch[180] Batch [5]#011Speed: 986.73 samples/sec#011loss=5.137544\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:24 INFO 139827261196096] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1145.2288627624512, \"sum\": 1145.2288627624512, \"min\": 1145.2288627624512}}, \"EndTime\": 1601803284.358134, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803283.212606}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:24 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=553.563336765 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:24 INFO 139827261196096] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=180, train loss <loss>=5.14568400383\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:24 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:24 INFO 139827261196096] Epoch[181] Batch[0] avg_epoch_loss=5.163462\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=5.16346216202\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] Epoch[181] Batch[5] avg_epoch_loss=5.150116\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=5.15011620522\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] Epoch[181] Batch [5]#011Speed: 974.36 samples/sec#011loss=5.150116\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] Epoch[181] Batch[10] avg_epoch_loss=5.158756\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=5.16912431717\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] Epoch[181] Batch [10]#011Speed: 959.37 samples/sec#011loss=5.169124\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1212.843894958496, \"sum\": 1212.843894958496, \"min\": 1212.843894958496}}, \"EndTime\": 1601803285.571409, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803284.358186}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=531.767160839 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=181, train loss <loss>=5.1587562561\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:25 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] Epoch[182] Batch[0] avg_epoch_loss=5.138752\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=5.13875246048\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] Epoch[182] Batch[5] avg_epoch_loss=5.154864\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=5.15486375491\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] Epoch[182] Batch [5]#011Speed: 973.24 samples/sec#011loss=5.154864\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] Epoch[182] Batch[10] avg_epoch_loss=5.140111\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=5.12240667343\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] Epoch[182] Batch [10]#011Speed: 962.42 samples/sec#011loss=5.122407\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1224.9171733856201, \"sum\": 1224.9171733856201, \"min\": 1224.9171733856201}}, \"EndTime\": 1601803286.796705, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803285.571473}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=548.569229179 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=182, train loss <loss>=5.14011053606\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:26 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:27 INFO 139827261196096] Epoch[183] Batch[0] avg_epoch_loss=5.145044\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=5.14504384995\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:27 INFO 139827261196096] Epoch[183] Batch[5] avg_epoch_loss=5.146958\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=5.14695843061\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:27 INFO 139827261196096] Epoch[183] Batch [5]#011Speed: 952.76 samples/sec#011loss=5.146958\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:27 INFO 139827261196096] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1145.9980010986328, \"sum\": 1145.9980010986328, \"min\": 1145.9980010986328}}, \"EndTime\": 1601803287.943127, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803286.796769}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:27 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=551.438607732 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:27 INFO 139827261196096] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=183, train loss <loss>=5.12908873558\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:27 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:28 INFO 139827261196096] Epoch[184] Batch[0] avg_epoch_loss=5.099206\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=5.0992064476\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:28 INFO 139827261196096] Epoch[184] Batch[5] avg_epoch_loss=5.108228\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=5.10822788874\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:28 INFO 139827261196096] Epoch[184] Batch [5]#011Speed: 979.96 samples/sec#011loss=5.108228\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] Epoch[184] Batch[10] avg_epoch_loss=5.095851\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=184, batch=10 train loss <loss>=5.08099784851\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] Epoch[184] Batch [10]#011Speed: 956.59 samples/sec#011loss=5.080998\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1211.510181427002, \"sum\": 1211.510181427002, \"min\": 1211.510181427002}}, \"EndTime\": 1601803289.155101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803287.943192}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=529.879591531 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=184, train loss <loss>=5.09585059773\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_dcb267be-5215-42fb-bd9a-613e44fe80da-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.375106811523438, \"sum\": 22.375106811523438, \"min\": 22.375106811523438}}, \"EndTime\": 1601803289.177824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803289.155157}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] Epoch[185] Batch[0] avg_epoch_loss=5.125939\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=5.12593889236\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:30 INFO 139827261196096] Epoch[185] Batch[5] avg_epoch_loss=5.138895\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=5.13889455795\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:30 INFO 139827261196096] Epoch[185] Batch [5]#011Speed: 985.43 samples/sec#011loss=5.138895\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:30 INFO 139827261196096] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1140.2781009674072, \"sum\": 1140.2781009674072, \"min\": 1140.2781009674072}}, \"EndTime\": 1601803290.318206, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803289.177877}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:30 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=542.807127919 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:30 INFO 139827261196096] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=185, train loss <loss>=5.11017384529\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:30 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:30 INFO 139827261196096] Epoch[186] Batch[0] avg_epoch_loss=5.170138\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=5.17013788223\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] Epoch[186] Batch[5] avg_epoch_loss=5.139238\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=5.13923796018\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] Epoch[186] Batch [5]#011Speed: 969.49 samples/sec#011loss=5.139238\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] Epoch[186] Batch[10] avg_epoch_loss=5.127838\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=186, batch=10 train loss <loss>=5.11415872574\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] Epoch[186] Batch [10]#011Speed: 925.51 samples/sec#011loss=5.114159\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1240.231990814209, \"sum\": 1240.231990814209, \"min\": 1240.231990814209}}, \"EndTime\": 1601803291.558875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803290.318268}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=524.059530201 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=186, train loss <loss>=5.12783830816\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:31 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] Epoch[187] Batch[0] avg_epoch_loss=5.133539\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=5.13353919983\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] Epoch[187] Batch[5] avg_epoch_loss=5.148647\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=5.1486471494\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] Epoch[187] Batch [5]#011Speed: 991.93 samples/sec#011loss=5.148647\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] Epoch[187] Batch[10] avg_epoch_loss=5.126667\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=5.10029067993\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] Epoch[187] Batch [10]#011Speed: 960.04 samples/sec#011loss=5.100291\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1218.4550762176514, \"sum\": 1218.4550762176514, \"min\": 1218.4550762176514}}, \"EndTime\": 1601803292.777648, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803291.558934}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.553917241 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=187, train loss <loss>=5.12666693601\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:32 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] Epoch[188] Batch[0] avg_epoch_loss=5.227311\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=5.2273106575\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] Epoch[188] Batch[5] avg_epoch_loss=5.129409\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=5.12940915426\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] Epoch[188] Batch [5]#011Speed: 992.02 samples/sec#011loss=5.129409\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] Epoch[188] Batch[10] avg_epoch_loss=5.138610\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=188, batch=10 train loss <loss>=5.14965209961\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] Epoch[188] Batch [10]#011Speed: 981.66 samples/sec#011loss=5.149652\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] processed a total of 684 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1193.068027496338, \"sum\": 1193.068027496338, \"min\": 1193.068027496338}}, \"EndTime\": 1601803293.971049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803292.777707}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=573.272409227 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=188, train loss <loss>=5.13861049305\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:33 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:34 INFO 139827261196096] Epoch[189] Batch[0] avg_epoch_loss=5.201032\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=5.20103216171\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:34 INFO 139827261196096] Epoch[189] Batch[5] avg_epoch_loss=5.169984\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=5.16998386383\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:34 INFO 139827261196096] Epoch[189] Batch [5]#011Speed: 957.68 samples/sec#011loss=5.169984\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:35 INFO 139827261196096] Epoch[189] Batch[10] avg_epoch_loss=5.118338\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=5.05636262894\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:35 INFO 139827261196096] Epoch[189] Batch [10]#011Speed: 970.07 samples/sec#011loss=5.056363\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:35 INFO 139827261196096] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1198.0299949645996, \"sum\": 1198.0299949645996, \"min\": 1198.0299949645996}}, \"EndTime\": 1601803295.16938, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803293.971105}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:35 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=541.685149197 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:35 INFO 139827261196096] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=189, train loss <loss>=5.11833784797\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:35 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:35 INFO 139827261196096] Epoch[190] Batch[0] avg_epoch_loss=5.164554\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=5.16455411911\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] Epoch[190] Batch[5] avg_epoch_loss=5.146372\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=5.14637207985\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] Epoch[190] Batch [5]#011Speed: 989.17 samples/sec#011loss=5.146372\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] Epoch[190] Batch[10] avg_epoch_loss=5.142720\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=5.13833732605\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] Epoch[190] Batch [10]#011Speed: 993.50 samples/sec#011loss=5.138337\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1179.7699928283691, \"sum\": 1179.7699928283691, \"min\": 1179.7699928283691}}, \"EndTime\": 1601803296.349459, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803295.169437}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=543.288915329 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=190, train loss <loss>=5.14271991903\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] Epoch[191] Batch[0] avg_epoch_loss=5.303556\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=5.30355596542\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] Epoch[191] Batch[5] avg_epoch_loss=5.218166\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=5.21816555659\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] Epoch[191] Batch [5]#011Speed: 1020.12 samples/sec#011loss=5.218166\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] Epoch[191] Batch[10] avg_epoch_loss=5.201135\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=5.18069887161\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] Epoch[191] Batch [10]#011Speed: 967.22 samples/sec#011loss=5.180699\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1171.8640327453613, \"sum\": 1171.8640327453613, \"min\": 1171.8640327453613}}, \"EndTime\": 1601803297.52169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803296.349515}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.951169144 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=191, train loss <loss>=5.20113524524\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:37 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] Epoch[192] Batch[0] avg_epoch_loss=5.195586\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=5.19558620453\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] Epoch[192] Batch[5] avg_epoch_loss=5.141626\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=5.14162611961\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] Epoch[192] Batch [5]#011Speed: 976.83 samples/sec#011loss=5.141626\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] Epoch[192] Batch[10] avg_epoch_loss=5.134777\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=192, batch=10 train loss <loss>=5.12655763626\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] Epoch[192] Batch [10]#011Speed: 942.05 samples/sec#011loss=5.126558\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1236.1829280853271, \"sum\": 1236.1829280853271, \"min\": 1236.1829280853271}}, \"EndTime\": 1601803298.758245, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803297.521748}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=530.628443683 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=192, train loss <loss>=5.134776809\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:38 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] Epoch[193] Batch[0] avg_epoch_loss=5.218357\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=5.21835708618\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] Epoch[193] Batch[5] avg_epoch_loss=5.172641\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=5.17264127731\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] Epoch[193] Batch [5]#011Speed: 971.90 samples/sec#011loss=5.172641\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] Epoch[193] Batch[10] avg_epoch_loss=5.138956\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=193, batch=10 train loss <loss>=5.09853343964\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] Epoch[193] Batch [10]#011Speed: 957.35 samples/sec#011loss=5.098533\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1216.6309356689453, \"sum\": 1216.6309356689453, \"min\": 1216.6309356689453}}, \"EndTime\": 1601803299.975188, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803298.758303}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=544.906185734 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=193, train loss <loss>=5.13895589655\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:39 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:40 INFO 139827261196096] Epoch[194] Batch[0] avg_epoch_loss=5.202616\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=5.20261621475\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:40 INFO 139827261196096] Epoch[194] Batch[5] avg_epoch_loss=5.144511\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=5.14451066653\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:40 INFO 139827261196096] Epoch[194] Batch [5]#011Speed: 928.98 samples/sec#011loss=5.144511\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:41 INFO 139827261196096] Epoch[194] Batch[10] avg_epoch_loss=5.124342\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=5.10014028549\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:41 INFO 139827261196096] Epoch[194] Batch [10]#011Speed: 945.68 samples/sec#011loss=5.100140\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:41 INFO 139827261196096] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1230.4279804229736, \"sum\": 1230.4279804229736, \"min\": 1230.4279804229736}}, \"EndTime\": 1601803301.206029, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803299.975253}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:41 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=529.031711966 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:41 INFO 139827261196096] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=194, train loss <loss>=5.12434231151\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:41 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:41 INFO 139827261196096] Epoch[195] Batch[0] avg_epoch_loss=5.154316\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=5.15431594849\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] Epoch[195] Batch[5] avg_epoch_loss=5.141514\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=5.14151414235\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] Epoch[195] Batch [5]#011Speed: 908.07 samples/sec#011loss=5.141514\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] Epoch[195] Batch[10] avg_epoch_loss=5.128719\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=5.11336536407\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] Epoch[195] Batch [10]#011Speed: 951.00 samples/sec#011loss=5.113365\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1250.3201961517334, \"sum\": 1250.3201961517334, \"min\": 1250.3201961517334}}, \"EndTime\": 1601803302.456688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803301.20609}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=526.228166462 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=195, train loss <loss>=5.12871924314\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:42 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] Epoch[196] Batch[0] avg_epoch_loss=5.143905\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=5.14390516281\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] Epoch[196] Batch[5] avg_epoch_loss=5.130249\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=5.13024926186\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] Epoch[196] Batch [5]#011Speed: 926.53 samples/sec#011loss=5.130249\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] Epoch[196] Batch[10] avg_epoch_loss=5.128373\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=5.12612190247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] Epoch[196] Batch [10]#011Speed: 930.58 samples/sec#011loss=5.126122\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1253.438949584961, \"sum\": 1253.438949584961, \"min\": 1253.438949584961}}, \"EndTime\": 1601803303.710444, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803302.456748}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=530.503970869 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=196, train loss <loss>=5.12837318941\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:43 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:44 INFO 139827261196096] Epoch[197] Batch[0] avg_epoch_loss=4.984586\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=4.98458576202\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:44 INFO 139827261196096] Epoch[197] Batch[5] avg_epoch_loss=5.100481\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=5.10048063596\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:44 INFO 139827261196096] Epoch[197] Batch [5]#011Speed: 1000.95 samples/sec#011loss=5.100481\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:44 INFO 139827261196096] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1142.3931121826172, \"sum\": 1142.3931121826172, \"min\": 1142.3931121826172}}, \"EndTime\": 1601803304.853152, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803303.710503}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:44 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=554.060201741 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:44 INFO 139827261196096] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=197, train loss <loss>=5.12047085762\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:44 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:45 INFO 139827261196096] Epoch[198] Batch[0] avg_epoch_loss=5.116572\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=5.11657190323\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:45 INFO 139827261196096] Epoch[198] Batch[5] avg_epoch_loss=5.125136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=5.12513550123\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:45 INFO 139827261196096] Epoch[198] Batch [5]#011Speed: 1015.70 samples/sec#011loss=5.125136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:45 INFO 139827261196096] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1102.9531955718994, \"sum\": 1102.9531955718994, \"min\": 1102.9531955718994}}, \"EndTime\": 1601803305.956521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803304.853208}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:45 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=562.078850211 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:45 INFO 139827261196096] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=198, train loss <loss>=5.13083152771\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:45 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:46 INFO 139827261196096] Epoch[199] Batch[0] avg_epoch_loss=5.151578\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=5.15157842636\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:46 INFO 139827261196096] Epoch[199] Batch[5] avg_epoch_loss=5.113081\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=5.11308058103\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:46 INFO 139827261196096] Epoch[199] Batch [5]#011Speed: 986.72 samples/sec#011loss=5.113081\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] Epoch[199] Batch[10] avg_epoch_loss=5.129339\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=5.14884986877\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] Epoch[199] Batch [10]#011Speed: 978.01 samples/sec#011loss=5.148850\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1184.4367980957031, \"sum\": 1184.4367980957031, \"min\": 1184.4367980957031}}, \"EndTime\": 1601803307.141457, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803305.956585}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=579.98176174 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=199, train loss <loss>=5.12933934819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] Epoch[200] Batch[0] avg_epoch_loss=5.073483\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=5.07348251343\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] Epoch[200] Batch[5] avg_epoch_loss=5.098543\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=5.0985426108\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:47 INFO 139827261196096] Epoch[200] Batch [5]#011Speed: 1012.34 samples/sec#011loss=5.098543\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:48 INFO 139827261196096] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1095.844030380249, \"sum\": 1095.844030380249, \"min\": 1095.844030380249}}, \"EndTime\": 1601803308.237683, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803307.141509}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:48 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=554.773873685 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:48 INFO 139827261196096] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=200, train loss <loss>=5.12232089043\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:48 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:48 INFO 139827261196096] Epoch[201] Batch[0] avg_epoch_loss=5.119379\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=5.11937856674\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] Epoch[201] Batch[5] avg_epoch_loss=5.100179\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=5.10017887751\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] Epoch[201] Batch [5]#011Speed: 1027.72 samples/sec#011loss=5.100179\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] Epoch[201] Batch[10] avg_epoch_loss=5.102774\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=201, batch=10 train loss <loss>=5.10588798523\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] Epoch[201] Batch [10]#011Speed: 997.58 samples/sec#011loss=5.105888\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1165.8527851104736, \"sum\": 1165.8527851104736, \"min\": 1165.8527851104736}}, \"EndTime\": 1601803309.403986, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803308.237748}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=588.369573037 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=201, train loss <loss>=5.10277392647\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] Epoch[202] Batch[0] avg_epoch_loss=5.064892\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=5.06489181519\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:50 INFO 139827261196096] Epoch[202] Batch[5] avg_epoch_loss=5.115767\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=5.11576724052\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:50 INFO 139827261196096] Epoch[202] Batch [5]#011Speed: 1022.23 samples/sec#011loss=5.115767\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:50 INFO 139827261196096] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1090.2340412139893, \"sum\": 1090.2340412139893, \"min\": 1090.2340412139893}}, \"EndTime\": 1601803310.494596, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803309.404039}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:50 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=562.217626999 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:50 INFO 139827261196096] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=202, train loss <loss>=5.08638801575\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:50 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:50 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_3c46b7db-f75e-4055-ac62-fb169632e07f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.169828414916992, \"sum\": 22.169828414916992, \"min\": 22.169828414916992}}, \"EndTime\": 1601803310.517174, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803310.494657}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:51 INFO 139827261196096] Epoch[203] Batch[0] avg_epoch_loss=5.157008\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=5.15700817108\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:51 INFO 139827261196096] Epoch[203] Batch[5] avg_epoch_loss=5.086135\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=5.08613467216\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:51 INFO 139827261196096] Epoch[203] Batch [5]#011Speed: 1021.43 samples/sec#011loss=5.086135\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:51 INFO 139827261196096] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1128.4501552581787, \"sum\": 1128.4501552581787, \"min\": 1128.4501552581787}}, \"EndTime\": 1601803311.645726, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803310.517227}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:51 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=550.270910731 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:51 INFO 139827261196096] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=203, train loss <loss>=5.10445342064\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:51 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:52 INFO 139827261196096] Epoch[204] Batch[0] avg_epoch_loss=5.139299\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=5.13929891586\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:52 INFO 139827261196096] Epoch[204] Batch[5] avg_epoch_loss=5.127527\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=5.12752652168\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:52 INFO 139827261196096] Epoch[204] Batch [5]#011Speed: 1024.10 samples/sec#011loss=5.127527\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:52 INFO 139827261196096] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1098.0191230773926, \"sum\": 1098.0191230773926, \"min\": 1098.0191230773926}}, \"EndTime\": 1601803312.744186, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803311.645784}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:52 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=548.211227669 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:52 INFO 139827261196096] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=204, train loss <loss>=5.10837163925\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:52 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] Epoch[205] Batch[0] avg_epoch_loss=5.174541\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=5.17454147339\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] Epoch[205] Batch[5] avg_epoch_loss=5.117569\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=5.11756857236\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] Epoch[205] Batch [5]#011Speed: 1007.03 samples/sec#011loss=5.117569\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] Epoch[205] Batch[10] avg_epoch_loss=5.110100\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=5.10113716125\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] Epoch[205] Batch [10]#011Speed: 987.98 samples/sec#011loss=5.101137\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1169.82102394104, \"sum\": 1169.82102394104, \"min\": 1169.82102394104}}, \"EndTime\": 1601803313.914446, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803312.744252}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=561.587976775 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=205, train loss <loss>=5.11009974913\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:53 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:54 INFO 139827261196096] Epoch[206] Batch[0] avg_epoch_loss=5.156571\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=5.15657138824\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:54 INFO 139827261196096] Epoch[206] Batch[5] avg_epoch_loss=5.123971\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=5.12397098541\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:54 INFO 139827261196096] Epoch[206] Batch [5]#011Speed: 1023.46 samples/sec#011loss=5.123971\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:55 INFO 139827261196096] processed a total of 596 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1096.1089134216309, \"sum\": 1096.1089134216309, \"min\": 1096.1089134216309}}, \"EndTime\": 1601803315.010906, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803313.914497}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:55 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=543.695938057 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:55 INFO 139827261196096] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=206, train loss <loss>=5.14669694901\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:55 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:55 INFO 139827261196096] Epoch[207] Batch[0] avg_epoch_loss=5.139184\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=5.13918399811\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:55 INFO 139827261196096] Epoch[207] Batch[5] avg_epoch_loss=5.091726\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=5.09172558784\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:55 INFO 139827261196096] Epoch[207] Batch [5]#011Speed: 967.88 samples/sec#011loss=5.091726\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:56 INFO 139827261196096] Epoch[207] Batch[10] avg_epoch_loss=5.096156\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=207, batch=10 train loss <loss>=5.10147294998\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:56 INFO 139827261196096] Epoch[207] Batch [10]#011Speed: 951.16 samples/sec#011loss=5.101473\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:56 INFO 139827261196096] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1198.056936264038, \"sum\": 1198.056936264038, \"min\": 1198.056936264038}}, \"EndTime\": 1601803316.209326, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803315.01097}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:56 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=537.498870929 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:56 INFO 139827261196096] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=207, train loss <loss>=5.096156207\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:56 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:56 INFO 139827261196096] Epoch[208] Batch[0] avg_epoch_loss=5.168611\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=5.16861104965\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:57 INFO 139827261196096] Epoch[208] Batch[5] avg_epoch_loss=5.145704\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=5.14570411046\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:57 INFO 139827261196096] Epoch[208] Batch [5]#011Speed: 969.50 samples/sec#011loss=5.145704\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:57 INFO 139827261196096] processed a total of 586 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1120.0580596923828, \"sum\": 1120.0580596923828, \"min\": 1120.0580596923828}}, \"EndTime\": 1601803317.329692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803316.209385}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:57 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=523.145627605 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:57 INFO 139827261196096] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=208, train loss <loss>=5.13243522644\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:57 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:57 INFO 139827261196096] Epoch[209] Batch[0] avg_epoch_loss=5.133983\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=5.13398313522\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:58 INFO 139827261196096] Epoch[209] Batch[5] avg_epoch_loss=5.120533\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=5.12053330739\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:58 INFO 139827261196096] Epoch[209] Batch [5]#011Speed: 969.65 samples/sec#011loss=5.120533\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:58 INFO 139827261196096] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1120.1679706573486, \"sum\": 1120.1679706573486, \"min\": 1120.1679706573486}}, \"EndTime\": 1601803318.45025, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803317.329754}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:58 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=561.476799914 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:58 INFO 139827261196096] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=209, train loss <loss>=5.12212424278\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:58 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:58 INFO 139827261196096] Epoch[210] Batch[0] avg_epoch_loss=5.118745\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=5.11874485016\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] Epoch[210] Batch[5] avg_epoch_loss=5.122833\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=5.12283269564\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] Epoch[210] Batch [5]#011Speed: 975.37 samples/sec#011loss=5.122833\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] Epoch[210] Batch[10] avg_epoch_loss=5.135858\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=210, batch=10 train loss <loss>=5.15148773193\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] Epoch[210] Batch [10]#011Speed: 956.24 samples/sec#011loss=5.151488\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1209.4769477844238, \"sum\": 1209.4769477844238, \"min\": 1209.4769477844238}}, \"EndTime\": 1601803319.6601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803318.450313}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=539.038069916 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=210, train loss <loss>=5.13585771214\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:21:59 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] Epoch[211] Batch[0] avg_epoch_loss=5.110748\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=5.11074829102\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] Epoch[211] Batch[5] avg_epoch_loss=5.111946\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=5.11194642385\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] Epoch[211] Batch [5]#011Speed: 997.86 samples/sec#011loss=5.111946\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] Epoch[211] Batch[10] avg_epoch_loss=5.099779\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=5.08517904282\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] Epoch[211] Batch [10]#011Speed: 933.94 samples/sec#011loss=5.085179\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1217.8921699523926, \"sum\": 1217.8921699523926, \"min\": 1217.8921699523926}}, \"EndTime\": 1601803320.878307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803319.660157}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=540.24186359 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=211, train loss <loss>=5.09977943247\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:00 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:01 INFO 139827261196096] Epoch[212] Batch[0] avg_epoch_loss=5.175257\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=5.17525672913\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:01 INFO 139827261196096] Epoch[212] Batch[5] avg_epoch_loss=5.120937\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=5.12093655268\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:01 INFO 139827261196096] Epoch[212] Batch [5]#011Speed: 867.58 samples/sec#011loss=5.120937\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:02 INFO 139827261196096] Epoch[212] Batch[10] avg_epoch_loss=5.139581\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=212, batch=10 train loss <loss>=5.16195344925\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:02 INFO 139827261196096] Epoch[212] Batch [10]#011Speed: 916.44 samples/sec#011loss=5.161953\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:02 INFO 139827261196096] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1254.8370361328125, \"sum\": 1254.8370361328125, \"min\": 1254.8370361328125}}, \"EndTime\": 1601803322.133495, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803320.878359}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:02 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=520.35031078 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:02 INFO 139827261196096] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=212, train loss <loss>=5.13958059658\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:02 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:02 INFO 139827261196096] Epoch[213] Batch[0] avg_epoch_loss=5.090874\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=5.09087371826\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] Epoch[213] Batch[5] avg_epoch_loss=5.104713\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=5.104713281\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] Epoch[213] Batch [5]#011Speed: 950.74 samples/sec#011loss=5.104713\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] Epoch[213] Batch[10] avg_epoch_loss=5.179375\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=5.26896905899\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] Epoch[213] Batch [10]#011Speed: 945.44 samples/sec#011loss=5.268969\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1214.1690254211426, \"sum\": 1214.1690254211426, \"min\": 1214.1690254211426}}, \"EndTime\": 1601803323.347978, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803322.133552}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=532.837384063 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=213, train loss <loss>=5.17937499827\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] Epoch[214] Batch[0] avg_epoch_loss=5.160131\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=5.16013097763\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] Epoch[214] Batch[5] avg_epoch_loss=5.102534\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=5.10253365835\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] Epoch[214] Batch [5]#011Speed: 952.23 samples/sec#011loss=5.102534\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] Epoch[214] Batch[10] avg_epoch_loss=5.116152\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=214, batch=10 train loss <loss>=5.13249368668\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] Epoch[214] Batch [10]#011Speed: 943.68 samples/sec#011loss=5.132494\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1292.311191558838, \"sum\": 1292.311191558838, \"min\": 1292.311191558838}}, \"EndTime\": 1601803324.640618, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803323.348036}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=526.156629796 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=214, train loss <loss>=5.11615185304\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:04 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] Epoch[215] Batch[0] avg_epoch_loss=5.217099\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=5.21709871292\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] Epoch[215] Batch[5] avg_epoch_loss=5.144638\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=5.144638141\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] Epoch[215] Batch [5]#011Speed: 956.37 samples/sec#011loss=5.144638\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] Epoch[215] Batch[10] avg_epoch_loss=5.121615\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=215, batch=10 train loss <loss>=5.09398813248\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] Epoch[215] Batch [10]#011Speed: 954.48 samples/sec#011loss=5.093988\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1237.4038696289062, \"sum\": 1237.4038696289062, \"min\": 1237.4038696289062}}, \"EndTime\": 1601803325.878411, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803324.640669}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=520.410276763 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=215, train loss <loss>=5.12161540985\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:05 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:06 INFO 139827261196096] Epoch[216] Batch[0] avg_epoch_loss=5.190108\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=5.19010829926\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:06 INFO 139827261196096] Epoch[216] Batch[5] avg_epoch_loss=5.142959\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=5.14295919736\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:06 INFO 139827261196096] Epoch[216] Batch [5]#011Speed: 981.08 samples/sec#011loss=5.142959\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:07 INFO 139827261196096] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1173.0670928955078, \"sum\": 1173.0670928955078, \"min\": 1173.0670928955078}}, \"EndTime\": 1601803327.051777, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803325.878463}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:07 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=526.778263262 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:07 INFO 139827261196096] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=216, train loss <loss>=5.13208489418\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:07 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:07 INFO 139827261196096] Epoch[217] Batch[0] avg_epoch_loss=5.056774\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=5.0567741394\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:07 INFO 139827261196096] Epoch[217] Batch[5] avg_epoch_loss=5.116284\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=5.11628437042\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:07 INFO 139827261196096] Epoch[217] Batch [5]#011Speed: 975.29 samples/sec#011loss=5.116284\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:08 INFO 139827261196096] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1140.1479244232178, \"sum\": 1140.1479244232178, \"min\": 1140.1479244232178}}, \"EndTime\": 1601803328.192383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803327.051846}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:08 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=553.391712065 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:08 INFO 139827261196096] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=217, train loss <loss>=5.10841383934\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:08 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:08 INFO 139827261196096] Epoch[218] Batch[0] avg_epoch_loss=5.055308\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=218, batch=0 train loss <loss>=5.05530786514\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] Epoch[218] Batch[5] avg_epoch_loss=5.084871\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=218, batch=5 train loss <loss>=5.08487113317\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] Epoch[218] Batch [5]#011Speed: 968.14 samples/sec#011loss=5.084871\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] Epoch[218] Batch[10] avg_epoch_loss=5.094867\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=218, batch=10 train loss <loss>=5.10686206818\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] Epoch[218] Batch [10]#011Speed: 968.05 samples/sec#011loss=5.106862\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1222.5310802459717, \"sum\": 1222.5310802459717, \"min\": 1222.5310802459717}}, \"EndTime\": 1601803329.415285, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803328.192446}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=544.730526134 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=218, train loss <loss>=5.09486701272\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] Epoch[219] Batch[0] avg_epoch_loss=5.173828\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=219, batch=0 train loss <loss>=5.17382764816\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:10 INFO 139827261196096] Epoch[219] Batch[5] avg_epoch_loss=5.119521\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=219, batch=5 train loss <loss>=5.11952122053\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:10 INFO 139827261196096] Epoch[219] Batch [5]#011Speed: 957.52 samples/sec#011loss=5.119521\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:10 INFO 139827261196096] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1183.7949752807617, \"sum\": 1183.7949752807617, \"min\": 1183.7949752807617}}, \"EndTime\": 1601803330.599447, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803329.415346}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:10 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=521.165546856 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:10 INFO 139827261196096] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=219, train loss <loss>=5.10776348114\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:10 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] Epoch[220] Batch[0] avg_epoch_loss=5.109101\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=220, batch=0 train loss <loss>=5.10910081863\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] Epoch[220] Batch[5] avg_epoch_loss=5.082762\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=220, batch=5 train loss <loss>=5.08276200294\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] Epoch[220] Batch [5]#011Speed: 960.29 samples/sec#011loss=5.082762\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] Epoch[220] Batch[10] avg_epoch_loss=5.102246\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=220, batch=10 train loss <loss>=5.12562580109\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] Epoch[220] Batch [10]#011Speed: 934.06 samples/sec#011loss=5.125626\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1226.6058921813965, \"sum\": 1226.6058921813965, \"min\": 1226.6058921813965}}, \"EndTime\": 1601803331.826503, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803330.59951}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=529.878627115 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=220, train loss <loss>=5.10224554755\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:11 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:12 INFO 139827261196096] Epoch[221] Batch[0] avg_epoch_loss=5.182081\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=221, batch=0 train loss <loss>=5.18208122253\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:12 INFO 139827261196096] Epoch[221] Batch[5] avg_epoch_loss=5.110341\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=221, batch=5 train loss <loss>=5.11034067472\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:12 INFO 139827261196096] Epoch[221] Batch [5]#011Speed: 970.91 samples/sec#011loss=5.110341\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:12 INFO 139827261196096] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1156.6331386566162, \"sum\": 1156.6331386566162, \"min\": 1156.6331386566162}}, \"EndTime\": 1601803332.983543, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803331.82656}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:12 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=529.939353666 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:12 INFO 139827261196096] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=221, train loss <loss>=5.12490844727\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:12 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:13 INFO 139827261196096] Epoch[222] Batch[0] avg_epoch_loss=5.140576\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=222, batch=0 train loss <loss>=5.14057588577\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:13 INFO 139827261196096] Epoch[222] Batch[5] avg_epoch_loss=5.135612\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=222, batch=5 train loss <loss>=5.13561209043\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:13 INFO 139827261196096] Epoch[222] Batch [5]#011Speed: 929.83 samples/sec#011loss=5.135612\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:14 INFO 139827261196096] Epoch[222] Batch[10] avg_epoch_loss=5.113366\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=222, batch=10 train loss <loss>=5.08667020798\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:14 INFO 139827261196096] Epoch[222] Batch [10]#011Speed: 933.86 samples/sec#011loss=5.086670\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:14 INFO 139827261196096] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1250.0858306884766, \"sum\": 1250.0858306884766, \"min\": 1250.0858306884766}}, \"EndTime\": 1601803334.234062, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803332.983612}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:14 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=516.727658443 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:14 INFO 139827261196096] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=222, train loss <loss>=5.11336578022\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:14 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:14 INFO 139827261196096] Epoch[223] Batch[0] avg_epoch_loss=5.318551\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=223, batch=0 train loss <loss>=5.31855106354\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:15 INFO 139827261196096] Epoch[223] Batch[5] avg_epoch_loss=5.205508\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=223, batch=5 train loss <loss>=5.20550767581\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:15 INFO 139827261196096] Epoch[223] Batch [5]#011Speed: 971.24 samples/sec#011loss=5.205508\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:15 INFO 139827261196096] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1145.7300186157227, \"sum\": 1145.7300186157227, \"min\": 1145.7300186157227}}, \"EndTime\": 1601803335.380118, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803334.234123}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:15 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=529.751664042 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:15 INFO 139827261196096] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=223, train loss <loss>=5.18454561234\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:15 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:15 INFO 139827261196096] Epoch[224] Batch[0] avg_epoch_loss=5.098718\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=224, batch=0 train loss <loss>=5.09871816635\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:16 INFO 139827261196096] Epoch[224] Batch[5] avg_epoch_loss=5.124520\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=224, batch=5 train loss <loss>=5.12452046076\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:16 INFO 139827261196096] Epoch[224] Batch [5]#011Speed: 989.98 samples/sec#011loss=5.124520\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:16 INFO 139827261196096] processed a total of 621 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1126.1000633239746, \"sum\": 1126.1000633239746, \"min\": 1126.1000633239746}}, \"EndTime\": 1601803336.506601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803335.38018}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:16 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=551.419667971 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:16 INFO 139827261196096] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=224, train loss <loss>=5.12358121872\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:16 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:17 INFO 139827261196096] Epoch[225] Batch[0] avg_epoch_loss=5.147998\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=225, batch=0 train loss <loss>=5.14799833298\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:17 INFO 139827261196096] Epoch[225] Batch[5] avg_epoch_loss=5.117755\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=225, batch=5 train loss <loss>=5.11775501569\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:17 INFO 139827261196096] Epoch[225] Batch [5]#011Speed: 1022.08 samples/sec#011loss=5.117755\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:17 INFO 139827261196096] processed a total of 604 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1094.0399169921875, \"sum\": 1094.0399169921875, \"min\": 1094.0399169921875}}, \"EndTime\": 1601803337.601039, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803336.506659}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:17 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=552.02569159 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:17 INFO 139827261196096] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=225, train loss <loss>=5.10201067924\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:17 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:18 INFO 139827261196096] Epoch[226] Batch[0] avg_epoch_loss=5.145624\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=226, batch=0 train loss <loss>=5.14562368393\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:18 INFO 139827261196096] Epoch[226] Batch[5] avg_epoch_loss=5.128288\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=226, batch=5 train loss <loss>=5.12828771273\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:18 INFO 139827261196096] Epoch[226] Batch [5]#011Speed: 1018.22 samples/sec#011loss=5.128288\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:18 INFO 139827261196096] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1099.7118949890137, \"sum\": 1099.7118949890137, \"min\": 1099.7118949890137}}, \"EndTime\": 1601803338.701204, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803337.601121}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:18 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=581.013664277 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:18 INFO 139827261196096] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=226, train loss <loss>=5.12480430603\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:18 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] Epoch[227] Batch[0] avg_epoch_loss=5.053779\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=227, batch=0 train loss <loss>=5.05377864838\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] Epoch[227] Batch[5] avg_epoch_loss=5.103455\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=227, batch=5 train loss <loss>=5.10345538457\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] Epoch[227] Batch [5]#011Speed: 993.02 samples/sec#011loss=5.103455\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] Epoch[227] Batch[10] avg_epoch_loss=5.139595\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=227, batch=10 train loss <loss>=5.18296175003\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] Epoch[227] Batch [10]#011Speed: 984.66 samples/sec#011loss=5.182962\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1174.1669178009033, \"sum\": 1174.1669178009033, \"min\": 1174.1669178009033}}, \"EndTime\": 1601803339.875791, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803338.701263}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=556.099126811 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=227, train loss <loss>=5.1395946416\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:19 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:20 INFO 139827261196096] Epoch[228] Batch[0] avg_epoch_loss=5.180697\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=228, batch=0 train loss <loss>=5.18069696426\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:20 INFO 139827261196096] Epoch[228] Batch[5] avg_epoch_loss=5.108399\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=228, batch=5 train loss <loss>=5.1083993117\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:20 INFO 139827261196096] Epoch[228] Batch [5]#011Speed: 1020.08 samples/sec#011loss=5.108399\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] Epoch[228] Batch[10] avg_epoch_loss=5.110057\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=228, batch=10 train loss <loss>=5.11204710007\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] Epoch[228] Batch [10]#011Speed: 1004.98 samples/sec#011loss=5.112047\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1163.1159782409668, \"sum\": 1163.1159782409668, \"min\": 1163.1159782409668}}, \"EndTime\": 1601803341.03922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803339.875848}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=552.786372731 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=228, train loss <loss>=5.11005739732\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] Epoch[229] Batch[0] avg_epoch_loss=5.201149\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=229, batch=0 train loss <loss>=5.20114898682\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] Epoch[229] Batch[5] avg_epoch_loss=5.171564\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=229, batch=5 train loss <loss>=5.17156362534\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:21 INFO 139827261196096] Epoch[229] Batch [5]#011Speed: 1016.08 samples/sec#011loss=5.171564\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:22 INFO 139827261196096] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1096.9769954681396, \"sum\": 1096.9769954681396, \"min\": 1096.9769954681396}}, \"EndTime\": 1601803342.136551, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803341.039275}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:22 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=552.381882774 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:22 INFO 139827261196096] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=229, train loss <loss>=5.14932360649\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:22 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:22 INFO 139827261196096] Epoch[230] Batch[0] avg_epoch_loss=5.120220\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=230, batch=0 train loss <loss>=5.12022018433\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:22 INFO 139827261196096] Epoch[230] Batch[5] avg_epoch_loss=5.120334\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=230, batch=5 train loss <loss>=5.12033390999\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:22 INFO 139827261196096] Epoch[230] Batch [5]#011Speed: 1024.72 samples/sec#011loss=5.120334\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:23 INFO 139827261196096] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1110.502004623413, \"sum\": 1110.502004623413, \"min\": 1110.502004623413}}, \"EndTime\": 1601803343.247468, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803342.13661}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:23 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=550.160513734 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:23 INFO 139827261196096] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=230, train loss <loss>=5.11753387451\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:23 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:23 INFO 139827261196096] Epoch[231] Batch[0] avg_epoch_loss=5.031832\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=231, batch=0 train loss <loss>=5.03183221817\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:24 INFO 139827261196096] Epoch[231] Batch[5] avg_epoch_loss=5.087042\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=231, batch=5 train loss <loss>=5.08704185486\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:24 INFO 139827261196096] Epoch[231] Batch [5]#011Speed: 1022.86 samples/sec#011loss=5.087042\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:24 INFO 139827261196096] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1094.6578979492188, \"sum\": 1094.6578979492188, \"min\": 1094.6578979492188}}, \"EndTime\": 1601803344.342532, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803343.247526}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:24 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=569.081843162 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:24 INFO 139827261196096] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=231, train loss <loss>=5.09858288765\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:24 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:24 INFO 139827261196096] Epoch[232] Batch[0] avg_epoch_loss=5.108750\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=232, batch=0 train loss <loss>=5.10875034332\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:25 INFO 139827261196096] Epoch[232] Batch[5] avg_epoch_loss=5.120976\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=232, batch=5 train loss <loss>=5.12097589175\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:25 INFO 139827261196096] Epoch[232] Batch [5]#011Speed: 1013.94 samples/sec#011loss=5.120976\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:25 INFO 139827261196096] processed a total of 580 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1086.6458415985107, \"sum\": 1086.6458415985107, \"min\": 1086.6458415985107}}, \"EndTime\": 1601803345.42961, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803344.342594}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:25 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=533.710287042 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:25 INFO 139827261196096] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=232, train loss <loss>=5.08659892082\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:25 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:25 INFO 139827261196096] Epoch[233] Batch[0] avg_epoch_loss=5.072089\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=233, batch=0 train loss <loss>=5.07208871841\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:26 INFO 139827261196096] Epoch[233] Batch[5] avg_epoch_loss=5.100792\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=233, batch=5 train loss <loss>=5.1007920901\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:26 INFO 139827261196096] Epoch[233] Batch [5]#011Speed: 1016.90 samples/sec#011loss=5.100792\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:26 INFO 139827261196096] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1092.5769805908203, \"sum\": 1092.5769805908203, \"min\": 1092.5769805908203}}, \"EndTime\": 1601803346.522629, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803345.42967}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:26 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=580.237947443 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:26 INFO 139827261196096] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=233, train loss <loss>=5.10367884636\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:26 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] Epoch[234] Batch[0] avg_epoch_loss=5.071120\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=234, batch=0 train loss <loss>=5.07111978531\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] Epoch[234] Batch[5] avg_epoch_loss=5.090834\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=234, batch=5 train loss <loss>=5.09083390236\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] Epoch[234] Batch [5]#011Speed: 981.73 samples/sec#011loss=5.090834\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] Epoch[234] Batch[10] avg_epoch_loss=5.109816\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=234, batch=10 train loss <loss>=5.13259429932\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] Epoch[234] Batch [10]#011Speed: 993.35 samples/sec#011loss=5.132594\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1252.8250217437744, \"sum\": 1252.8250217437744, \"min\": 1252.8250217437744}}, \"EndTime\": 1601803347.775892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803346.52268}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=563.482347568 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=234, train loss <loss>=5.10439411799\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:27 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:28 INFO 139827261196096] Epoch[235] Batch[0] avg_epoch_loss=5.097142\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=235, batch=0 train loss <loss>=5.09714174271\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:28 INFO 139827261196096] Epoch[235] Batch[5] avg_epoch_loss=5.098570\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=235, batch=5 train loss <loss>=5.09856987\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:28 INFO 139827261196096] Epoch[235] Batch [5]#011Speed: 985.07 samples/sec#011loss=5.098570\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:28 INFO 139827261196096] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1174.3321418762207, \"sum\": 1174.3321418762207, \"min\": 1174.3321418762207}}, \"EndTime\": 1601803348.950614, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803347.775959}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:28 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=527.916574975 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:28 INFO 139827261196096] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=235, train loss <loss>=5.110476017\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:28 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:29 INFO 139827261196096] Epoch[236] Batch[0] avg_epoch_loss=5.165087\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=236, batch=0 train loss <loss>=5.16508722305\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:29 INFO 139827261196096] Epoch[236] Batch[5] avg_epoch_loss=5.113471\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=236, batch=5 train loss <loss>=5.11347087224\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:29 INFO 139827261196096] Epoch[236] Batch [5]#011Speed: 1020.58 samples/sec#011loss=5.113471\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:30 INFO 139827261196096] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1140.1238441467285, \"sum\": 1140.1238441467285, \"min\": 1140.1238441467285}}, \"EndTime\": 1601803350.091121, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803348.95068}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:30 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=555.156522476 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:30 INFO 139827261196096] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=236, train loss <loss>=5.11312003136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:30 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:30 INFO 139827261196096] Epoch[237] Batch[0] avg_epoch_loss=5.111692\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=237, batch=0 train loss <loss>=5.11169195175\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:30 INFO 139827261196096] Epoch[237] Batch[5] avg_epoch_loss=5.084442\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=237, batch=5 train loss <loss>=5.08444190025\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:30 INFO 139827261196096] Epoch[237] Batch [5]#011Speed: 1023.88 samples/sec#011loss=5.084442\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:31 INFO 139827261196096] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1096.0700511932373, \"sum\": 1096.0700511932373, \"min\": 1096.0700511932373}}, \"EndTime\": 1601803351.187617, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803350.091188}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:31 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=570.171155313 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:31 INFO 139827261196096] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=237, train loss <loss>=5.09849438667\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:31 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:31 INFO 139827261196096] Epoch[238] Batch[0] avg_epoch_loss=5.015780\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=238, batch=0 train loss <loss>=5.01577997208\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:32 INFO 139827261196096] Epoch[238] Batch[5] avg_epoch_loss=5.101471\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=238, batch=5 train loss <loss>=5.10147118568\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:32 INFO 139827261196096] Epoch[238] Batch [5]#011Speed: 1001.58 samples/sec#011loss=5.101471\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:32 INFO 139827261196096] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1109.5800399780273, \"sum\": 1109.5800399780273, \"min\": 1109.5800399780273}}, \"EndTime\": 1601803352.297606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803351.187681}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:32 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=561.426642769 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:32 INFO 139827261196096] #progress_metric: host=algo-1, completed 59 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=238, train loss <loss>=5.11448640823\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:32 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:32 INFO 139827261196096] Epoch[239] Batch[0] avg_epoch_loss=5.089088\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=239, batch=0 train loss <loss>=5.08908843994\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] Epoch[239] Batch[5] avg_epoch_loss=5.106038\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=239, batch=5 train loss <loss>=5.1060376962\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] Epoch[239] Batch [5]#011Speed: 1018.67 samples/sec#011loss=5.106038\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] Epoch[239] Batch[10] avg_epoch_loss=5.100415\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=239, batch=10 train loss <loss>=5.09366836548\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] Epoch[239] Batch [10]#011Speed: 897.70 samples/sec#011loss=5.093668\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1212.1219635009766, \"sum\": 1212.1219635009766, \"min\": 1212.1219635009766}}, \"EndTime\": 1601803353.510098, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803352.29767}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.10733927 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=239, train loss <loss>=5.10041527315\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:33 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] Epoch[240] Batch[0] avg_epoch_loss=5.131097\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=240, batch=0 train loss <loss>=5.13109731674\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] Epoch[240] Batch[5] avg_epoch_loss=5.125406\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=240, batch=5 train loss <loss>=5.12540578842\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] Epoch[240] Batch [5]#011Speed: 986.24 samples/sec#011loss=5.125406\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] Epoch[240] Batch[10] avg_epoch_loss=5.118933\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=240, batch=10 train loss <loss>=5.1111656189\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] Epoch[240] Batch [10]#011Speed: 990.99 samples/sec#011loss=5.111166\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1178.9419651031494, \"sum\": 1178.9419651031494, \"min\": 1178.9419651031494}}, \"EndTime\": 1601803354.689435, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803353.510163}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=558.0902003 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=240, train loss <loss>=5.11893298409\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:34 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] Epoch[241] Batch[0] avg_epoch_loss=5.125077\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=241, batch=0 train loss <loss>=5.12507677078\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] Epoch[241] Batch[5] avg_epoch_loss=5.093557\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=241, batch=5 train loss <loss>=5.09355680148\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] Epoch[241] Batch [5]#011Speed: 986.66 samples/sec#011loss=5.093557\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] Epoch[241] Batch[10] avg_epoch_loss=5.081914\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=241, batch=10 train loss <loss>=5.06794366837\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] Epoch[241] Batch [10]#011Speed: 999.43 samples/sec#011loss=5.067944\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1190.5040740966797, \"sum\": 1190.5040740966797, \"min\": 1190.5040740966797}}, \"EndTime\": 1601803355.880293, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803354.689489}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=539.231624375 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=241, train loss <loss>=5.08191446825\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:35 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_cd286f16-1318-48b4-a262-b0cd66b022b7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.67587661743164, \"sum\": 17.67587661743164, \"min\": 17.67587661743164}}, \"EndTime\": 1601803355.898378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803355.880343}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:36 INFO 139827261196096] Epoch[242] Batch[0] avg_epoch_loss=5.140891\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=242, batch=0 train loss <loss>=5.14089107513\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:36 INFO 139827261196096] Epoch[242] Batch[5] avg_epoch_loss=5.068070\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=242, batch=5 train loss <loss>=5.06806985537\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:36 INFO 139827261196096] Epoch[242] Batch [5]#011Speed: 1018.39 samples/sec#011loss=5.068070\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:36 INFO 139827261196096] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1086.395025253296, \"sum\": 1086.395025253296, \"min\": 1086.395025253296}}, \"EndTime\": 1601803356.984879, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803355.898436}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:36 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=570.649723471 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:36 INFO 139827261196096] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=242, train loss <loss>=5.08366103172\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:36 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:37 INFO 139827261196096] Epoch[243] Batch[0] avg_epoch_loss=5.156503\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=243, batch=0 train loss <loss>=5.15650272369\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:37 INFO 139827261196096] Epoch[243] Batch[5] avg_epoch_loss=5.125032\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=243, batch=5 train loss <loss>=5.12503202756\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:37 INFO 139827261196096] Epoch[243] Batch [5]#011Speed: 1025.79 samples/sec#011loss=5.125032\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:38 INFO 139827261196096] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1092.2369956970215, \"sum\": 1092.2369956970215, \"min\": 1092.2369956970215}}, \"EndTime\": 1601803358.077555, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803356.984939}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:38 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=578.587195256 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:38 INFO 139827261196096] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=243, train loss <loss>=5.12445259094\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:38 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:38 INFO 139827261196096] Epoch[244] Batch[0] avg_epoch_loss=5.104812\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=244, batch=0 train loss <loss>=5.1048116684\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:38 INFO 139827261196096] Epoch[244] Batch[5] avg_epoch_loss=5.032709\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:38 INFO 139827261196096] #quality_metric: host=algo-1, epoch=244, batch=5 train loss <loss>=5.03270896276\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:38 INFO 139827261196096] Epoch[244] Batch [5]#011Speed: 1012.20 samples/sec#011loss=5.032709\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:39 INFO 139827261196096] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1096.1267948150635, \"sum\": 1096.1267948150635, \"min\": 1096.1267948150635}}, \"EndTime\": 1601803359.174069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803358.077607}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:39 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=580.180298497 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:39 INFO 139827261196096] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=244, train loss <loss>=5.06394076347\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:39 INFO 139827261196096] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:39 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/state_373013e5-53d2-4b52-8cc9-d9fa2ae9ba29-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.59505271911621, \"sum\": 17.59505271911621, \"min\": 17.59505271911621}}, \"EndTime\": 1601803359.192131, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803359.174123}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:39 INFO 139827261196096] Epoch[245] Batch[0] avg_epoch_loss=5.117679\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:39 INFO 139827261196096] #quality_metric: host=algo-1, epoch=245, batch=0 train loss <loss>=5.11767911911\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] Epoch[245] Batch[5] avg_epoch_loss=5.102318\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=245, batch=5 train loss <loss>=5.10231812795\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] Epoch[245] Batch [5]#011Speed: 1020.45 samples/sec#011loss=5.102318\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] Epoch[245] Batch[10] avg_epoch_loss=5.098288\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=245, batch=10 train loss <loss>=5.09345293045\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] Epoch[245] Batch [10]#011Speed: 994.13 samples/sec#011loss=5.093453\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1165.5609607696533, \"sum\": 1165.5609607696533, \"min\": 1165.5609607696533}}, \"EndTime\": 1601803360.357797, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803359.192187}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=582.513148992 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=245, train loss <loss>=5.09828849272\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] Epoch[246] Batch[0] avg_epoch_loss=5.114136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:40 INFO 139827261196096] #quality_metric: host=algo-1, epoch=246, batch=0 train loss <loss>=5.11413621902\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:41 INFO 139827261196096] Epoch[246] Batch[5] avg_epoch_loss=5.122042\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=246, batch=5 train loss <loss>=5.12204178174\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:41 INFO 139827261196096] Epoch[246] Batch [5]#011Speed: 1019.53 samples/sec#011loss=5.122042\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:41 INFO 139827261196096] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1093.0500030517578, \"sum\": 1093.0500030517578, \"min\": 1093.0500030517578}}, \"EndTime\": 1601803361.451227, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803360.357849}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:41 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=571.752739798 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:41 INFO 139827261196096] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=246, train loss <loss>=5.12360129356\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:41 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:41 INFO 139827261196096] Epoch[247] Batch[0] avg_epoch_loss=5.073136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:41 INFO 139827261196096] #quality_metric: host=algo-1, epoch=247, batch=0 train loss <loss>=5.07313632965\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:42 INFO 139827261196096] Epoch[247] Batch[5] avg_epoch_loss=5.087726\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=247, batch=5 train loss <loss>=5.08772579829\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:42 INFO 139827261196096] Epoch[247] Batch [5]#011Speed: 1006.12 samples/sec#011loss=5.087726\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:42 INFO 139827261196096] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1104.5031547546387, \"sum\": 1104.5031547546387, \"min\": 1104.5031547546387}}, \"EndTime\": 1601803362.556141, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803361.45128}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:42 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=574.870244351 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:42 INFO 139827261196096] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:42 INFO 139827261196096] #quality_metric: host=algo-1, epoch=247, train loss <loss>=5.10145487785\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:42 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] Epoch[248] Batch[0] avg_epoch_loss=5.154543\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=248, batch=0 train loss <loss>=5.15454292297\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] Epoch[248] Batch[5] avg_epoch_loss=5.111141\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=248, batch=5 train loss <loss>=5.111140728\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] Epoch[248] Batch [5]#011Speed: 1012.62 samples/sec#011loss=5.111141\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] Epoch[248] Batch[10] avg_epoch_loss=5.124120\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=248, batch=10 train loss <loss>=5.13969449997\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] Epoch[248] Batch [10]#011Speed: 998.19 samples/sec#011loss=5.139694\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1170.8199977874756, \"sum\": 1170.8199977874756, \"min\": 1170.8199977874756}}, \"EndTime\": 1601803363.727324, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803362.556204}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=547.442200236 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] #quality_metric: host=algo-1, epoch=248, train loss <loss>=5.12411971526\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:43 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] Epoch[249] Batch[0] avg_epoch_loss=5.141456\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=249, batch=0 train loss <loss>=5.14145612717\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] Epoch[249] Batch[5] avg_epoch_loss=5.083057\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=249, batch=5 train loss <loss>=5.08305668831\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] Epoch[249] Batch [5]#011Speed: 953.49 samples/sec#011loss=5.083057\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] Epoch[249] Batch[10] avg_epoch_loss=5.127906\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=249, batch=10 train loss <loss>=5.18172464371\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] Epoch[249] Batch [10]#011Speed: 992.02 samples/sec#011loss=5.181725\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1182.2190284729004, \"sum\": 1182.2190284729004, \"min\": 1182.2190284729004}}, \"EndTime\": 1601803364.909924, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803363.727379}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=543.853839673 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] #quality_metric: host=algo-1, epoch=249, train loss <loss>=5.12790575894\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:44 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:45 INFO 139827261196096] Epoch[250] Batch[0] avg_epoch_loss=5.136244\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=250, batch=0 train loss <loss>=5.13624382019\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:45 INFO 139827261196096] Epoch[250] Batch[5] avg_epoch_loss=5.144014\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:45 INFO 139827261196096] #quality_metric: host=algo-1, epoch=250, batch=5 train loss <loss>=5.14401364326\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:45 INFO 139827261196096] Epoch[250] Batch [5]#011Speed: 1002.43 samples/sec#011loss=5.144014\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:46 INFO 139827261196096] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1132.8070163726807, \"sum\": 1132.8070163726807, \"min\": 1132.8070163726807}}, \"EndTime\": 1601803366.043106, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803364.909982}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:46 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=527.849883347 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:46 INFO 139827261196096] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=250, train loss <loss>=5.13966054916\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:46 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:46 INFO 139827261196096] Epoch[251] Batch[0] avg_epoch_loss=5.076529\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=251, batch=0 train loss <loss>=5.07652854919\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:46 INFO 139827261196096] Epoch[251] Batch[5] avg_epoch_loss=5.117531\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:46 INFO 139827261196096] #quality_metric: host=algo-1, epoch=251, batch=5 train loss <loss>=5.11753074328\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:46 INFO 139827261196096] Epoch[251] Batch [5]#011Speed: 1001.66 samples/sec#011loss=5.117531\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:47 INFO 139827261196096] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1138.8168334960938, \"sum\": 1138.8168334960938, \"min\": 1138.8168334960938}}, \"EndTime\": 1601803367.182284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803366.043167}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:47 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=533.845636873 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:47 INFO 139827261196096] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=251, train loss <loss>=5.15045948029\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:47 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:47 INFO 139827261196096] Epoch[252] Batch[0] avg_epoch_loss=5.133552\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:47 INFO 139827261196096] #quality_metric: host=algo-1, epoch=252, batch=0 train loss <loss>=5.13355207443\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] Epoch[252] Batch[5] avg_epoch_loss=5.097435\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=252, batch=5 train loss <loss>=5.09743460019\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] Epoch[252] Batch [5]#011Speed: 1003.45 samples/sec#011loss=5.097435\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] Epoch[252] Batch[10] avg_epoch_loss=5.081911\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=252, batch=10 train loss <loss>=5.06328172684\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] Epoch[252] Batch [10]#011Speed: 973.78 samples/sec#011loss=5.063282\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1211.3971710205078, \"sum\": 1211.3971710205078, \"min\": 1211.3971710205078}}, \"EndTime\": 1601803368.394036, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803367.182345}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=539.832960597 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=252, train loss <loss>=5.08191056685\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] Epoch[253] Batch[0] avg_epoch_loss=5.035217\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:48 INFO 139827261196096] #quality_metric: host=algo-1, epoch=253, batch=0 train loss <loss>=5.03521680832\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:49 INFO 139827261196096] Epoch[253] Batch[5] avg_epoch_loss=5.099417\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=253, batch=5 train loss <loss>=5.09941720963\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:49 INFO 139827261196096] Epoch[253] Batch [5]#011Speed: 984.29 samples/sec#011loss=5.099417\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:49 INFO 139827261196096] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1120.9678649902344, \"sum\": 1120.9678649902344, \"min\": 1120.9678649902344}}, \"EndTime\": 1601803369.515341, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803368.394096}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:49 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=548.594295378 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:49 INFO 139827261196096] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:49 INFO 139827261196096] #quality_metric: host=algo-1, epoch=253, train loss <loss>=5.12051072121\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:49 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:50 INFO 139827261196096] Epoch[254] Batch[0] avg_epoch_loss=5.096889\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=254, batch=0 train loss <loss>=5.09688901901\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:50 INFO 139827261196096] Epoch[254] Batch[5] avg_epoch_loss=5.084679\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=254, batch=5 train loss <loss>=5.08467896779\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:50 INFO 139827261196096] Epoch[254] Batch [5]#011Speed: 1019.60 samples/sec#011loss=5.084679\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:50 INFO 139827261196096] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1114.5389080047607, \"sum\": 1114.5389080047607, \"min\": 1114.5389080047607}}, \"EndTime\": 1601803370.630287, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803369.515393}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:50 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=564.311863798 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:50 INFO 139827261196096] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:50 INFO 139827261196096] #quality_metric: host=algo-1, epoch=254, train loss <loss>=5.09495396614\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:50 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] Epoch[255] Batch[0] avg_epoch_loss=5.097507\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=255, batch=0 train loss <loss>=5.09750652313\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] Epoch[255] Batch[5] avg_epoch_loss=5.090603\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=255, batch=5 train loss <loss>=5.09060343107\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] Epoch[255] Batch [5]#011Speed: 963.57 samples/sec#011loss=5.090603\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] Epoch[255] Batch[10] avg_epoch_loss=5.108510\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=255, batch=10 train loss <loss>=5.12999858856\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] Epoch[255] Batch [10]#011Speed: 1001.99 samples/sec#011loss=5.129999\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1200.6759643554688, \"sum\": 1200.6759643554688, \"min\": 1200.6759643554688}}, \"EndTime\": 1601803371.831323, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803370.63035}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=557.147634754 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] #quality_metric: host=algo-1, epoch=255, train loss <loss>=5.10851032084\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:51 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] Epoch[256] Batch[0] avg_epoch_loss=5.114328\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=256, batch=0 train loss <loss>=5.11432790756\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] Epoch[256] Batch[5] avg_epoch_loss=5.087628\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=256, batch=5 train loss <loss>=5.08762772878\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] Epoch[256] Batch [5]#011Speed: 1007.59 samples/sec#011loss=5.087628\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] Epoch[256] Batch[10] avg_epoch_loss=5.097964\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=256, batch=10 train loss <loss>=5.11036748886\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] Epoch[256] Batch [10]#011Speed: 1004.35 samples/sec#011loss=5.110367\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1165.5609607696533, \"sum\": 1165.5609607696533, \"min\": 1165.5609607696533}}, \"EndTime\": 1601803372.997249, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803371.831378}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=570.499534676 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] #quality_metric: host=algo-1, epoch=256, train loss <loss>=5.09796398336\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:52 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:53 INFO 139827261196096] Epoch[257] Batch[0] avg_epoch_loss=5.077495\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=257, batch=0 train loss <loss>=5.07749509811\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:53 INFO 139827261196096] Epoch[257] Batch[5] avg_epoch_loss=5.088640\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:53 INFO 139827261196096] #quality_metric: host=algo-1, epoch=257, batch=5 train loss <loss>=5.08863997459\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:53 INFO 139827261196096] Epoch[257] Batch [5]#011Speed: 987.46 samples/sec#011loss=5.088640\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:54 INFO 139827261196096] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1110.5990409851074, \"sum\": 1110.5990409851074, \"min\": 1110.5990409851074}}, \"EndTime\": 1601803374.10825, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803372.997302}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:54 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=575.31650304 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:54 INFO 139827261196096] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=257, train loss <loss>=5.08868021965\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:54 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:54 INFO 139827261196096] Epoch[258] Batch[0] avg_epoch_loss=5.143309\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=258, batch=0 train loss <loss>=5.14330863953\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:54 INFO 139827261196096] Epoch[258] Batch[5] avg_epoch_loss=5.128508\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:54 INFO 139827261196096] #quality_metric: host=algo-1, epoch=258, batch=5 train loss <loss>=5.12850824992\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:54 INFO 139827261196096] Epoch[258] Batch [5]#011Speed: 1000.52 samples/sec#011loss=5.128508\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:55 INFO 139827261196096] Epoch[258] Batch[10] avg_epoch_loss=5.082967\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=258, batch=10 train loss <loss>=5.02831735611\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:55 INFO 139827261196096] Epoch[258] Batch [10]#011Speed: 985.93 samples/sec#011loss=5.028317\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:55 INFO 139827261196096] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1176.9020557403564, \"sum\": 1176.9020557403564, \"min\": 1176.9020557403564}}, \"EndTime\": 1601803375.285542, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803374.108314}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:55 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=545.460601247 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:55 INFO 139827261196096] #progress_metric: host=algo-1, completed 64 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=258, train loss <loss>=5.08296693455\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:55 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:55 INFO 139827261196096] Epoch[259] Batch[0] avg_epoch_loss=5.069795\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:55 INFO 139827261196096] #quality_metric: host=algo-1, epoch=259, batch=0 train loss <loss>=5.06979465485\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:56 INFO 139827261196096] Epoch[259] Batch[5] avg_epoch_loss=5.080553\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=259, batch=5 train loss <loss>=5.08055281639\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:56 INFO 139827261196096] Epoch[259] Batch [5]#011Speed: 1022.43 samples/sec#011loss=5.080553\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:56 INFO 139827261196096] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1102.1389961242676, \"sum\": 1102.1389961242676, \"min\": 1102.1389961242676}}, \"EndTime\": 1601803376.38805, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803375.285598}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:56 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=561.588256517 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:56 INFO 139827261196096] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=259, train loss <loss>=5.076364851\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:56 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:56 INFO 139827261196096] Epoch[260] Batch[0] avg_epoch_loss=5.124032\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:56 INFO 139827261196096] #quality_metric: host=algo-1, epoch=260, batch=0 train loss <loss>=5.12403202057\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] Epoch[260] Batch[5] avg_epoch_loss=5.110313\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=260, batch=5 train loss <loss>=5.11031325658\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] Epoch[260] Batch [5]#011Speed: 1017.64 samples/sec#011loss=5.110313\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] Epoch[260] Batch[10] avg_epoch_loss=5.110079\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=260, batch=10 train loss <loss>=5.10979795456\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] Epoch[260] Batch [10]#011Speed: 975.49 samples/sec#011loss=5.109798\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1176.0659217834473, \"sum\": 1176.0659217834473, \"min\": 1176.0659217834473}}, \"EndTime\": 1601803377.564548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803376.388112}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=565.404605518 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] #quality_metric: host=algo-1, epoch=260, train loss <loss>=5.11007902839\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:57 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:58 INFO 139827261196096] Epoch[261] Batch[0] avg_epoch_loss=5.129539\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=261, batch=0 train loss <loss>=5.12953948975\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:58 INFO 139827261196096] Epoch[261] Batch[5] avg_epoch_loss=5.098152\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=261, batch=5 train loss <loss>=5.09815160433\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:58 INFO 139827261196096] Epoch[261] Batch [5]#011Speed: 1017.34 samples/sec#011loss=5.098152\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:58 INFO 139827261196096] processed a total of 598 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1094.6941375732422, \"sum\": 1094.6941375732422, \"min\": 1094.6941375732422}}, \"EndTime\": 1601803378.659606, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803377.564601}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:58 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=546.227411224 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:58 INFO 139827261196096] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:58 INFO 139827261196096] #quality_metric: host=algo-1, epoch=261, train loss <loss>=5.12011342049\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:58 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:59 INFO 139827261196096] Epoch[262] Batch[0] avg_epoch_loss=5.139708\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=262, batch=0 train loss <loss>=5.13970804214\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:59 INFO 139827261196096] Epoch[262] Batch[5] avg_epoch_loss=5.086696\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=262, batch=5 train loss <loss>=5.08669622739\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:59 INFO 139827261196096] Epoch[262] Batch [5]#011Speed: 1011.36 samples/sec#011loss=5.086696\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:59 INFO 139827261196096] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1094.5560932159424, \"sum\": 1094.5560932159424, \"min\": 1094.5560932159424}}, \"EndTime\": 1601803379.75456, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803378.659668}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:59 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=550.861590533 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:59 INFO 139827261196096] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:59 INFO 139827261196096] #quality_metric: host=algo-1, epoch=262, train loss <loss>=5.08073515892\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:22:59 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] Epoch[263] Batch[0] avg_epoch_loss=5.163230\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=263, batch=0 train loss <loss>=5.16323041916\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] Epoch[263] Batch[5] avg_epoch_loss=5.125739\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=263, batch=5 train loss <loss>=5.12573862076\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] Epoch[263] Batch [5]#011Speed: 1014.44 samples/sec#011loss=5.125739\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] Epoch[263] Batch[10] avg_epoch_loss=5.141486\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=263, batch=10 train loss <loss>=5.16038360596\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] Epoch[263] Batch [10]#011Speed: 1000.69 samples/sec#011loss=5.160384\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1163.6929512023926, \"sum\": 1163.6929512023926, \"min\": 1163.6929512023926}}, \"EndTime\": 1601803380.918709, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803379.754624}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=564.541552735 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] #quality_metric: host=algo-1, epoch=263, train loss <loss>=5.1414863413\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:00 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:01 INFO 139827261196096] Epoch[264] Batch[0] avg_epoch_loss=5.104302\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=264, batch=0 train loss <loss>=5.10430240631\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:01 INFO 139827261196096] Epoch[264] Batch[5] avg_epoch_loss=5.111895\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:01 INFO 139827261196096] #quality_metric: host=algo-1, epoch=264, batch=5 train loss <loss>=5.1118953228\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:01 INFO 139827261196096] Epoch[264] Batch [5]#011Speed: 935.56 samples/sec#011loss=5.111895\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:02 INFO 139827261196096] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1135.936975479126, \"sum\": 1135.936975479126, \"min\": 1135.936975479126}}, \"EndTime\": 1601803382.05502, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803380.91876}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:02 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=561.607382755 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:02 INFO 139827261196096] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=264, train loss <loss>=5.11077580452\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:02 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:02 INFO 139827261196096] Epoch[265] Batch[0] avg_epoch_loss=5.109344\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=265, batch=0 train loss <loss>=5.10934352875\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:02 INFO 139827261196096] Epoch[265] Batch[5] avg_epoch_loss=5.098297\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:02 INFO 139827261196096] #quality_metric: host=algo-1, epoch=265, batch=5 train loss <loss>=5.09829735756\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:02 INFO 139827261196096] Epoch[265] Batch [5]#011Speed: 944.40 samples/sec#011loss=5.098297\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:03 INFO 139827261196096] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1149.7461795806885, \"sum\": 1149.7461795806885, \"min\": 1149.7461795806885}}, \"EndTime\": 1601803383.205176, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803382.055076}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:03 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=527.894116896 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:03 INFO 139827261196096] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=265, train loss <loss>=5.10719099045\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:03 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:03 INFO 139827261196096] Epoch[266] Batch[0] avg_epoch_loss=5.122560\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:03 INFO 139827261196096] #quality_metric: host=algo-1, epoch=266, batch=0 train loss <loss>=5.12256002426\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:04 INFO 139827261196096] Epoch[266] Batch[5] avg_epoch_loss=5.095948\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=266, batch=5 train loss <loss>=5.09594798088\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:04 INFO 139827261196096] Epoch[266] Batch [5]#011Speed: 921.47 samples/sec#011loss=5.095948\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:04 INFO 139827261196096] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1206.2230110168457, \"sum\": 1206.2230110168457, \"min\": 1206.2230110168457}}, \"EndTime\": 1601803384.411785, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803383.205253}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:04 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=518.105959689 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:04 INFO 139827261196096] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=266, train loss <loss>=5.09125108719\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:04 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:04 INFO 139827261196096] Epoch[267] Batch[0] avg_epoch_loss=5.123116\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:04 INFO 139827261196096] #quality_metric: host=algo-1, epoch=267, batch=0 train loss <loss>=5.12311553955\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:05 INFO 139827261196096] Epoch[267] Batch[5] avg_epoch_loss=5.101350\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=267, batch=5 train loss <loss>=5.10135038694\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:05 INFO 139827261196096] Epoch[267] Batch [5]#011Speed: 910.60 samples/sec#011loss=5.101350\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:05 INFO 139827261196096] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1185.9338283538818, \"sum\": 1185.9338283538818, \"min\": 1185.9338283538818}}, \"EndTime\": 1601803385.598092, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803384.41185}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:05 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=535.397820965 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:05 INFO 139827261196096] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:05 INFO 139827261196096] #quality_metric: host=algo-1, epoch=267, train loss <loss>=5.0819542408\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:05 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] Epoch[268] Batch[0] avg_epoch_loss=5.031372\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=268, batch=0 train loss <loss>=5.03137159348\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] Epoch[268] Batch[5] avg_epoch_loss=5.093252\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=268, batch=5 train loss <loss>=5.09325202306\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] Epoch[268] Batch [5]#011Speed: 909.96 samples/sec#011loss=5.093252\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] Epoch[268] Batch[10] avg_epoch_loss=5.150417\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=268, batch=10 train loss <loss>=5.21901445389\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] Epoch[268] Batch [10]#011Speed: 942.51 samples/sec#011loss=5.219014\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1238.3818626403809, \"sum\": 1238.3818626403809, \"min\": 1238.3818626403809}}, \"EndTime\": 1601803386.836941, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803385.59816}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=533.723541851 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] #quality_metric: host=algo-1, epoch=268, train loss <loss>=5.15041676435\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:06 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:07 INFO 139827261196096] Epoch[269] Batch[0] avg_epoch_loss=5.137747\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=269, batch=0 train loss <loss>=5.13774681091\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:07 INFO 139827261196096] Epoch[269] Batch[5] avg_epoch_loss=5.114302\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=269, batch=5 train loss <loss>=5.11430223783\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:07 INFO 139827261196096] Epoch[269] Batch [5]#011Speed: 982.86 samples/sec#011loss=5.114302\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:07 INFO 139827261196096] processed a total of 571 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1063.673973083496, \"sum\": 1063.673973083496, \"min\": 1063.673973083496}}, \"EndTime\": 1601803387.900925, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803386.836999}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:07 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=536.773266268 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:07 INFO 139827261196096] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:07 INFO 139827261196096] #quality_metric: host=algo-1, epoch=269, train loss <loss>=5.09920162625\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:07 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:08 INFO 139827261196096] Epoch[270] Batch[0] avg_epoch_loss=5.076542\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=270, batch=0 train loss <loss>=5.07654190063\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:08 INFO 139827261196096] Epoch[270] Batch[5] avg_epoch_loss=5.095554\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:08 INFO 139827261196096] #quality_metric: host=algo-1, epoch=270, batch=5 train loss <loss>=5.09555419286\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:08 INFO 139827261196096] Epoch[270] Batch [5]#011Speed: 979.88 samples/sec#011loss=5.095554\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:09 INFO 139827261196096] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1152.9908180236816, \"sum\": 1152.9908180236816, \"min\": 1152.9908180236816}}, \"EndTime\": 1601803389.05429, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803387.900988}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:09 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=542.890565849 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:09 INFO 139827261196096] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=270, train loss <loss>=5.09954285622\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:09 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:09 INFO 139827261196096] Epoch[271] Batch[0] avg_epoch_loss=5.142650\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=271, batch=0 train loss <loss>=5.14264965057\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:09 INFO 139827261196096] Epoch[271] Batch[5] avg_epoch_loss=5.101530\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:09 INFO 139827261196096] #quality_metric: host=algo-1, epoch=271, batch=5 train loss <loss>=5.10153039296\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:09 INFO 139827261196096] Epoch[271] Batch [5]#011Speed: 948.13 samples/sec#011loss=5.101530\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:10 INFO 139827261196096] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1132.521152496338, \"sum\": 1132.521152496338, \"min\": 1132.521152496338}}, \"EndTime\": 1601803390.187197, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803389.054355}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:10 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=549.171679545 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:10 INFO 139827261196096] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=271, train loss <loss>=5.09019069672\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:10 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:10 INFO 139827261196096] Epoch[272] Batch[0] avg_epoch_loss=5.066341\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:10 INFO 139827261196096] #quality_metric: host=algo-1, epoch=272, batch=0 train loss <loss>=5.06634092331\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] Epoch[272] Batch[5] avg_epoch_loss=5.085559\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=272, batch=5 train loss <loss>=5.08555944761\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] Epoch[272] Batch [5]#011Speed: 953.64 samples/sec#011loss=5.085559\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] Epoch[272] Batch[10] avg_epoch_loss=5.085637\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=272, batch=10 train loss <loss>=5.08572940826\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] Epoch[272] Batch [10]#011Speed: 933.42 samples/sec#011loss=5.085729\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1261.5878582000732, \"sum\": 1261.5878582000732, \"min\": 1261.5878582000732}}, \"EndTime\": 1601803391.44918, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803390.187261}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=514.391900355 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] #quality_metric: host=algo-1, epoch=272, train loss <loss>=5.08563670245\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:11 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:12 INFO 139827261196096] Epoch[273] Batch[0] avg_epoch_loss=5.054479\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=273, batch=0 train loss <loss>=5.05447864532\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:12 INFO 139827261196096] Epoch[273] Batch[5] avg_epoch_loss=5.078472\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=273, batch=5 train loss <loss>=5.07847205798\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:12 INFO 139827261196096] Epoch[273] Batch [5]#011Speed: 978.06 samples/sec#011loss=5.078472\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:12 INFO 139827261196096] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1149.9290466308594, \"sum\": 1149.9290466308594, \"min\": 1149.9290466308594}}, \"EndTime\": 1601803392.599428, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803391.449236}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:12 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=547.815138489 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:12 INFO 139827261196096] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:12 INFO 139827261196096] #quality_metric: host=algo-1, epoch=273, train loss <loss>=5.0831510067\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:12 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:13 INFO 139827261196096] Epoch[274] Batch[0] avg_epoch_loss=5.100554\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=274, batch=0 train loss <loss>=5.10055398941\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:13 INFO 139827261196096] Epoch[274] Batch[5] avg_epoch_loss=5.098346\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=274, batch=5 train loss <loss>=5.09834551811\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:13 INFO 139827261196096] Epoch[274] Batch [5]#011Speed: 980.32 samples/sec#011loss=5.098346\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:13 INFO 139827261196096] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1147.8660106658936, \"sum\": 1147.8660106658936, \"min\": 1147.8660106658936}}, \"EndTime\": 1601803393.747701, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803392.59949}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:13 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=533.995857397 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:13 INFO 139827261196096] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:13 INFO 139827261196096] #quality_metric: host=algo-1, epoch=274, train loss <loss>=5.08881602287\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:13 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:14 INFO 139827261196096] Epoch[275] Batch[0] avg_epoch_loss=5.089209\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=275, batch=0 train loss <loss>=5.08920860291\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:14 INFO 139827261196096] Epoch[275] Batch[5] avg_epoch_loss=5.091271\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=275, batch=5 train loss <loss>=5.09127092361\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:14 INFO 139827261196096] Epoch[275] Batch [5]#011Speed: 987.16 samples/sec#011loss=5.091271\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:14 INFO 139827261196096] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1134.2720985412598, \"sum\": 1134.2720985412598, \"min\": 1134.2720985412598}}, \"EndTime\": 1601803394.882407, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803393.747757}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:14 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=537.742470892 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:14 INFO 139827261196096] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:14 INFO 139827261196096] #quality_metric: host=algo-1, epoch=275, train loss <loss>=5.100370121\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:14 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:15 INFO 139827261196096] Epoch[276] Batch[0] avg_epoch_loss=5.090400\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=276, batch=0 train loss <loss>=5.09039974213\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:15 INFO 139827261196096] Epoch[276] Batch[5] avg_epoch_loss=5.071057\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:15 INFO 139827261196096] #quality_metric: host=algo-1, epoch=276, batch=5 train loss <loss>=5.0710571607\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:15 INFO 139827261196096] Epoch[276] Batch [5]#011Speed: 945.77 samples/sec#011loss=5.071057\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:16 INFO 139827261196096] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1150.2270698547363, \"sum\": 1150.2270698547363, \"min\": 1150.2270698547363}}, \"EndTime\": 1601803396.033111, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803394.882474}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:16 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=552.019824258 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:16 INFO 139827261196096] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=276, train loss <loss>=5.0726439476\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:16 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:16 INFO 139827261196096] Epoch[277] Batch[0] avg_epoch_loss=5.018950\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=277, batch=0 train loss <loss>=5.01895046234\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:16 INFO 139827261196096] Epoch[277] Batch[5] avg_epoch_loss=5.070005\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:16 INFO 139827261196096] #quality_metric: host=algo-1, epoch=277, batch=5 train loss <loss>=5.07000525792\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:16 INFO 139827261196096] Epoch[277] Batch [5]#011Speed: 968.74 samples/sec#011loss=5.070005\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:17 INFO 139827261196096] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1147.3708152770996, \"sum\": 1147.3708152770996, \"min\": 1147.3708152770996}}, \"EndTime\": 1601803397.180906, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803396.033174}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:17 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=536.837000634 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:17 INFO 139827261196096] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=277, train loss <loss>=5.06997318268\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:17 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:17 INFO 139827261196096] Epoch[278] Batch[0] avg_epoch_loss=5.040343\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:17 INFO 139827261196096] #quality_metric: host=algo-1, epoch=278, batch=0 train loss <loss>=5.04034280777\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] Epoch[278] Batch[5] avg_epoch_loss=5.071064\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=278, batch=5 train loss <loss>=5.071063598\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] Epoch[278] Batch [5]#011Speed: 967.69 samples/sec#011loss=5.071064\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] Epoch[278] Batch[10] avg_epoch_loss=5.071072\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=278, batch=10 train loss <loss>=5.07108221054\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] Epoch[278] Batch [10]#011Speed: 960.23 samples/sec#011loss=5.071082\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1219.4950580596924, \"sum\": 1219.4950580596924, \"min\": 1219.4950580596924}}, \"EndTime\": 1601803398.40084, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803397.180964}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=541.165919598 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] #progress_metric: host=algo-1, completed 69 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=278, train loss <loss>=5.07107205824\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] Epoch[279] Batch[0] avg_epoch_loss=5.131700\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:18 INFO 139827261196096] #quality_metric: host=algo-1, epoch=279, batch=0 train loss <loss>=5.13169956207\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:19 INFO 139827261196096] Epoch[279] Batch[5] avg_epoch_loss=5.131041\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=279, batch=5 train loss <loss>=5.1310412089\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:19 INFO 139827261196096] Epoch[279] Batch [5]#011Speed: 985.41 samples/sec#011loss=5.131041\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:19 INFO 139827261196096] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1135.0481510162354, \"sum\": 1135.0481510162354, \"min\": 1135.0481510162354}}, \"EndTime\": 1601803399.53631, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803398.40091}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:19 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=554.99322014 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:19 INFO 139827261196096] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:19 INFO 139827261196096] #quality_metric: host=algo-1, epoch=279, train loss <loss>=5.12681694031\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:19 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] Epoch[280] Batch[0] avg_epoch_loss=5.101205\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=280, batch=0 train loss <loss>=5.10120534897\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] Epoch[280] Batch[5] avg_epoch_loss=5.087679\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=280, batch=5 train loss <loss>=5.08767906825\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] Epoch[280] Batch [5]#011Speed: 983.01 samples/sec#011loss=5.087679\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] Epoch[280] Batch[10] avg_epoch_loss=5.085229\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=280, batch=10 train loss <loss>=5.0822886467\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] Epoch[280] Batch [10]#011Speed: 954.70 samples/sec#011loss=5.082289\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1215.9380912780762, \"sum\": 1215.9380912780762, \"min\": 1215.9380912780762}}, \"EndTime\": 1601803400.752711, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803399.53638}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=544.397078254 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] #quality_metric: host=algo-1, epoch=280, train loss <loss>=5.08522887663\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:20 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:21 INFO 139827261196096] Epoch[281] Batch[0] avg_epoch_loss=5.155895\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=281, batch=0 train loss <loss>=5.15589523315\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:21 INFO 139827261196096] Epoch[281] Batch[5] avg_epoch_loss=5.134431\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=281, batch=5 train loss <loss>=5.13443056742\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:21 INFO 139827261196096] Epoch[281] Batch [5]#011Speed: 928.20 samples/sec#011loss=5.134431\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:21 INFO 139827261196096] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1159.9860191345215, \"sum\": 1159.9860191345215, \"min\": 1159.9860191345215}}, \"EndTime\": 1601803401.913007, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803400.752769}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:21 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=528.413156871 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:21 INFO 139827261196096] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:21 INFO 139827261196096] #quality_metric: host=algo-1, epoch=281, train loss <loss>=5.11433410645\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:21 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:22 INFO 139827261196096] Epoch[282] Batch[0] avg_epoch_loss=5.009387\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=282, batch=0 train loss <loss>=5.00938653946\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:22 INFO 139827261196096] Epoch[282] Batch[5] avg_epoch_loss=5.089009\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:22 INFO 139827261196096] #quality_metric: host=algo-1, epoch=282, batch=5 train loss <loss>=5.08900936445\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:22 INFO 139827261196096] Epoch[282] Batch [5]#011Speed: 976.44 samples/sec#011loss=5.089009\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:23 INFO 139827261196096] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1135.8368396759033, \"sum\": 1135.8368396759033, \"min\": 1135.8368396759033}}, \"EndTime\": 1601803403.049282, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803401.913073}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:23 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=551.087490293 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:23 INFO 139827261196096] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=282, train loss <loss>=5.09602942467\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:23 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:23 INFO 139827261196096] Epoch[283] Batch[0] avg_epoch_loss=5.081656\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=283, batch=0 train loss <loss>=5.08165597916\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:23 INFO 139827261196096] Epoch[283] Batch[5] avg_epoch_loss=5.067835\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:23 INFO 139827261196096] #quality_metric: host=algo-1, epoch=283, batch=5 train loss <loss>=5.06783501307\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:23 INFO 139827261196096] Epoch[283] Batch [5]#011Speed: 970.31 samples/sec#011loss=5.067835\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:24 INFO 139827261196096] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1138.213872909546, \"sum\": 1138.213872909546, \"min\": 1138.213872909546}}, \"EndTime\": 1601803404.187977, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803403.049349}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:24 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=547.305925847 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:24 INFO 139827261196096] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=283, train loss <loss>=5.09069871902\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:24 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:24 INFO 139827261196096] Epoch[284] Batch[0] avg_epoch_loss=5.129216\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:24 INFO 139827261196096] #quality_metric: host=algo-1, epoch=284, batch=0 train loss <loss>=5.12921571732\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:25 INFO 139827261196096] Epoch[284] Batch[5] avg_epoch_loss=5.085421\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=284, batch=5 train loss <loss>=5.08542148272\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:25 INFO 139827261196096] Epoch[284] Batch [5]#011Speed: 979.04 samples/sec#011loss=5.085421\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:25 INFO 139827261196096] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1133.9111328125, \"sum\": 1133.9111328125, \"min\": 1133.9111328125}}, \"EndTime\": 1601803405.322335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803404.188034}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:25 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=562.604283794 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:25 INFO 139827261196096] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=284, train loss <loss>=5.07977218628\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:25 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:25 INFO 139827261196096] Epoch[285] Batch[0] avg_epoch_loss=5.074624\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:25 INFO 139827261196096] #quality_metric: host=algo-1, epoch=285, batch=0 train loss <loss>=5.07462358475\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:26 INFO 139827261196096] Epoch[285] Batch[5] avg_epoch_loss=5.071802\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=285, batch=5 train loss <loss>=5.07180221876\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:26 INFO 139827261196096] Epoch[285] Batch [5]#011Speed: 987.11 samples/sec#011loss=5.071802\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:26 INFO 139827261196096] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1132.4200630187988, \"sum\": 1132.4200630187988, \"min\": 1132.4200630187988}}, \"EndTime\": 1601803406.455224, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803405.322402}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:26 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=565.113950997 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:26 INFO 139827261196096] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:26 INFO 139827261196096] #quality_metric: host=algo-1, epoch=285, train loss <loss>=5.07598118782\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:26 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:27 INFO 139827261196096] Epoch[286] Batch[0] avg_epoch_loss=5.083768\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=286, batch=0 train loss <loss>=5.08376789093\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:27 INFO 139827261196096] Epoch[286] Batch[5] avg_epoch_loss=5.069023\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=286, batch=5 train loss <loss>=5.06902305285\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:27 INFO 139827261196096] Epoch[286] Batch [5]#011Speed: 986.67 samples/sec#011loss=5.069023\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:27 INFO 139827261196096] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1144.9050903320312, \"sum\": 1144.9050903320312, \"min\": 1144.9050903320312}}, \"EndTime\": 1601803407.600554, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803406.455288}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:27 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=550.219724616 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:27 INFO 139827261196096] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:27 INFO 139827261196096] #quality_metric: host=algo-1, epoch=286, train loss <loss>=5.08202285767\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:27 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:28 INFO 139827261196096] Epoch[287] Batch[0] avg_epoch_loss=5.112309\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=287, batch=0 train loss <loss>=5.11230945587\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:28 INFO 139827261196096] Epoch[287] Batch[5] avg_epoch_loss=5.077388\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=287, batch=5 train loss <loss>=5.07738788923\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:28 INFO 139827261196096] Epoch[287] Batch [5]#011Speed: 985.89 samples/sec#011loss=5.077388\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:28 INFO 139827261196096] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1141.9811248779297, \"sum\": 1141.9811248779297, \"min\": 1141.9811248779297}}, \"EndTime\": 1601803408.742958, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803407.600614}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:28 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=545.496359985 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:28 INFO 139827261196096] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:28 INFO 139827261196096] #quality_metric: host=algo-1, epoch=287, train loss <loss>=5.0900657177\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:28 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] Epoch[288] Batch[0] avg_epoch_loss=5.105661\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=288, batch=0 train loss <loss>=5.10566139221\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] Epoch[288] Batch[5] avg_epoch_loss=5.085819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=288, batch=5 train loss <loss>=5.08581884702\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] Epoch[288] Batch [5]#011Speed: 983.65 samples/sec#011loss=5.085819\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] Epoch[288] Batch[10] avg_epoch_loss=5.095728\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=288, batch=10 train loss <loss>=5.10761890411\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] Epoch[288] Batch [10]#011Speed: 951.38 samples/sec#011loss=5.107619\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1212.1071815490723, \"sum\": 1212.1071815490723, \"min\": 1212.1071815490723}}, \"EndTime\": 1601803409.955515, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803408.743026}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=529.618211321 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] #quality_metric: host=algo-1, epoch=288, train loss <loss>=5.09572796388\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:29 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:30 INFO 139827261196096] Epoch[289] Batch[0] avg_epoch_loss=5.121541\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=289, batch=0 train loss <loss>=5.12154102325\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:30 INFO 139827261196096] Epoch[289] Batch[5] avg_epoch_loss=5.113997\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:30 INFO 139827261196096] #quality_metric: host=algo-1, epoch=289, batch=5 train loss <loss>=5.11399674416\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:30 INFO 139827261196096] Epoch[289] Batch [5]#011Speed: 970.42 samples/sec#011loss=5.113997\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:31 INFO 139827261196096] Epoch[289] Batch[10] avg_epoch_loss=5.130103\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=289, batch=10 train loss <loss>=5.14942989349\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:31 INFO 139827261196096] Epoch[289] Batch [10]#011Speed: 963.18 samples/sec#011loss=5.149430\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:31 INFO 139827261196096] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1214.5898342132568, \"sum\": 1214.5898342132568, \"min\": 1214.5898342132568}}, \"EndTime\": 1601803411.170423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803409.955573}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:31 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=530.181639887 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:31 INFO 139827261196096] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=289, train loss <loss>=5.13010272113\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:31 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:31 INFO 139827261196096] Epoch[290] Batch[0] avg_epoch_loss=5.060957\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:31 INFO 139827261196096] #quality_metric: host=algo-1, epoch=290, batch=0 train loss <loss>=5.06095695496\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] Epoch[290] Batch[5] avg_epoch_loss=5.076661\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=290, batch=5 train loss <loss>=5.07666126887\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] Epoch[290] Batch [5]#011Speed: 963.55 samples/sec#011loss=5.076661\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] Epoch[290] Batch[10] avg_epoch_loss=5.064076\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=290, batch=10 train loss <loss>=5.04897375107\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] Epoch[290] Batch [10]#011Speed: 942.16 samples/sec#011loss=5.048974\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1231.5020561218262, \"sum\": 1231.5020561218262, \"min\": 1231.5020561218262}}, \"EndTime\": 1601803412.402326, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803411.17048}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=520.463788787 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=290, train loss <loss>=5.06407603351\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] Epoch[291] Batch[0] avg_epoch_loss=5.095986\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:32 INFO 139827261196096] #quality_metric: host=algo-1, epoch=291, batch=0 train loss <loss>=5.09598636627\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] Epoch[291] Batch[5] avg_epoch_loss=5.131773\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=291, batch=5 train loss <loss>=5.13177347183\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] Epoch[291] Batch [5]#011Speed: 981.57 samples/sec#011loss=5.131773\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] Epoch[291] Batch[10] avg_epoch_loss=5.151607\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=291, batch=10 train loss <loss>=5.17540655136\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] Epoch[291] Batch [10]#011Speed: 965.20 samples/sec#011loss=5.175407\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1213.6268615722656, \"sum\": 1213.6268615722656, \"min\": 1213.6268615722656}}, \"EndTime\": 1601803413.616337, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803412.402391}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=552.021845279 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] #quality_metric: host=algo-1, epoch=291, train loss <loss>=5.1516066898\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:33 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:34 INFO 139827261196096] Epoch[292] Batch[0] avg_epoch_loss=5.204048\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=292, batch=0 train loss <loss>=5.2040476799\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:34 INFO 139827261196096] Epoch[292] Batch[5] avg_epoch_loss=5.138810\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=292, batch=5 train loss <loss>=5.13880991936\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:34 INFO 139827261196096] Epoch[292] Batch [5]#011Speed: 984.75 samples/sec#011loss=5.138810\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:34 INFO 139827261196096] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1137.584924697876, \"sum\": 1137.584924697876, \"min\": 1137.584924697876}}, \"EndTime\": 1601803414.754313, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803413.616398}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:34 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=554.643293433 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:34 INFO 139827261196096] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:34 INFO 139827261196096] #quality_metric: host=algo-1, epoch=292, train loss <loss>=5.12548642159\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:34 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:35 INFO 139827261196096] Epoch[293] Batch[0] avg_epoch_loss=5.043443\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=293, batch=0 train loss <loss>=5.04344272614\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:35 INFO 139827261196096] Epoch[293] Batch[5] avg_epoch_loss=5.105164\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=293, batch=5 train loss <loss>=5.10516428947\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:35 INFO 139827261196096] Epoch[293] Batch [5]#011Speed: 973.70 samples/sec#011loss=5.105164\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:35 INFO 139827261196096] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1151.2539386749268, \"sum\": 1151.2539386749268, \"min\": 1151.2539386749268}}, \"EndTime\": 1601803415.906011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803414.754368}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:35 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=537.61525639 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:35 INFO 139827261196096] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:35 INFO 139827261196096] #quality_metric: host=algo-1, epoch=293, train loss <loss>=5.0933719635\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:35 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:36 INFO 139827261196096] Epoch[294] Batch[0] avg_epoch_loss=4.982827\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=294, batch=0 train loss <loss>=4.98282670975\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:36 INFO 139827261196096] Epoch[294] Batch[5] avg_epoch_loss=5.086900\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:36 INFO 139827261196096] #quality_metric: host=algo-1, epoch=294, batch=5 train loss <loss>=5.08689991633\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:36 INFO 139827261196096] Epoch[294] Batch [5]#011Speed: 928.61 samples/sec#011loss=5.086900\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] Epoch[294] Batch[10] avg_epoch_loss=5.122175\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=294, batch=10 train loss <loss>=5.16450519562\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] Epoch[294] Batch [10]#011Speed: 949.04 samples/sec#011loss=5.164505\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 1231.835126876831, \"sum\": 1231.835126876831, \"min\": 1231.835126876831}}, \"EndTime\": 1601803417.13831, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803415.906084}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] #throughput_metric: host=algo-1, train throughput=521.946445157 records/second\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] #quality_metric: host=algo-1, epoch=294, train loss <loss>=5.12217504328\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] loss did not improve\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] Loading parameters from best epoch (244)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 7.850885391235352, \"sum\": 7.850885391235352, \"min\": 7.850885391235352}}, \"EndTime\": 1601803417.146609, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803417.138375}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] stopping training now\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] Final loss: 5.06394076347 (occurred at epoch 244)\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] #quality_metric: host=algo-1, train final_loss <loss>=5.06394076347\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 WARNING 139827261196096] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 300.8880615234375, \"sum\": 300.8880615234375, \"min\": 300.8880615234375}}, \"EndTime\": 1601803417.448115, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803417.146656}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 356.3838005065918, \"sum\": 356.3838005065918, \"min\": 356.3838005065918}}, \"EndTime\": 1601803417.503569, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803417.448176}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 8.24594497680664, \"sum\": 8.24594497680664, \"min\": 8.24594497680664}}, \"EndTime\": 1601803417.511894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803417.503614}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:37 INFO 139827261196096] Evaluating model accuracy on testset using 100 samples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.bind.time\": {\"count\": 1, \"max\": 0.024080276489257812, \"sum\": 0.024080276489257812, \"min\": 0.024080276489257812}}, \"EndTime\": 1601803417.512499, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803417.511931}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.score.time\": {\"count\": 1, \"max\": 2276.3869762420654, \"sum\": 2276.3869762420654, \"min\": 2276.3869762420654}}, \"EndTime\": 1601803419.788862, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803417.512541}\n",
      "\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, RMSE): 49.5123442791\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, mean_absolute_QuantileLoss): 40328.9912220425\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, mean_wQuantileLoss): 0.05272521698811922\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, wQuantileLoss[0.1]): 0.030207242496522745\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, wQuantileLoss[0.2]): 0.04680570118678728\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, wQuantileLoss[0.3]): 0.05753137358763329\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, wQuantileLoss[0.4]): 0.06394584361414254\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, wQuantileLoss[0.5]): 0.06703435008126775\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, wQuantileLoss[0.6]): 0.06565089487861472\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, wQuantileLoss[0.7]): 0.06029236245905604\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, wQuantileLoss[0.8]): 0.05006709090998405\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #test_score (algo-1, wQuantileLoss[0.9]): 0.03299209367906455\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #quality_metric: host=algo-1, test mean_wQuantileLoss <loss>=0.0527252169881\u001b[0m\n",
      "\u001b[34m[10/04/2020 09:23:39 INFO 139827261196096] #quality_metric: host=algo-1, test RMSE <loss>=49.5123442791\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 349471.53186798096, \"sum\": 349471.53186798096, \"min\": 349471.53186798096}, \"setuptime\": {\"count\": 1, \"max\": 7.102012634277344, \"sum\": 7.102012634277344, \"min\": 7.102012634277344}}, \"EndTime\": 1601803419.80992, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1601803419.788927}\n",
      "\u001b[0m\n",
      "\n",
      "2020-10-04 09:23:48 Uploading - Uploading generated training model\n",
      "2020-10-04 09:23:48 Completed - Training job completed\n",
      "Training seconds: 408\n",
      "Billable seconds: 408\n",
      "CPU times: user 1.37 s, sys: 157 ms, total: 1.53 s\n",
      "Wall time: 8min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Endpointを作成し、推論を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルのトレーニングが終わったので、これをEndpointにデプロイします。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!CPU times: user 246 ms, sys: 14.7 ms, total: 261 ms\n",
      "Wall time: 8min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# トレーニングが終わったモデルをEndpointにdeployする\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 作成したモデルの精度を検証する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TEST time series: 367\n",
      "length of TEST time series 1: 7301\n",
      "length of TEST time series 2: 7305\n",
      "length of TEST time series 3: 7309\n",
      "length of TEST time series 4: 7313\n",
      "length of TEST time series 5: 7317\n",
      "length of TEST time series 6: 7321\n",
      "length of TEST time series 7: 7325\n",
      "length of TEST time series 8: 7329\n",
      "length of TEST time series 9: 7333\n"
     ]
    }
   ],
   "source": [
    "# 61日間のテストデータを予測期間（例：24時間、4時間、1時間）に即して複数のテストデータに分割する\n",
    "num_test_windows = int(61 * 24 / prediction_length)\n",
    "\n",
    "# DeepARの必要フォーマットにあわせてテストデータを変形する\n",
    "test_data = []\n",
    "test_data_info = []\n",
    "\n",
    "# テストデータには、テストデータ期間をprediction_lengthで割った分だけの時系列を生成する\n",
    "for k in range(0, num_test_windows + 1):\n",
    "    start_time_delta = datetime.timedelta(hours= k * prediction_length)\n",
    "    df_test = df_summary[train_start:test_start + start_time_delta].copy().asfreq(freq)\n",
    "    test_data.append(convert_to_DeepAR_dict(df_test, 'count', train_start))\n",
    "\n",
    "    # テストデータの情報は精度評価時に利用するため保存する\n",
    "    test_data_info.append({'pred_start_time':test_start + start_time_delta})\n",
    "\n",
    "print('Number of TEST time series: {}'.format(len(test_data)))\n",
    "for i in range(1,min(len(test_data), 10)):\n",
    "    print('length of TEST time series {}: {}'.format(i, len(test_data[i]['target'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 388 ms, sys: 48.1 ms, total: 436 ms\n",
      "Wall time: 31.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論用のデータをendpointに投入して予測結果を取得する\n",
    "\n",
    "# 全データを一括で推論することはできないので、分割して投入する\n",
    "pred_batch_size = 40\n",
    "num_test_data = len(test_data)\n",
    "num_cycle = int(num_test_data / pred_batch_size)\n",
    "\n",
    "pred_response = {}\n",
    "pred_response['predictions'] = []\n",
    "\n",
    "for k in range(0,num_cycle+1):\n",
    "    # 推論用データとconfigをreqにまとめる\n",
    "    # 予測値として、低位値、中位値、高位値の3つを取得することをconfigで指定する\n",
    "    req = {'instances': test_data[k*pred_batch_size:(k+1)*pred_batch_size],\n",
    "           'configuration':{\n",
    "               'num_samples': 50,\n",
    "               'output_types': ['quantiles'],\n",
    "               'quantiles': ['0.1', '0.5', '0.9']\n",
    "           }\n",
    "          }\n",
    "\n",
    "    # リクエストはbytes型としてencodingして渡す\n",
    "    req_encoded = json.dumps(req).encode('utf-8')\n",
    "\n",
    "    # predictorをcallして推論の結果を取得する\n",
    "    response = predictor.predict(req_encoded)\n",
    "\n",
    "    # bytes型で返却されるので、dictに変換する\n",
    "    response_dict = json.loads(response.decode())\n",
    "    \n",
    "    pred_response['predictions'].extend(response_dict['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.5</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <td>212.151169</td>\n",
       "      <td>265.435028</td>\n",
       "      <td>241.570862</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 01:00:00</th>\n",
       "      <td>124.617722</td>\n",
       "      <td>171.000305</td>\n",
       "      <td>145.031357</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 02:00:00</th>\n",
       "      <td>80.706589</td>\n",
       "      <td>117.129768</td>\n",
       "      <td>101.627487</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 03:00:00</th>\n",
       "      <td>72.566772</td>\n",
       "      <td>97.084290</td>\n",
       "      <td>85.603622</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 04:00:00</th>\n",
       "      <td>98.508514</td>\n",
       "      <td>131.258377</td>\n",
       "      <td>114.383095</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 05:00:00</th>\n",
       "      <td>153.487030</td>\n",
       "      <td>186.792969</td>\n",
       "      <td>168.263992</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 06:00:00</th>\n",
       "      <td>334.848877</td>\n",
       "      <td>438.448975</td>\n",
       "      <td>384.286133</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 07:00:00</th>\n",
       "      <td>563.527161</td>\n",
       "      <td>669.975586</td>\n",
       "      <td>615.068115</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 08:00:00</th>\n",
       "      <td>655.870667</td>\n",
       "      <td>734.443359</td>\n",
       "      <td>685.650879</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 09:00:00</th>\n",
       "      <td>593.185181</td>\n",
       "      <td>675.854431</td>\n",
       "      <td>633.049072</td>\n",
       "      <td>712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 10:00:00</th>\n",
       "      <td>546.174805</td>\n",
       "      <td>649.930481</td>\n",
       "      <td>608.360718</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 11:00:00</th>\n",
       "      <td>550.857788</td>\n",
       "      <td>622.386414</td>\n",
       "      <td>588.267212</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 12:00:00</th>\n",
       "      <td>507.769958</td>\n",
       "      <td>573.518677</td>\n",
       "      <td>534.737244</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 13:00:00</th>\n",
       "      <td>590.475769</td>\n",
       "      <td>691.678406</td>\n",
       "      <td>633.467346</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 14:00:00</th>\n",
       "      <td>693.076416</td>\n",
       "      <td>816.870117</td>\n",
       "      <td>748.113464</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 15:00:00</th>\n",
       "      <td>763.526672</td>\n",
       "      <td>880.894409</td>\n",
       "      <td>829.899658</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 16:00:00</th>\n",
       "      <td>898.578918</td>\n",
       "      <td>1030.268311</td>\n",
       "      <td>972.444885</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 17:00:00</th>\n",
       "      <td>884.743408</td>\n",
       "      <td>1023.133301</td>\n",
       "      <td>958.861206</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 18:00:00</th>\n",
       "      <td>818.326294</td>\n",
       "      <td>956.415710</td>\n",
       "      <td>884.686401</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 19:00:00</th>\n",
       "      <td>706.503662</td>\n",
       "      <td>832.738525</td>\n",
       "      <td>769.550232</td>\n",
       "      <td>958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 20:00:00</th>\n",
       "      <td>741.083984</td>\n",
       "      <td>858.501709</td>\n",
       "      <td>795.321533</td>\n",
       "      <td>928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 21:00:00</th>\n",
       "      <td>645.237305</td>\n",
       "      <td>760.188354</td>\n",
       "      <td>695.020081</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 22:00:00</th>\n",
       "      <td>602.483826</td>\n",
       "      <td>752.955017</td>\n",
       "      <td>663.901306</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 23:00:00</th>\n",
       "      <td>478.145905</td>\n",
       "      <td>589.286926</td>\n",
       "      <td>542.303345</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 00:00:00</th>\n",
       "      <td>408.892822</td>\n",
       "      <td>482.716125</td>\n",
       "      <td>435.279327</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 01:00:00</th>\n",
       "      <td>313.713440</td>\n",
       "      <td>379.960632</td>\n",
       "      <td>351.702209</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 02:00:00</th>\n",
       "      <td>230.462128</td>\n",
       "      <td>321.196228</td>\n",
       "      <td>273.053070</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 03:00:00</th>\n",
       "      <td>174.236008</td>\n",
       "      <td>245.430084</td>\n",
       "      <td>206.434677</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 04:00:00</th>\n",
       "      <td>100.757751</td>\n",
       "      <td>144.895813</td>\n",
       "      <td>114.460846</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 05:00:00</th>\n",
       "      <td>86.865906</td>\n",
       "      <td>124.313004</td>\n",
       "      <td>105.222527</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 06:00:00</th>\n",
       "      <td>166.591248</td>\n",
       "      <td>216.678085</td>\n",
       "      <td>193.810745</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 07:00:00</th>\n",
       "      <td>267.266479</td>\n",
       "      <td>341.752289</td>\n",
       "      <td>312.071411</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 08:00:00</th>\n",
       "      <td>394.480743</td>\n",
       "      <td>477.315582</td>\n",
       "      <td>444.336365</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 09:00:00</th>\n",
       "      <td>457.281403</td>\n",
       "      <td>551.453125</td>\n",
       "      <td>511.633148</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 10:00:00</th>\n",
       "      <td>530.850708</td>\n",
       "      <td>616.243896</td>\n",
       "      <td>580.063171</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 11:00:00</th>\n",
       "      <td>558.110168</td>\n",
       "      <td>663.672302</td>\n",
       "      <td>607.130981</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 12:00:00</th>\n",
       "      <td>547.548462</td>\n",
       "      <td>617.364319</td>\n",
       "      <td>580.791931</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 13:00:00</th>\n",
       "      <td>590.203064</td>\n",
       "      <td>697.570435</td>\n",
       "      <td>641.759705</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 14:00:00</th>\n",
       "      <td>650.398865</td>\n",
       "      <td>778.394592</td>\n",
       "      <td>711.513611</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 15:00:00</th>\n",
       "      <td>692.957642</td>\n",
       "      <td>835.818115</td>\n",
       "      <td>757.624023</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 16:00:00</th>\n",
       "      <td>833.570801</td>\n",
       "      <td>937.508484</td>\n",
       "      <td>870.561768</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 17:00:00</th>\n",
       "      <td>821.340332</td>\n",
       "      <td>925.030029</td>\n",
       "      <td>869.725403</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 18:00:00</th>\n",
       "      <td>787.757141</td>\n",
       "      <td>924.330261</td>\n",
       "      <td>856.678101</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 19:00:00</th>\n",
       "      <td>717.452942</td>\n",
       "      <td>836.199768</td>\n",
       "      <td>781.360840</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 20:00:00</th>\n",
       "      <td>708.614563</td>\n",
       "      <td>814.070068</td>\n",
       "      <td>755.186890</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 21:00:00</th>\n",
       "      <td>657.911438</td>\n",
       "      <td>781.517761</td>\n",
       "      <td>742.128662</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 22:00:00</th>\n",
       "      <td>640.446716</td>\n",
       "      <td>764.049622</td>\n",
       "      <td>708.591064</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-02 23:00:00</th>\n",
       "      <td>534.640747</td>\n",
       "      <td>652.010010</td>\n",
       "      <td>598.371338</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 00:00:00</th>\n",
       "      <td>469.679871</td>\n",
       "      <td>522.212097</td>\n",
       "      <td>494.708160</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 01:00:00</th>\n",
       "      <td>366.600067</td>\n",
       "      <td>439.302338</td>\n",
       "      <td>398.490204</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 02:00:00</th>\n",
       "      <td>280.029999</td>\n",
       "      <td>348.320435</td>\n",
       "      <td>305.244049</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 03:00:00</th>\n",
       "      <td>206.901184</td>\n",
       "      <td>260.846069</td>\n",
       "      <td>233.235596</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 04:00:00</th>\n",
       "      <td>83.720001</td>\n",
       "      <td>129.534988</td>\n",
       "      <td>108.139076</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 05:00:00</th>\n",
       "      <td>58.763992</td>\n",
       "      <td>115.180321</td>\n",
       "      <td>86.348465</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 06:00:00</th>\n",
       "      <td>122.418961</td>\n",
       "      <td>169.800049</td>\n",
       "      <td>142.571381</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 07:00:00</th>\n",
       "      <td>183.394272</td>\n",
       "      <td>256.729492</td>\n",
       "      <td>208.879776</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 08:00:00</th>\n",
       "      <td>319.129883</td>\n",
       "      <td>371.760986</td>\n",
       "      <td>351.146118</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 09:00:00</th>\n",
       "      <td>396.730835</td>\n",
       "      <td>464.542267</td>\n",
       "      <td>429.755859</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 10:00:00</th>\n",
       "      <td>458.333679</td>\n",
       "      <td>558.716431</td>\n",
       "      <td>516.946045</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 11:00:00</th>\n",
       "      <td>541.452087</td>\n",
       "      <td>626.103943</td>\n",
       "      <td>589.593689</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 12:00:00</th>\n",
       "      <td>434.587952</td>\n",
       "      <td>534.832153</td>\n",
       "      <td>473.315552</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 13:00:00</th>\n",
       "      <td>493.805084</td>\n",
       "      <td>589.574768</td>\n",
       "      <td>530.802979</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 14:00:00</th>\n",
       "      <td>537.532471</td>\n",
       "      <td>669.916687</td>\n",
       "      <td>589.283691</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 15:00:00</th>\n",
       "      <td>535.189575</td>\n",
       "      <td>661.083252</td>\n",
       "      <td>599.898071</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 16:00:00</th>\n",
       "      <td>557.234924</td>\n",
       "      <td>649.444580</td>\n",
       "      <td>589.072937</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 17:00:00</th>\n",
       "      <td>538.160339</td>\n",
       "      <td>640.778442</td>\n",
       "      <td>586.345276</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 18:00:00</th>\n",
       "      <td>528.790405</td>\n",
       "      <td>622.005432</td>\n",
       "      <td>561.862671</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 19:00:00</th>\n",
       "      <td>441.208771</td>\n",
       "      <td>537.989563</td>\n",
       "      <td>491.431580</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 20:00:00</th>\n",
       "      <td>418.342834</td>\n",
       "      <td>495.579773</td>\n",
       "      <td>460.463806</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 21:00:00</th>\n",
       "      <td>329.583862</td>\n",
       "      <td>417.679016</td>\n",
       "      <td>368.612518</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 22:00:00</th>\n",
       "      <td>281.123596</td>\n",
       "      <td>356.403473</td>\n",
       "      <td>307.804077</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-03 23:00:00</th>\n",
       "      <td>179.053497</td>\n",
       "      <td>245.611755</td>\n",
       "      <td>208.257462</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 00:00:00</th>\n",
       "      <td>104.897591</td>\n",
       "      <td>141.045822</td>\n",
       "      <td>127.497467</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 01:00:00</th>\n",
       "      <td>42.550190</td>\n",
       "      <td>83.516304</td>\n",
       "      <td>59.457638</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 02:00:00</th>\n",
       "      <td>39.986168</td>\n",
       "      <td>73.008492</td>\n",
       "      <td>54.659710</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 03:00:00</th>\n",
       "      <td>52.418156</td>\n",
       "      <td>80.028168</td>\n",
       "      <td>64.212364</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 04:00:00</th>\n",
       "      <td>67.633774</td>\n",
       "      <td>102.236618</td>\n",
       "      <td>89.398979</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 05:00:00</th>\n",
       "      <td>144.536011</td>\n",
       "      <td>193.651993</td>\n",
       "      <td>161.373459</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 06:00:00</th>\n",
       "      <td>307.106689</td>\n",
       "      <td>442.968475</td>\n",
       "      <td>377.248199</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 07:00:00</th>\n",
       "      <td>505.471466</td>\n",
       "      <td>687.522339</td>\n",
       "      <td>591.716614</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 08:00:00</th>\n",
       "      <td>629.330261</td>\n",
       "      <td>706.005249</td>\n",
       "      <td>669.411072</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 09:00:00</th>\n",
       "      <td>553.165039</td>\n",
       "      <td>642.921631</td>\n",
       "      <td>603.028259</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 10:00:00</th>\n",
       "      <td>534.608154</td>\n",
       "      <td>611.047791</td>\n",
       "      <td>569.143494</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 11:00:00</th>\n",
       "      <td>524.049500</td>\n",
       "      <td>592.215393</td>\n",
       "      <td>555.732483</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 12:00:00</th>\n",
       "      <td>514.754395</td>\n",
       "      <td>575.532776</td>\n",
       "      <td>545.493835</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 13:00:00</th>\n",
       "      <td>556.463806</td>\n",
       "      <td>641.497803</td>\n",
       "      <td>599.640259</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 14:00:00</th>\n",
       "      <td>618.048096</td>\n",
       "      <td>720.984314</td>\n",
       "      <td>670.913940</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 15:00:00</th>\n",
       "      <td>642.504944</td>\n",
       "      <td>769.530273</td>\n",
       "      <td>708.591736</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 16:00:00</th>\n",
       "      <td>796.927673</td>\n",
       "      <td>894.509460</td>\n",
       "      <td>837.782776</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 17:00:00</th>\n",
       "      <td>776.996582</td>\n",
       "      <td>908.238159</td>\n",
       "      <td>848.273560</td>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 18:00:00</th>\n",
       "      <td>708.485107</td>\n",
       "      <td>810.544739</td>\n",
       "      <td>766.801514</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 19:00:00</th>\n",
       "      <td>558.686584</td>\n",
       "      <td>654.514526</td>\n",
       "      <td>609.074646</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 20:00:00</th>\n",
       "      <td>457.181885</td>\n",
       "      <td>539.295715</td>\n",
       "      <td>496.521057</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 21:00:00</th>\n",
       "      <td>329.727203</td>\n",
       "      <td>450.412689</td>\n",
       "      <td>369.331879</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 22:00:00</th>\n",
       "      <td>259.671661</td>\n",
       "      <td>337.403564</td>\n",
       "      <td>295.137024</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-04 23:00:00</th>\n",
       "      <td>173.489700</td>\n",
       "      <td>218.762894</td>\n",
       "      <td>197.697357</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 00:00:00</th>\n",
       "      <td>108.979530</td>\n",
       "      <td>149.128189</td>\n",
       "      <td>137.404282</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 01:00:00</th>\n",
       "      <td>59.994556</td>\n",
       "      <td>90.051125</td>\n",
       "      <td>73.762138</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 02:00:00</th>\n",
       "      <td>45.241249</td>\n",
       "      <td>81.345375</td>\n",
       "      <td>64.898956</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 03:00:00</th>\n",
       "      <td>48.226395</td>\n",
       "      <td>73.105370</td>\n",
       "      <td>58.358112</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 04:00:00</th>\n",
       "      <td>58.689766</td>\n",
       "      <td>89.441925</td>\n",
       "      <td>71.687904</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 05:00:00</th>\n",
       "      <td>122.034019</td>\n",
       "      <td>169.612518</td>\n",
       "      <td>148.789978</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 06:00:00</th>\n",
       "      <td>283.883057</td>\n",
       "      <td>454.023529</td>\n",
       "      <td>362.460358</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 07:00:00</th>\n",
       "      <td>467.842224</td>\n",
       "      <td>677.171631</td>\n",
       "      <td>578.935059</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 08:00:00</th>\n",
       "      <td>517.682251</td>\n",
       "      <td>606.523499</td>\n",
       "      <td>567.640198</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 09:00:00</th>\n",
       "      <td>439.667847</td>\n",
       "      <td>594.560364</td>\n",
       "      <td>513.100342</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 10:00:00</th>\n",
       "      <td>452.616180</td>\n",
       "      <td>569.199463</td>\n",
       "      <td>497.151794</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 11:00:00</th>\n",
       "      <td>447.268188</td>\n",
       "      <td>542.818420</td>\n",
       "      <td>497.370850</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 12:00:00</th>\n",
       "      <td>494.067474</td>\n",
       "      <td>559.515564</td>\n",
       "      <td>525.105286</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 13:00:00</th>\n",
       "      <td>541.179688</td>\n",
       "      <td>640.637207</td>\n",
       "      <td>585.461731</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 14:00:00</th>\n",
       "      <td>614.883240</td>\n",
       "      <td>720.580078</td>\n",
       "      <td>661.853577</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 15:00:00</th>\n",
       "      <td>638.115540</td>\n",
       "      <td>781.339417</td>\n",
       "      <td>711.907959</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 16:00:00</th>\n",
       "      <td>781.289062</td>\n",
       "      <td>911.383057</td>\n",
       "      <td>821.457275</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 17:00:00</th>\n",
       "      <td>767.261963</td>\n",
       "      <td>877.763062</td>\n",
       "      <td>825.121887</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 18:00:00</th>\n",
       "      <td>704.924988</td>\n",
       "      <td>822.701355</td>\n",
       "      <td>778.994324</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 19:00:00</th>\n",
       "      <td>579.822388</td>\n",
       "      <td>705.210510</td>\n",
       "      <td>653.335083</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 20:00:00</th>\n",
       "      <td>480.613556</td>\n",
       "      <td>581.362244</td>\n",
       "      <td>536.001160</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 21:00:00</th>\n",
       "      <td>401.420532</td>\n",
       "      <td>503.094696</td>\n",
       "      <td>448.434265</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 22:00:00</th>\n",
       "      <td>320.104523</td>\n",
       "      <td>403.460968</td>\n",
       "      <td>351.242523</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-05 23:00:00</th>\n",
       "      <td>199.496109</td>\n",
       "      <td>249.488251</td>\n",
       "      <td>225.587173</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 00:00:00</th>\n",
       "      <td>120.031593</td>\n",
       "      <td>146.098389</td>\n",
       "      <td>131.185440</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 01:00:00</th>\n",
       "      <td>58.011932</td>\n",
       "      <td>98.257179</td>\n",
       "      <td>76.553833</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 02:00:00</th>\n",
       "      <td>51.237808</td>\n",
       "      <td>81.880455</td>\n",
       "      <td>66.909622</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 03:00:00</th>\n",
       "      <td>53.616142</td>\n",
       "      <td>78.925842</td>\n",
       "      <td>66.148415</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 04:00:00</th>\n",
       "      <td>55.049976</td>\n",
       "      <td>78.230728</td>\n",
       "      <td>69.545937</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 05:00:00</th>\n",
       "      <td>146.967224</td>\n",
       "      <td>187.262360</td>\n",
       "      <td>165.158997</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 06:00:00</th>\n",
       "      <td>357.051361</td>\n",
       "      <td>422.437134</td>\n",
       "      <td>388.167328</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 07:00:00</th>\n",
       "      <td>546.798523</td>\n",
       "      <td>653.593628</td>\n",
       "      <td>601.051025</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 08:00:00</th>\n",
       "      <td>677.068542</td>\n",
       "      <td>740.314087</td>\n",
       "      <td>696.623230</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 09:00:00</th>\n",
       "      <td>597.453003</td>\n",
       "      <td>665.578186</td>\n",
       "      <td>628.451050</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 10:00:00</th>\n",
       "      <td>558.205811</td>\n",
       "      <td>670.933350</td>\n",
       "      <td>600.798645</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 11:00:00</th>\n",
       "      <td>563.632935</td>\n",
       "      <td>655.452271</td>\n",
       "      <td>606.896240</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 12:00:00</th>\n",
       "      <td>546.450073</td>\n",
       "      <td>605.394165</td>\n",
       "      <td>579.993408</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 13:00:00</th>\n",
       "      <td>607.052185</td>\n",
       "      <td>686.951599</td>\n",
       "      <td>643.829651</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 14:00:00</th>\n",
       "      <td>676.973572</td>\n",
       "      <td>772.525330</td>\n",
       "      <td>712.500000</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 15:00:00</th>\n",
       "      <td>710.632812</td>\n",
       "      <td>844.251160</td>\n",
       "      <td>763.569214</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 16:00:00</th>\n",
       "      <td>832.351379</td>\n",
       "      <td>929.862183</td>\n",
       "      <td>865.121521</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 17:00:00</th>\n",
       "      <td>805.690308</td>\n",
       "      <td>901.933105</td>\n",
       "      <td>854.013489</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 18:00:00</th>\n",
       "      <td>685.079102</td>\n",
       "      <td>832.651001</td>\n",
       "      <td>773.900879</td>\n",
       "      <td>894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 19:00:00</th>\n",
       "      <td>614.313660</td>\n",
       "      <td>751.472412</td>\n",
       "      <td>667.147522</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 20:00:00</th>\n",
       "      <td>510.294617</td>\n",
       "      <td>602.173645</td>\n",
       "      <td>564.842102</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 21:00:00</th>\n",
       "      <td>416.878815</td>\n",
       "      <td>508.102173</td>\n",
       "      <td>460.133698</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 22:00:00</th>\n",
       "      <td>332.888855</td>\n",
       "      <td>407.371674</td>\n",
       "      <td>366.571869</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-06 23:00:00</th>\n",
       "      <td>209.562500</td>\n",
       "      <td>281.781647</td>\n",
       "      <td>247.874451</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 00:00:00</th>\n",
       "      <td>154.536621</td>\n",
       "      <td>198.352615</td>\n",
       "      <td>178.672531</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 01:00:00</th>\n",
       "      <td>85.836197</td>\n",
       "      <td>126.214890</td>\n",
       "      <td>107.461296</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 02:00:00</th>\n",
       "      <td>71.176331</td>\n",
       "      <td>105.507431</td>\n",
       "      <td>84.500954</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 03:00:00</th>\n",
       "      <td>67.799973</td>\n",
       "      <td>91.843002</td>\n",
       "      <td>80.639732</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 04:00:00</th>\n",
       "      <td>65.261620</td>\n",
       "      <td>96.153046</td>\n",
       "      <td>73.442726</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 05:00:00</th>\n",
       "      <td>148.667099</td>\n",
       "      <td>196.631104</td>\n",
       "      <td>166.629425</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 06:00:00</th>\n",
       "      <td>346.158478</td>\n",
       "      <td>456.121307</td>\n",
       "      <td>415.816681</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 07:00:00</th>\n",
       "      <td>580.023376</td>\n",
       "      <td>671.577148</td>\n",
       "      <td>637.341736</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 08:00:00</th>\n",
       "      <td>625.740784</td>\n",
       "      <td>707.583069</td>\n",
       "      <td>660.976196</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 09:00:00</th>\n",
       "      <td>590.964355</td>\n",
       "      <td>666.621338</td>\n",
       "      <td>638.090210</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 10:00:00</th>\n",
       "      <td>551.853516</td>\n",
       "      <td>651.369507</td>\n",
       "      <td>603.440979</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 11:00:00</th>\n",
       "      <td>550.025635</td>\n",
       "      <td>638.355591</td>\n",
       "      <td>590.331116</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 12:00:00</th>\n",
       "      <td>531.618225</td>\n",
       "      <td>596.649658</td>\n",
       "      <td>566.733276</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 13:00:00</th>\n",
       "      <td>592.300049</td>\n",
       "      <td>676.227234</td>\n",
       "      <td>628.538147</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 14:00:00</th>\n",
       "      <td>655.613159</td>\n",
       "      <td>778.002197</td>\n",
       "      <td>708.070190</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 15:00:00</th>\n",
       "      <td>729.469666</td>\n",
       "      <td>858.990967</td>\n",
       "      <td>790.451172</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 16:00:00</th>\n",
       "      <td>848.008850</td>\n",
       "      <td>958.843933</td>\n",
       "      <td>908.770752</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 17:00:00</th>\n",
       "      <td>828.153809</td>\n",
       "      <td>955.943542</td>\n",
       "      <td>890.027466</td>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 18:00:00</th>\n",
       "      <td>759.265442</td>\n",
       "      <td>912.148438</td>\n",
       "      <td>841.728577</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 19:00:00</th>\n",
       "      <td>633.085083</td>\n",
       "      <td>762.429932</td>\n",
       "      <td>696.952942</td>\n",
       "      <td>941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 20:00:00</th>\n",
       "      <td>615.296204</td>\n",
       "      <td>755.263367</td>\n",
       "      <td>685.636169</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 21:00:00</th>\n",
       "      <td>513.299866</td>\n",
       "      <td>619.183411</td>\n",
       "      <td>552.914246</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 22:00:00</th>\n",
       "      <td>401.491943</td>\n",
       "      <td>528.994873</td>\n",
       "      <td>455.643738</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07 23:00:00</th>\n",
       "      <td>286.002106</td>\n",
       "      <td>379.272400</td>\n",
       "      <td>316.988434</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 00:00:00</th>\n",
       "      <td>216.311035</td>\n",
       "      <td>265.578247</td>\n",
       "      <td>240.572296</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 01:00:00</th>\n",
       "      <td>125.647949</td>\n",
       "      <td>178.717133</td>\n",
       "      <td>151.827621</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 02:00:00</th>\n",
       "      <td>91.302414</td>\n",
       "      <td>150.843582</td>\n",
       "      <td>125.870430</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 03:00:00</th>\n",
       "      <td>80.746521</td>\n",
       "      <td>122.041779</td>\n",
       "      <td>101.483696</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 04:00:00</th>\n",
       "      <td>72.219185</td>\n",
       "      <td>99.779999</td>\n",
       "      <td>84.560417</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 05:00:00</th>\n",
       "      <td>140.748047</td>\n",
       "      <td>188.298416</td>\n",
       "      <td>164.161041</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 06:00:00</th>\n",
       "      <td>346.441010</td>\n",
       "      <td>450.229736</td>\n",
       "      <td>390.335297</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 07:00:00</th>\n",
       "      <td>541.184937</td>\n",
       "      <td>689.708252</td>\n",
       "      <td>620.493835</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 08:00:00</th>\n",
       "      <td>685.413147</td>\n",
       "      <td>767.049927</td>\n",
       "      <td>728.522888</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 09:00:00</th>\n",
       "      <td>606.388123</td>\n",
       "      <td>740.309509</td>\n",
       "      <td>670.823303</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 10:00:00</th>\n",
       "      <td>565.399475</td>\n",
       "      <td>664.160095</td>\n",
       "      <td>609.643799</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 11:00:00</th>\n",
       "      <td>522.497437</td>\n",
       "      <td>635.116516</td>\n",
       "      <td>565.146973</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 12:00:00</th>\n",
       "      <td>527.740417</td>\n",
       "      <td>598.593994</td>\n",
       "      <td>566.652466</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 13:00:00</th>\n",
       "      <td>591.035767</td>\n",
       "      <td>690.077881</td>\n",
       "      <td>638.404114</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 14:00:00</th>\n",
       "      <td>680.250977</td>\n",
       "      <td>802.069336</td>\n",
       "      <td>748.117981</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 15:00:00</th>\n",
       "      <td>781.884460</td>\n",
       "      <td>892.557251</td>\n",
       "      <td>836.887817</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 16:00:00</th>\n",
       "      <td>954.487000</td>\n",
       "      <td>1056.618652</td>\n",
       "      <td>999.263489</td>\n",
       "      <td>944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 17:00:00</th>\n",
       "      <td>944.237732</td>\n",
       "      <td>1102.287842</td>\n",
       "      <td>1027.949829</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 18:00:00</th>\n",
       "      <td>829.673096</td>\n",
       "      <td>1033.464111</td>\n",
       "      <td>922.947754</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 19:00:00</th>\n",
       "      <td>727.593079</td>\n",
       "      <td>922.356750</td>\n",
       "      <td>821.852966</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 20:00:00</th>\n",
       "      <td>724.739136</td>\n",
       "      <td>864.636658</td>\n",
       "      <td>794.931152</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 21:00:00</th>\n",
       "      <td>640.078979</td>\n",
       "      <td>780.604187</td>\n",
       "      <td>706.869934</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 22:00:00</th>\n",
       "      <td>559.934326</td>\n",
       "      <td>696.958008</td>\n",
       "      <td>651.765747</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-08 23:00:00</th>\n",
       "      <td>474.933441</td>\n",
       "      <td>569.112488</td>\n",
       "      <td>530.630981</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 00:00:00</th>\n",
       "      <td>472.708466</td>\n",
       "      <td>538.798950</td>\n",
       "      <td>507.038513</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 01:00:00</th>\n",
       "      <td>325.890076</td>\n",
       "      <td>409.356720</td>\n",
       "      <td>362.316010</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 02:00:00</th>\n",
       "      <td>225.057129</td>\n",
       "      <td>288.190033</td>\n",
       "      <td>262.066803</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 03:00:00</th>\n",
       "      <td>169.345169</td>\n",
       "      <td>233.352875</td>\n",
       "      <td>199.389526</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 04:00:00</th>\n",
       "      <td>82.911011</td>\n",
       "      <td>122.478500</td>\n",
       "      <td>102.418190</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 05:00:00</th>\n",
       "      <td>91.324623</td>\n",
       "      <td>130.142319</td>\n",
       "      <td>103.620216</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 06:00:00</th>\n",
       "      <td>155.198181</td>\n",
       "      <td>211.265564</td>\n",
       "      <td>191.414825</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 07:00:00</th>\n",
       "      <td>276.863037</td>\n",
       "      <td>362.651917</td>\n",
       "      <td>311.501495</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 08:00:00</th>\n",
       "      <td>406.641052</td>\n",
       "      <td>481.822205</td>\n",
       "      <td>441.901978</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 09:00:00</th>\n",
       "      <td>449.298859</td>\n",
       "      <td>539.086670</td>\n",
       "      <td>518.014038</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 10:00:00</th>\n",
       "      <td>502.651672</td>\n",
       "      <td>595.182922</td>\n",
       "      <td>550.196411</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 11:00:00</th>\n",
       "      <td>539.595337</td>\n",
       "      <td>641.658691</td>\n",
       "      <td>584.984619</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 12:00:00</th>\n",
       "      <td>554.368408</td>\n",
       "      <td>665.646179</td>\n",
       "      <td>619.336060</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 13:00:00</th>\n",
       "      <td>593.122192</td>\n",
       "      <td>685.328491</td>\n",
       "      <td>648.962769</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 14:00:00</th>\n",
       "      <td>681.046814</td>\n",
       "      <td>781.319153</td>\n",
       "      <td>737.911926</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 15:00:00</th>\n",
       "      <td>722.749268</td>\n",
       "      <td>822.251099</td>\n",
       "      <td>772.750854</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 16:00:00</th>\n",
       "      <td>813.462585</td>\n",
       "      <td>916.153320</td>\n",
       "      <td>864.611938</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 17:00:00</th>\n",
       "      <td>794.333069</td>\n",
       "      <td>913.083984</td>\n",
       "      <td>856.340637</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 18:00:00</th>\n",
       "      <td>774.540527</td>\n",
       "      <td>898.513550</td>\n",
       "      <td>850.328064</td>\n",
       "      <td>877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 19:00:00</th>\n",
       "      <td>704.035706</td>\n",
       "      <td>843.543762</td>\n",
       "      <td>778.419067</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 20:00:00</th>\n",
       "      <td>682.676819</td>\n",
       "      <td>795.357666</td>\n",
       "      <td>737.287231</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 21:00:00</th>\n",
       "      <td>647.068542</td>\n",
       "      <td>755.810059</td>\n",
       "      <td>700.130432</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 22:00:00</th>\n",
       "      <td>607.219604</td>\n",
       "      <td>744.663513</td>\n",
       "      <td>679.067810</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-09 23:00:00</th>\n",
       "      <td>549.046753</td>\n",
       "      <td>661.324524</td>\n",
       "      <td>595.794556</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 00:00:00</th>\n",
       "      <td>472.163025</td>\n",
       "      <td>541.086487</td>\n",
       "      <td>500.898712</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 01:00:00</th>\n",
       "      <td>329.601776</td>\n",
       "      <td>396.785645</td>\n",
       "      <td>366.160950</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 02:00:00</th>\n",
       "      <td>252.260056</td>\n",
       "      <td>312.343018</td>\n",
       "      <td>283.109009</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 03:00:00</th>\n",
       "      <td>186.352310</td>\n",
       "      <td>241.111099</td>\n",
       "      <td>214.908035</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 04:00:00</th>\n",
       "      <td>90.110725</td>\n",
       "      <td>126.257774</td>\n",
       "      <td>109.557350</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 05:00:00</th>\n",
       "      <td>72.234131</td>\n",
       "      <td>105.504532</td>\n",
       "      <td>85.594711</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 06:00:00</th>\n",
       "      <td>131.988098</td>\n",
       "      <td>176.546295</td>\n",
       "      <td>159.610718</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 07:00:00</th>\n",
       "      <td>218.160950</td>\n",
       "      <td>278.169861</td>\n",
       "      <td>247.190491</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 08:00:00</th>\n",
       "      <td>302.984497</td>\n",
       "      <td>370.279541</td>\n",
       "      <td>329.934235</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 09:00:00</th>\n",
       "      <td>370.293457</td>\n",
       "      <td>460.314301</td>\n",
       "      <td>419.945862</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 10:00:00</th>\n",
       "      <td>456.932159</td>\n",
       "      <td>529.503296</td>\n",
       "      <td>496.747681</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 11:00:00</th>\n",
       "      <td>494.625824</td>\n",
       "      <td>605.215210</td>\n",
       "      <td>541.106384</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 12:00:00</th>\n",
       "      <td>542.617737</td>\n",
       "      <td>612.394470</td>\n",
       "      <td>572.842163</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 13:00:00</th>\n",
       "      <td>546.836609</td>\n",
       "      <td>631.236816</td>\n",
       "      <td>587.873657</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 14:00:00</th>\n",
       "      <td>586.843567</td>\n",
       "      <td>688.770081</td>\n",
       "      <td>636.194214</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 15:00:00</th>\n",
       "      <td>594.695312</td>\n",
       "      <td>663.920654</td>\n",
       "      <td>627.134216</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 16:00:00</th>\n",
       "      <td>647.064453</td>\n",
       "      <td>715.802368</td>\n",
       "      <td>674.659729</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 17:00:00</th>\n",
       "      <td>624.477661</td>\n",
       "      <td>725.753662</td>\n",
       "      <td>672.417725</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 18:00:00</th>\n",
       "      <td>565.092529</td>\n",
       "      <td>663.934875</td>\n",
       "      <td>608.751221</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 19:00:00</th>\n",
       "      <td>486.441345</td>\n",
       "      <td>577.528442</td>\n",
       "      <td>537.940918</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 20:00:00</th>\n",
       "      <td>441.562286</td>\n",
       "      <td>531.713867</td>\n",
       "      <td>486.197998</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 21:00:00</th>\n",
       "      <td>330.798645</td>\n",
       "      <td>436.581543</td>\n",
       "      <td>389.749725</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 22:00:00</th>\n",
       "      <td>256.957550</td>\n",
       "      <td>347.151581</td>\n",
       "      <td>306.080933</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-10 23:00:00</th>\n",
       "      <td>156.929611</td>\n",
       "      <td>225.900726</td>\n",
       "      <td>186.497772</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 00:00:00</th>\n",
       "      <td>98.868301</td>\n",
       "      <td>141.759506</td>\n",
       "      <td>119.272026</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 01:00:00</th>\n",
       "      <td>69.057045</td>\n",
       "      <td>98.020447</td>\n",
       "      <td>85.814384</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 02:00:00</th>\n",
       "      <td>56.073143</td>\n",
       "      <td>89.553551</td>\n",
       "      <td>73.738991</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 03:00:00</th>\n",
       "      <td>67.731056</td>\n",
       "      <td>94.442680</td>\n",
       "      <td>79.609016</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 04:00:00</th>\n",
       "      <td>64.172104</td>\n",
       "      <td>90.432983</td>\n",
       "      <td>78.413132</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 05:00:00</th>\n",
       "      <td>145.597275</td>\n",
       "      <td>194.443130</td>\n",
       "      <td>167.357254</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 06:00:00</th>\n",
       "      <td>350.462402</td>\n",
       "      <td>443.151123</td>\n",
       "      <td>397.169495</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 07:00:00</th>\n",
       "      <td>532.997009</td>\n",
       "      <td>665.842102</td>\n",
       "      <td>590.862610</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 08:00:00</th>\n",
       "      <td>502.730286</td>\n",
       "      <td>589.255493</td>\n",
       "      <td>543.144043</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 09:00:00</th>\n",
       "      <td>501.687317</td>\n",
       "      <td>565.274597</td>\n",
       "      <td>526.506531</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 10:00:00</th>\n",
       "      <td>477.691986</td>\n",
       "      <td>555.596191</td>\n",
       "      <td>519.750244</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 11:00:00</th>\n",
       "      <td>486.958923</td>\n",
       "      <td>552.466125</td>\n",
       "      <td>520.641174</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 12:00:00</th>\n",
       "      <td>513.621094</td>\n",
       "      <td>566.088257</td>\n",
       "      <td>539.088074</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 13:00:00</th>\n",
       "      <td>564.873535</td>\n",
       "      <td>641.765564</td>\n",
       "      <td>602.929626</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 14:00:00</th>\n",
       "      <td>631.119324</td>\n",
       "      <td>728.172424</td>\n",
       "      <td>679.637634</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 15:00:00</th>\n",
       "      <td>662.249390</td>\n",
       "      <td>768.316895</td>\n",
       "      <td>709.871521</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 16:00:00</th>\n",
       "      <td>689.765625</td>\n",
       "      <td>784.072876</td>\n",
       "      <td>740.893066</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 17:00:00</th>\n",
       "      <td>703.969971</td>\n",
       "      <td>814.275085</td>\n",
       "      <td>757.804260</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 18:00:00</th>\n",
       "      <td>616.069397</td>\n",
       "      <td>780.550598</td>\n",
       "      <td>684.234497</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 19:00:00</th>\n",
       "      <td>502.926910</td>\n",
       "      <td>633.561340</td>\n",
       "      <td>574.293274</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 20:00:00</th>\n",
       "      <td>412.217316</td>\n",
       "      <td>468.016693</td>\n",
       "      <td>434.893066</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 21:00:00</th>\n",
       "      <td>313.454468</td>\n",
       "      <td>393.833618</td>\n",
       "      <td>353.484375</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 22:00:00</th>\n",
       "      <td>253.086960</td>\n",
       "      <td>311.782227</td>\n",
       "      <td>284.046387</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-11 23:00:00</th>\n",
       "      <td>163.677246</td>\n",
       "      <td>222.381256</td>\n",
       "      <td>187.368637</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 00:00:00</th>\n",
       "      <td>92.997696</td>\n",
       "      <td>121.225052</td>\n",
       "      <td>105.589607</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 01:00:00</th>\n",
       "      <td>55.013069</td>\n",
       "      <td>80.672028</td>\n",
       "      <td>68.910080</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 02:00:00</th>\n",
       "      <td>44.510807</td>\n",
       "      <td>71.778755</td>\n",
       "      <td>58.205940</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 03:00:00</th>\n",
       "      <td>50.509586</td>\n",
       "      <td>67.464462</td>\n",
       "      <td>56.910385</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 04:00:00</th>\n",
       "      <td>51.212807</td>\n",
       "      <td>80.510567</td>\n",
       "      <td>65.784660</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 05:00:00</th>\n",
       "      <td>120.214867</td>\n",
       "      <td>185.925400</td>\n",
       "      <td>154.281494</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 06:00:00</th>\n",
       "      <td>298.990204</td>\n",
       "      <td>451.302734</td>\n",
       "      <td>356.705658</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 07:00:00</th>\n",
       "      <td>472.283447</td>\n",
       "      <td>655.076904</td>\n",
       "      <td>550.988586</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 08:00:00</th>\n",
       "      <td>625.706787</td>\n",
       "      <td>712.308472</td>\n",
       "      <td>669.471191</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 09:00:00</th>\n",
       "      <td>557.222107</td>\n",
       "      <td>646.499573</td>\n",
       "      <td>603.588562</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 10:00:00</th>\n",
       "      <td>530.656311</td>\n",
       "      <td>606.561768</td>\n",
       "      <td>572.209473</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 11:00:00</th>\n",
       "      <td>509.791046</td>\n",
       "      <td>615.314941</td>\n",
       "      <td>552.793518</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 12:00:00</th>\n",
       "      <td>537.059265</td>\n",
       "      <td>597.193176</td>\n",
       "      <td>568.340759</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 13:00:00</th>\n",
       "      <td>581.884521</td>\n",
       "      <td>674.031433</td>\n",
       "      <td>622.044067</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 14:00:00</th>\n",
       "      <td>652.532898</td>\n",
       "      <td>760.202454</td>\n",
       "      <td>693.924500</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 15:00:00</th>\n",
       "      <td>701.014648</td>\n",
       "      <td>808.185730</td>\n",
       "      <td>741.425781</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 16:00:00</th>\n",
       "      <td>805.074097</td>\n",
       "      <td>926.988525</td>\n",
       "      <td>863.221985</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 17:00:00</th>\n",
       "      <td>757.110718</td>\n",
       "      <td>903.366028</td>\n",
       "      <td>824.181335</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 18:00:00</th>\n",
       "      <td>677.882141</td>\n",
       "      <td>791.606079</td>\n",
       "      <td>746.876099</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 19:00:00</th>\n",
       "      <td>575.325928</td>\n",
       "      <td>692.378296</td>\n",
       "      <td>635.688599</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 20:00:00</th>\n",
       "      <td>550.372253</td>\n",
       "      <td>646.367493</td>\n",
       "      <td>590.811584</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 21:00:00</th>\n",
       "      <td>422.111053</td>\n",
       "      <td>511.087799</td>\n",
       "      <td>456.586609</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 22:00:00</th>\n",
       "      <td>315.982666</td>\n",
       "      <td>379.714294</td>\n",
       "      <td>344.751007</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-12 23:00:00</th>\n",
       "      <td>193.745560</td>\n",
       "      <td>246.658310</td>\n",
       "      <td>216.899887</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 00:00:00</th>\n",
       "      <td>127.678139</td>\n",
       "      <td>163.216888</td>\n",
       "      <td>145.436203</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 01:00:00</th>\n",
       "      <td>74.433022</td>\n",
       "      <td>104.926094</td>\n",
       "      <td>88.219749</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 02:00:00</th>\n",
       "      <td>50.371597</td>\n",
       "      <td>77.954056</td>\n",
       "      <td>63.215240</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 03:00:00</th>\n",
       "      <td>47.115952</td>\n",
       "      <td>74.686996</td>\n",
       "      <td>58.403812</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 04:00:00</th>\n",
       "      <td>59.012058</td>\n",
       "      <td>81.569733</td>\n",
       "      <td>69.999168</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 05:00:00</th>\n",
       "      <td>142.382431</td>\n",
       "      <td>184.495728</td>\n",
       "      <td>164.100021</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 06:00:00</th>\n",
       "      <td>359.465240</td>\n",
       "      <td>445.897278</td>\n",
       "      <td>392.824005</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 07:00:00</th>\n",
       "      <td>562.465332</td>\n",
       "      <td>650.278625</td>\n",
       "      <td>605.039856</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 08:00:00</th>\n",
       "      <td>664.981384</td>\n",
       "      <td>739.423340</td>\n",
       "      <td>707.561768</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 09:00:00</th>\n",
       "      <td>600.001526</td>\n",
       "      <td>670.844543</td>\n",
       "      <td>632.665344</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 10:00:00</th>\n",
       "      <td>552.037842</td>\n",
       "      <td>665.454163</td>\n",
       "      <td>612.575012</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 11:00:00</th>\n",
       "      <td>540.401062</td>\n",
       "      <td>640.866699</td>\n",
       "      <td>587.055359</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 12:00:00</th>\n",
       "      <td>552.965393</td>\n",
       "      <td>645.652588</td>\n",
       "      <td>601.896301</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 13:00:00</th>\n",
       "      <td>604.983521</td>\n",
       "      <td>691.587524</td>\n",
       "      <td>647.518799</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 14:00:00</th>\n",
       "      <td>643.346924</td>\n",
       "      <td>765.916199</td>\n",
       "      <td>718.642212</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 15:00:00</th>\n",
       "      <td>694.054382</td>\n",
       "      <td>825.515320</td>\n",
       "      <td>764.467285</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 16:00:00</th>\n",
       "      <td>798.205261</td>\n",
       "      <td>954.942505</td>\n",
       "      <td>869.037659</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 17:00:00</th>\n",
       "      <td>833.882080</td>\n",
       "      <td>979.820312</td>\n",
       "      <td>890.515503</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 18:00:00</th>\n",
       "      <td>743.527100</td>\n",
       "      <td>919.586426</td>\n",
       "      <td>812.757202</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 19:00:00</th>\n",
       "      <td>630.419617</td>\n",
       "      <td>763.779419</td>\n",
       "      <td>684.730042</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 20:00:00</th>\n",
       "      <td>542.754578</td>\n",
       "      <td>647.749695</td>\n",
       "      <td>606.519958</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 21:00:00</th>\n",
       "      <td>460.097412</td>\n",
       "      <td>550.009338</td>\n",
       "      <td>509.743683</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 22:00:00</th>\n",
       "      <td>336.638092</td>\n",
       "      <td>434.125244</td>\n",
       "      <td>387.591858</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-13 23:00:00</th>\n",
       "      <td>219.857635</td>\n",
       "      <td>285.535065</td>\n",
       "      <td>260.881409</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 00:00:00</th>\n",
       "      <td>130.310181</td>\n",
       "      <td>165.668411</td>\n",
       "      <td>144.483322</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 01:00:00</th>\n",
       "      <td>72.023186</td>\n",
       "      <td>113.809998</td>\n",
       "      <td>94.985321</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 02:00:00</th>\n",
       "      <td>49.612030</td>\n",
       "      <td>82.024452</td>\n",
       "      <td>66.154922</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 03:00:00</th>\n",
       "      <td>46.524910</td>\n",
       "      <td>81.880669</td>\n",
       "      <td>60.514610</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 04:00:00</th>\n",
       "      <td>57.040627</td>\n",
       "      <td>82.259880</td>\n",
       "      <td>69.102821</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 05:00:00</th>\n",
       "      <td>157.385361</td>\n",
       "      <td>193.012695</td>\n",
       "      <td>176.948685</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 06:00:00</th>\n",
       "      <td>383.475311</td>\n",
       "      <td>456.195160</td>\n",
       "      <td>420.891174</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 07:00:00</th>\n",
       "      <td>600.530762</td>\n",
       "      <td>689.361633</td>\n",
       "      <td>641.130737</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 08:00:00</th>\n",
       "      <td>665.016296</td>\n",
       "      <td>743.239258</td>\n",
       "      <td>712.009583</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 09:00:00</th>\n",
       "      <td>611.017883</td>\n",
       "      <td>704.338989</td>\n",
       "      <td>653.070251</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 10:00:00</th>\n",
       "      <td>572.902649</td>\n",
       "      <td>682.917114</td>\n",
       "      <td>626.562073</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 11:00:00</th>\n",
       "      <td>546.969971</td>\n",
       "      <td>678.589478</td>\n",
       "      <td>620.037964</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 12:00:00</th>\n",
       "      <td>596.245483</td>\n",
       "      <td>678.811035</td>\n",
       "      <td>634.298706</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 13:00:00</th>\n",
       "      <td>638.752563</td>\n",
       "      <td>713.090088</td>\n",
       "      <td>680.392212</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 14:00:00</th>\n",
       "      <td>701.680176</td>\n",
       "      <td>803.443115</td>\n",
       "      <td>747.501465</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 15:00:00</th>\n",
       "      <td>767.198486</td>\n",
       "      <td>892.097656</td>\n",
       "      <td>831.141113</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 16:00:00</th>\n",
       "      <td>826.754028</td>\n",
       "      <td>934.964844</td>\n",
       "      <td>881.136230</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 17:00:00</th>\n",
       "      <td>826.583008</td>\n",
       "      <td>1014.542236</td>\n",
       "      <td>932.579041</td>\n",
       "      <td>908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 18:00:00</th>\n",
       "      <td>760.097900</td>\n",
       "      <td>916.594543</td>\n",
       "      <td>860.503967</td>\n",
       "      <td>1025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 19:00:00</th>\n",
       "      <td>680.189941</td>\n",
       "      <td>792.296631</td>\n",
       "      <td>741.832581</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 20:00:00</th>\n",
       "      <td>605.156738</td>\n",
       "      <td>709.878113</td>\n",
       "      <td>643.846252</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 21:00:00</th>\n",
       "      <td>488.508972</td>\n",
       "      <td>627.792053</td>\n",
       "      <td>539.246460</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 22:00:00</th>\n",
       "      <td>383.711975</td>\n",
       "      <td>507.046906</td>\n",
       "      <td>447.236572</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-14 23:00:00</th>\n",
       "      <td>280.653961</td>\n",
       "      <td>367.943665</td>\n",
       "      <td>323.708710</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 00:00:00</th>\n",
       "      <td>157.857147</td>\n",
       "      <td>215.625381</td>\n",
       "      <td>191.810867</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 01:00:00</th>\n",
       "      <td>97.114685</td>\n",
       "      <td>150.968826</td>\n",
       "      <td>125.746796</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 02:00:00</th>\n",
       "      <td>70.796295</td>\n",
       "      <td>116.234482</td>\n",
       "      <td>92.882469</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 03:00:00</th>\n",
       "      <td>69.083099</td>\n",
       "      <td>98.680397</td>\n",
       "      <td>83.712082</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 04:00:00</th>\n",
       "      <td>59.883839</td>\n",
       "      <td>90.025452</td>\n",
       "      <td>74.485519</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 05:00:00</th>\n",
       "      <td>150.790619</td>\n",
       "      <td>193.561172</td>\n",
       "      <td>168.423172</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 06:00:00</th>\n",
       "      <td>370.706360</td>\n",
       "      <td>451.938171</td>\n",
       "      <td>398.718964</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 07:00:00</th>\n",
       "      <td>583.132568</td>\n",
       "      <td>664.897705</td>\n",
       "      <td>619.178284</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 08:00:00</th>\n",
       "      <td>636.968750</td>\n",
       "      <td>735.667480</td>\n",
       "      <td>682.452515</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 09:00:00</th>\n",
       "      <td>583.406860</td>\n",
       "      <td>684.837952</td>\n",
       "      <td>630.868652</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 10:00:00</th>\n",
       "      <td>547.098083</td>\n",
       "      <td>632.901733</td>\n",
       "      <td>585.331360</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 11:00:00</th>\n",
       "      <td>500.434570</td>\n",
       "      <td>596.432251</td>\n",
       "      <td>555.796082</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 12:00:00</th>\n",
       "      <td>509.675140</td>\n",
       "      <td>572.860535</td>\n",
       "      <td>550.030762</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 13:00:00</th>\n",
       "      <td>574.954651</td>\n",
       "      <td>670.782715</td>\n",
       "      <td>615.967529</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 14:00:00</th>\n",
       "      <td>664.219238</td>\n",
       "      <td>774.336548</td>\n",
       "      <td>732.848145</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 15:00:00</th>\n",
       "      <td>742.513123</td>\n",
       "      <td>875.042786</td>\n",
       "      <td>802.982666</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 16:00:00</th>\n",
       "      <td>906.130676</td>\n",
       "      <td>1015.041992</td>\n",
       "      <td>947.623413</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 17:00:00</th>\n",
       "      <td>912.188477</td>\n",
       "      <td>1035.558228</td>\n",
       "      <td>967.317139</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 18:00:00</th>\n",
       "      <td>773.162354</td>\n",
       "      <td>942.331909</td>\n",
       "      <td>875.274902</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 19:00:00</th>\n",
       "      <td>705.770630</td>\n",
       "      <td>860.500000</td>\n",
       "      <td>791.481995</td>\n",
       "      <td>975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 20:00:00</th>\n",
       "      <td>708.868958</td>\n",
       "      <td>829.030762</td>\n",
       "      <td>795.346130</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 21:00:00</th>\n",
       "      <td>642.337585</td>\n",
       "      <td>753.226501</td>\n",
       "      <td>698.943420</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 22:00:00</th>\n",
       "      <td>601.446350</td>\n",
       "      <td>719.828247</td>\n",
       "      <td>665.463745</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-15 23:00:00</th>\n",
       "      <td>490.471954</td>\n",
       "      <td>617.198730</td>\n",
       "      <td>542.746887</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 00:00:00</th>\n",
       "      <td>426.521637</td>\n",
       "      <td>505.080658</td>\n",
       "      <td>452.747192</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 01:00:00</th>\n",
       "      <td>299.614075</td>\n",
       "      <td>365.197784</td>\n",
       "      <td>336.737671</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 02:00:00</th>\n",
       "      <td>222.902817</td>\n",
       "      <td>290.945435</td>\n",
       "      <td>262.126648</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 03:00:00</th>\n",
       "      <td>164.342972</td>\n",
       "      <td>217.796661</td>\n",
       "      <td>193.819611</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 04:00:00</th>\n",
       "      <td>96.093185</td>\n",
       "      <td>134.544739</td>\n",
       "      <td>114.373779</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 05:00:00</th>\n",
       "      <td>103.792213</td>\n",
       "      <td>148.075287</td>\n",
       "      <td>121.661423</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 06:00:00</th>\n",
       "      <td>185.082428</td>\n",
       "      <td>233.767242</td>\n",
       "      <td>209.132187</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 07:00:00</th>\n",
       "      <td>277.166687</td>\n",
       "      <td>350.629517</td>\n",
       "      <td>311.882812</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 08:00:00</th>\n",
       "      <td>411.263397</td>\n",
       "      <td>470.733826</td>\n",
       "      <td>450.512817</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 09:00:00</th>\n",
       "      <td>468.384094</td>\n",
       "      <td>554.779297</td>\n",
       "      <td>507.166992</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 10:00:00</th>\n",
       "      <td>473.830475</td>\n",
       "      <td>616.650391</td>\n",
       "      <td>540.708679</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 11:00:00</th>\n",
       "      <td>511.302979</td>\n",
       "      <td>625.882996</td>\n",
       "      <td>551.622742</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 12:00:00</th>\n",
       "      <td>572.206787</td>\n",
       "      <td>663.882202</td>\n",
       "      <td>618.897949</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 13:00:00</th>\n",
       "      <td>624.700256</td>\n",
       "      <td>720.819946</td>\n",
       "      <td>678.494385</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 14:00:00</th>\n",
       "      <td>665.879822</td>\n",
       "      <td>809.910400</td>\n",
       "      <td>729.595337</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 15:00:00</th>\n",
       "      <td>732.552551</td>\n",
       "      <td>859.530090</td>\n",
       "      <td>783.139343</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 16:00:00</th>\n",
       "      <td>832.455444</td>\n",
       "      <td>934.107056</td>\n",
       "      <td>873.149902</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 17:00:00</th>\n",
       "      <td>831.791931</td>\n",
       "      <td>935.273865</td>\n",
       "      <td>871.964111</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 18:00:00</th>\n",
       "      <td>790.175293</td>\n",
       "      <td>932.517456</td>\n",
       "      <td>866.154968</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 19:00:00</th>\n",
       "      <td>710.069763</td>\n",
       "      <td>843.748108</td>\n",
       "      <td>793.813049</td>\n",
       "      <td>843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 20:00:00</th>\n",
       "      <td>699.477234</td>\n",
       "      <td>803.047913</td>\n",
       "      <td>756.997559</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 21:00:00</th>\n",
       "      <td>678.414062</td>\n",
       "      <td>779.792419</td>\n",
       "      <td>733.048706</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 22:00:00</th>\n",
       "      <td>639.285950</td>\n",
       "      <td>765.783020</td>\n",
       "      <td>693.330566</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-16 23:00:00</th>\n",
       "      <td>553.411133</td>\n",
       "      <td>639.964661</td>\n",
       "      <td>598.062256</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 00:00:00</th>\n",
       "      <td>454.387604</td>\n",
       "      <td>509.243195</td>\n",
       "      <td>481.773895</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 01:00:00</th>\n",
       "      <td>317.227142</td>\n",
       "      <td>373.606201</td>\n",
       "      <td>337.391418</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 02:00:00</th>\n",
       "      <td>257.525238</td>\n",
       "      <td>309.290192</td>\n",
       "      <td>284.483704</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 03:00:00</th>\n",
       "      <td>187.868713</td>\n",
       "      <td>230.130280</td>\n",
       "      <td>212.144638</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 04:00:00</th>\n",
       "      <td>102.910812</td>\n",
       "      <td>137.835892</td>\n",
       "      <td>121.004227</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 05:00:00</th>\n",
       "      <td>64.931946</td>\n",
       "      <td>105.024109</td>\n",
       "      <td>86.708420</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 06:00:00</th>\n",
       "      <td>126.597168</td>\n",
       "      <td>165.024475</td>\n",
       "      <td>143.089386</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 07:00:00</th>\n",
       "      <td>188.380051</td>\n",
       "      <td>233.311966</td>\n",
       "      <td>211.395401</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 08:00:00</th>\n",
       "      <td>298.686157</td>\n",
       "      <td>341.757477</td>\n",
       "      <td>316.368439</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 09:00:00</th>\n",
       "      <td>378.337524</td>\n",
       "      <td>452.041595</td>\n",
       "      <td>411.653198</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 10:00:00</th>\n",
       "      <td>444.136810</td>\n",
       "      <td>544.290039</td>\n",
       "      <td>497.480774</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 11:00:00</th>\n",
       "      <td>492.014008</td>\n",
       "      <td>576.518555</td>\n",
       "      <td>536.234497</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 12:00:00</th>\n",
       "      <td>504.211853</td>\n",
       "      <td>592.019104</td>\n",
       "      <td>549.141602</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 13:00:00</th>\n",
       "      <td>557.244385</td>\n",
       "      <td>655.817139</td>\n",
       "      <td>613.673218</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 14:00:00</th>\n",
       "      <td>584.856384</td>\n",
       "      <td>699.270874</td>\n",
       "      <td>643.837097</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 15:00:00</th>\n",
       "      <td>571.307922</td>\n",
       "      <td>689.639282</td>\n",
       "      <td>633.010864</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 16:00:00</th>\n",
       "      <td>638.705200</td>\n",
       "      <td>719.445068</td>\n",
       "      <td>681.265564</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 17:00:00</th>\n",
       "      <td>611.494263</td>\n",
       "      <td>722.499817</td>\n",
       "      <td>655.048096</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 18:00:00</th>\n",
       "      <td>538.364258</td>\n",
       "      <td>666.686401</td>\n",
       "      <td>609.277283</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 19:00:00</th>\n",
       "      <td>476.688904</td>\n",
       "      <td>579.612793</td>\n",
       "      <td>531.010620</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 20:00:00</th>\n",
       "      <td>413.410156</td>\n",
       "      <td>510.624359</td>\n",
       "      <td>461.364471</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 21:00:00</th>\n",
       "      <td>326.086975</td>\n",
       "      <td>407.307617</td>\n",
       "      <td>374.282074</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 22:00:00</th>\n",
       "      <td>269.497894</td>\n",
       "      <td>337.588562</td>\n",
       "      <td>295.700714</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-17 23:00:00</th>\n",
       "      <td>167.542053</td>\n",
       "      <td>222.602707</td>\n",
       "      <td>190.866226</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 00:00:00</th>\n",
       "      <td>112.281212</td>\n",
       "      <td>145.291641</td>\n",
       "      <td>130.520493</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 01:00:00</th>\n",
       "      <td>79.664871</td>\n",
       "      <td>111.313797</td>\n",
       "      <td>95.746857</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 02:00:00</th>\n",
       "      <td>70.011192</td>\n",
       "      <td>97.400299</td>\n",
       "      <td>82.663750</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 03:00:00</th>\n",
       "      <td>68.744553</td>\n",
       "      <td>88.463638</td>\n",
       "      <td>76.626465</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 04:00:00</th>\n",
       "      <td>57.914291</td>\n",
       "      <td>79.318764</td>\n",
       "      <td>69.557709</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 05:00:00</th>\n",
       "      <td>132.601715</td>\n",
       "      <td>190.234283</td>\n",
       "      <td>160.508774</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 06:00:00</th>\n",
       "      <td>330.341919</td>\n",
       "      <td>451.195160</td>\n",
       "      <td>385.567810</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 07:00:00</th>\n",
       "      <td>510.342804</td>\n",
       "      <td>660.863037</td>\n",
       "      <td>589.871704</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 08:00:00</th>\n",
       "      <td>649.801086</td>\n",
       "      <td>739.118042</td>\n",
       "      <td>682.301697</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 09:00:00</th>\n",
       "      <td>596.811035</td>\n",
       "      <td>667.443115</td>\n",
       "      <td>634.144958</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 10:00:00</th>\n",
       "      <td>567.804077</td>\n",
       "      <td>635.269043</td>\n",
       "      <td>603.513672</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 11:00:00</th>\n",
       "      <td>536.453003</td>\n",
       "      <td>609.592041</td>\n",
       "      <td>569.277893</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 12:00:00</th>\n",
       "      <td>549.714783</td>\n",
       "      <td>621.237183</td>\n",
       "      <td>583.025940</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 13:00:00</th>\n",
       "      <td>610.913635</td>\n",
       "      <td>699.868774</td>\n",
       "      <td>644.330261</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 14:00:00</th>\n",
       "      <td>648.339783</td>\n",
       "      <td>766.585938</td>\n",
       "      <td>706.716614</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 15:00:00</th>\n",
       "      <td>676.807617</td>\n",
       "      <td>792.781799</td>\n",
       "      <td>748.426819</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 16:00:00</th>\n",
       "      <td>710.478149</td>\n",
       "      <td>808.829834</td>\n",
       "      <td>751.438599</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 17:00:00</th>\n",
       "      <td>686.794617</td>\n",
       "      <td>815.898132</td>\n",
       "      <td>760.970215</td>\n",
       "      <td>863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 18:00:00</th>\n",
       "      <td>648.511963</td>\n",
       "      <td>745.936157</td>\n",
       "      <td>695.302795</td>\n",
       "      <td>854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 19:00:00</th>\n",
       "      <td>538.808289</td>\n",
       "      <td>632.938293</td>\n",
       "      <td>587.019226</td>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 20:00:00</th>\n",
       "      <td>518.977722</td>\n",
       "      <td>626.348877</td>\n",
       "      <td>563.536865</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 21:00:00</th>\n",
       "      <td>386.875275</td>\n",
       "      <td>471.995514</td>\n",
       "      <td>428.357910</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 22:00:00</th>\n",
       "      <td>287.591248</td>\n",
       "      <td>376.628265</td>\n",
       "      <td>322.035492</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-18 23:00:00</th>\n",
       "      <td>182.161179</td>\n",
       "      <td>241.539459</td>\n",
       "      <td>201.269989</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 00:00:00</th>\n",
       "      <td>110.426590</td>\n",
       "      <td>151.429291</td>\n",
       "      <td>126.437698</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 01:00:00</th>\n",
       "      <td>68.504028</td>\n",
       "      <td>99.955765</td>\n",
       "      <td>82.232506</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 02:00:00</th>\n",
       "      <td>53.972496</td>\n",
       "      <td>84.896835</td>\n",
       "      <td>64.288849</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 03:00:00</th>\n",
       "      <td>50.848763</td>\n",
       "      <td>73.292473</td>\n",
       "      <td>64.727219</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 04:00:00</th>\n",
       "      <td>46.975395</td>\n",
       "      <td>70.409256</td>\n",
       "      <td>60.882046</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 05:00:00</th>\n",
       "      <td>129.871490</td>\n",
       "      <td>193.354294</td>\n",
       "      <td>164.304413</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 06:00:00</th>\n",
       "      <td>360.350983</td>\n",
       "      <td>476.450012</td>\n",
       "      <td>424.289276</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 07:00:00</th>\n",
       "      <td>523.748779</td>\n",
       "      <td>682.397522</td>\n",
       "      <td>612.596619</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 08:00:00</th>\n",
       "      <td>604.976562</td>\n",
       "      <td>685.714844</td>\n",
       "      <td>645.196411</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 09:00:00</th>\n",
       "      <td>565.604431</td>\n",
       "      <td>655.461182</td>\n",
       "      <td>608.251892</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 10:00:00</th>\n",
       "      <td>535.591431</td>\n",
       "      <td>636.132629</td>\n",
       "      <td>597.789490</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 11:00:00</th>\n",
       "      <td>525.749817</td>\n",
       "      <td>610.850159</td>\n",
       "      <td>563.263306</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 12:00:00</th>\n",
       "      <td>531.508362</td>\n",
       "      <td>589.415222</td>\n",
       "      <td>564.949341</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 13:00:00</th>\n",
       "      <td>594.492676</td>\n",
       "      <td>678.468262</td>\n",
       "      <td>639.930603</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 14:00:00</th>\n",
       "      <td>661.619263</td>\n",
       "      <td>749.077087</td>\n",
       "      <td>693.953247</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 15:00:00</th>\n",
       "      <td>706.041077</td>\n",
       "      <td>824.545471</td>\n",
       "      <td>749.347595</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 16:00:00</th>\n",
       "      <td>798.786621</td>\n",
       "      <td>905.143799</td>\n",
       "      <td>842.283447</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 17:00:00</th>\n",
       "      <td>787.253906</td>\n",
       "      <td>914.925232</td>\n",
       "      <td>848.521545</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 18:00:00</th>\n",
       "      <td>707.693237</td>\n",
       "      <td>846.089233</td>\n",
       "      <td>797.088379</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 19:00:00</th>\n",
       "      <td>624.398987</td>\n",
       "      <td>737.184937</td>\n",
       "      <td>700.679260</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 20:00:00</th>\n",
       "      <td>520.391357</td>\n",
       "      <td>617.737732</td>\n",
       "      <td>563.439026</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 21:00:00</th>\n",
       "      <td>398.245270</td>\n",
       "      <td>502.409302</td>\n",
       "      <td>443.915588</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 22:00:00</th>\n",
       "      <td>307.989868</td>\n",
       "      <td>382.626282</td>\n",
       "      <td>343.061127</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-19 23:00:00</th>\n",
       "      <td>194.475906</td>\n",
       "      <td>242.037628</td>\n",
       "      <td>219.869736</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 00:00:00</th>\n",
       "      <td>131.127563</td>\n",
       "      <td>166.989838</td>\n",
       "      <td>148.580551</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 01:00:00</th>\n",
       "      <td>68.895241</td>\n",
       "      <td>102.957901</td>\n",
       "      <td>88.702950</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 02:00:00</th>\n",
       "      <td>55.415977</td>\n",
       "      <td>79.418182</td>\n",
       "      <td>67.537598</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 03:00:00</th>\n",
       "      <td>48.995090</td>\n",
       "      <td>72.402496</td>\n",
       "      <td>59.445457</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 04:00:00</th>\n",
       "      <td>55.530949</td>\n",
       "      <td>76.064819</td>\n",
       "      <td>67.129555</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 05:00:00</th>\n",
       "      <td>156.585373</td>\n",
       "      <td>186.195312</td>\n",
       "      <td>169.248306</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 06:00:00</th>\n",
       "      <td>378.287048</td>\n",
       "      <td>437.810272</td>\n",
       "      <td>408.951538</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 07:00:00</th>\n",
       "      <td>609.318054</td>\n",
       "      <td>678.881653</td>\n",
       "      <td>637.242432</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 08:00:00</th>\n",
       "      <td>638.136108</td>\n",
       "      <td>709.254639</td>\n",
       "      <td>666.178589</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 09:00:00</th>\n",
       "      <td>570.856689</td>\n",
       "      <td>660.452576</td>\n",
       "      <td>616.909119</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 10:00:00</th>\n",
       "      <td>567.313904</td>\n",
       "      <td>631.683105</td>\n",
       "      <td>592.989014</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 11:00:00</th>\n",
       "      <td>541.593628</td>\n",
       "      <td>646.835693</td>\n",
       "      <td>594.951355</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 12:00:00</th>\n",
       "      <td>557.188232</td>\n",
       "      <td>625.802734</td>\n",
       "      <td>599.724060</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 13:00:00</th>\n",
       "      <td>601.852783</td>\n",
       "      <td>695.171265</td>\n",
       "      <td>636.329102</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 14:00:00</th>\n",
       "      <td>671.096497</td>\n",
       "      <td>770.412170</td>\n",
       "      <td>714.347473</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 15:00:00</th>\n",
       "      <td>737.260132</td>\n",
       "      <td>846.901245</td>\n",
       "      <td>791.043945</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 16:00:00</th>\n",
       "      <td>808.965149</td>\n",
       "      <td>888.931946</td>\n",
       "      <td>846.600830</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 17:00:00</th>\n",
       "      <td>811.322205</td>\n",
       "      <td>927.212646</td>\n",
       "      <td>858.196167</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 18:00:00</th>\n",
       "      <td>716.444763</td>\n",
       "      <td>868.762451</td>\n",
       "      <td>806.518372</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 19:00:00</th>\n",
       "      <td>620.887146</td>\n",
       "      <td>749.929138</td>\n",
       "      <td>687.845520</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 20:00:00</th>\n",
       "      <td>612.935547</td>\n",
       "      <td>738.387695</td>\n",
       "      <td>657.797607</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 21:00:00</th>\n",
       "      <td>483.737885</td>\n",
       "      <td>584.921875</td>\n",
       "      <td>535.219360</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 22:00:00</th>\n",
       "      <td>358.007599</td>\n",
       "      <td>463.413513</td>\n",
       "      <td>409.647888</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-20 23:00:00</th>\n",
       "      <td>240.340881</td>\n",
       "      <td>308.140442</td>\n",
       "      <td>271.249695</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 00:00:00</th>\n",
       "      <td>145.766586</td>\n",
       "      <td>193.303101</td>\n",
       "      <td>163.900742</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 01:00:00</th>\n",
       "      <td>86.773560</td>\n",
       "      <td>121.033112</td>\n",
       "      <td>103.646523</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 02:00:00</th>\n",
       "      <td>63.563557</td>\n",
       "      <td>87.660103</td>\n",
       "      <td>72.427376</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 03:00:00</th>\n",
       "      <td>56.354462</td>\n",
       "      <td>79.380539</td>\n",
       "      <td>68.421402</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 04:00:00</th>\n",
       "      <td>56.676003</td>\n",
       "      <td>83.367607</td>\n",
       "      <td>70.486702</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 05:00:00</th>\n",
       "      <td>155.287109</td>\n",
       "      <td>185.630783</td>\n",
       "      <td>168.857910</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 06:00:00</th>\n",
       "      <td>385.746735</td>\n",
       "      <td>457.697968</td>\n",
       "      <td>422.707031</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 07:00:00</th>\n",
       "      <td>606.175354</td>\n",
       "      <td>711.371277</td>\n",
       "      <td>652.471069</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 08:00:00</th>\n",
       "      <td>657.260071</td>\n",
       "      <td>731.021973</td>\n",
       "      <td>685.524109</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 09:00:00</th>\n",
       "      <td>585.758972</td>\n",
       "      <td>674.330444</td>\n",
       "      <td>630.065063</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 10:00:00</th>\n",
       "      <td>566.792664</td>\n",
       "      <td>651.230591</td>\n",
       "      <td>606.014709</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 11:00:00</th>\n",
       "      <td>550.820190</td>\n",
       "      <td>627.223389</td>\n",
       "      <td>589.945129</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 12:00:00</th>\n",
       "      <td>604.445618</td>\n",
       "      <td>667.948914</td>\n",
       "      <td>636.034668</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 13:00:00</th>\n",
       "      <td>643.609924</td>\n",
       "      <td>724.495178</td>\n",
       "      <td>675.631348</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 14:00:00</th>\n",
       "      <td>721.349976</td>\n",
       "      <td>804.291138</td>\n",
       "      <td>758.392822</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 15:00:00</th>\n",
       "      <td>763.210938</td>\n",
       "      <td>866.914307</td>\n",
       "      <td>805.694519</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 16:00:00</th>\n",
       "      <td>870.339783</td>\n",
       "      <td>961.377197</td>\n",
       "      <td>909.817810</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 17:00:00</th>\n",
       "      <td>823.449890</td>\n",
       "      <td>990.989868</td>\n",
       "      <td>910.317871</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 18:00:00</th>\n",
       "      <td>780.369995</td>\n",
       "      <td>943.137634</td>\n",
       "      <td>877.593750</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 19:00:00</th>\n",
       "      <td>674.775024</td>\n",
       "      <td>804.879944</td>\n",
       "      <td>730.710449</td>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 20:00:00</th>\n",
       "      <td>587.509949</td>\n",
       "      <td>692.333618</td>\n",
       "      <td>639.141418</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 21:00:00</th>\n",
       "      <td>470.061340</td>\n",
       "      <td>578.008301</td>\n",
       "      <td>533.997742</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 22:00:00</th>\n",
       "      <td>405.714661</td>\n",
       "      <td>494.944183</td>\n",
       "      <td>451.549225</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-21 23:00:00</th>\n",
       "      <td>295.985291</td>\n",
       "      <td>364.951691</td>\n",
       "      <td>315.420868</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 00:00:00</th>\n",
       "      <td>220.009399</td>\n",
       "      <td>256.195099</td>\n",
       "      <td>232.972214</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 01:00:00</th>\n",
       "      <td>135.737656</td>\n",
       "      <td>174.115829</td>\n",
       "      <td>156.369904</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 02:00:00</th>\n",
       "      <td>100.321609</td>\n",
       "      <td>142.613586</td>\n",
       "      <td>115.786026</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 03:00:00</th>\n",
       "      <td>79.869514</td>\n",
       "      <td>112.332222</td>\n",
       "      <td>99.429764</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 04:00:00</th>\n",
       "      <td>54.676895</td>\n",
       "      <td>85.738495</td>\n",
       "      <td>71.682671</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 05:00:00</th>\n",
       "      <td>152.936447</td>\n",
       "      <td>190.833725</td>\n",
       "      <td>165.341187</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 06:00:00</th>\n",
       "      <td>350.228973</td>\n",
       "      <td>435.288513</td>\n",
       "      <td>394.114532</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 07:00:00</th>\n",
       "      <td>583.196716</td>\n",
       "      <td>688.140869</td>\n",
       "      <td>631.182861</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 08:00:00</th>\n",
       "      <td>640.196472</td>\n",
       "      <td>716.322327</td>\n",
       "      <td>675.425964</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 09:00:00</th>\n",
       "      <td>567.881775</td>\n",
       "      <td>665.379333</td>\n",
       "      <td>614.304077</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 10:00:00</th>\n",
       "      <td>544.551636</td>\n",
       "      <td>656.852661</td>\n",
       "      <td>576.812256</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 11:00:00</th>\n",
       "      <td>500.404755</td>\n",
       "      <td>585.007080</td>\n",
       "      <td>540.063721</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 12:00:00</th>\n",
       "      <td>563.920532</td>\n",
       "      <td>642.464050</td>\n",
       "      <td>601.761414</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 13:00:00</th>\n",
       "      <td>627.982910</td>\n",
       "      <td>731.190186</td>\n",
       "      <td>674.915588</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 14:00:00</th>\n",
       "      <td>739.152649</td>\n",
       "      <td>851.722229</td>\n",
       "      <td>790.049377</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 15:00:00</th>\n",
       "      <td>811.806519</td>\n",
       "      <td>932.414062</td>\n",
       "      <td>875.377686</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 16:00:00</th>\n",
       "      <td>877.071228</td>\n",
       "      <td>992.965820</td>\n",
       "      <td>934.060303</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 17:00:00</th>\n",
       "      <td>863.430420</td>\n",
       "      <td>1023.212463</td>\n",
       "      <td>944.624084</td>\n",
       "      <td>1005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 18:00:00</th>\n",
       "      <td>843.328491</td>\n",
       "      <td>1010.029114</td>\n",
       "      <td>905.899963</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 19:00:00</th>\n",
       "      <td>763.513123</td>\n",
       "      <td>909.813354</td>\n",
       "      <td>825.429016</td>\n",
       "      <td>1028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 20:00:00</th>\n",
       "      <td>749.755615</td>\n",
       "      <td>843.647583</td>\n",
       "      <td>796.971375</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 21:00:00</th>\n",
       "      <td>610.669739</td>\n",
       "      <td>764.434082</td>\n",
       "      <td>698.379761</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 22:00:00</th>\n",
       "      <td>588.844116</td>\n",
       "      <td>725.149048</td>\n",
       "      <td>652.940491</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 23:00:00</th>\n",
       "      <td>484.914429</td>\n",
       "      <td>594.270996</td>\n",
       "      <td>544.455078</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 00:00:00</th>\n",
       "      <td>381.635498</td>\n",
       "      <td>455.075745</td>\n",
       "      <td>425.778168</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 01:00:00</th>\n",
       "      <td>302.625458</td>\n",
       "      <td>361.940704</td>\n",
       "      <td>329.158173</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 02:00:00</th>\n",
       "      <td>239.850937</td>\n",
       "      <td>299.721191</td>\n",
       "      <td>264.626953</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 03:00:00</th>\n",
       "      <td>172.216949</td>\n",
       "      <td>227.718491</td>\n",
       "      <td>191.648804</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 04:00:00</th>\n",
       "      <td>85.721771</td>\n",
       "      <td>129.768921</td>\n",
       "      <td>111.778168</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 05:00:00</th>\n",
       "      <td>90.068893</td>\n",
       "      <td>131.841919</td>\n",
       "      <td>110.070625</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 06:00:00</th>\n",
       "      <td>169.011078</td>\n",
       "      <td>214.696533</td>\n",
       "      <td>189.685760</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 07:00:00</th>\n",
       "      <td>282.025696</td>\n",
       "      <td>347.401306</td>\n",
       "      <td>310.489441</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 08:00:00</th>\n",
       "      <td>363.988739</td>\n",
       "      <td>447.275757</td>\n",
       "      <td>409.794312</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 09:00:00</th>\n",
       "      <td>439.243988</td>\n",
       "      <td>530.112000</td>\n",
       "      <td>483.091125</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 10:00:00</th>\n",
       "      <td>483.932343</td>\n",
       "      <td>588.460449</td>\n",
       "      <td>537.843994</td>\n",
       "      <td>525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 11:00:00</th>\n",
       "      <td>510.336456</td>\n",
       "      <td>617.759338</td>\n",
       "      <td>561.084717</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 12:00:00</th>\n",
       "      <td>608.067322</td>\n",
       "      <td>691.558838</td>\n",
       "      <td>659.118286</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 13:00:00</th>\n",
       "      <td>605.931213</td>\n",
       "      <td>721.008728</td>\n",
       "      <td>677.076355</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 14:00:00</th>\n",
       "      <td>690.671143</td>\n",
       "      <td>796.933655</td>\n",
       "      <td>742.841980</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 15:00:00</th>\n",
       "      <td>728.555603</td>\n",
       "      <td>823.986755</td>\n",
       "      <td>775.218628</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 16:00:00</th>\n",
       "      <td>811.094910</td>\n",
       "      <td>920.398560</td>\n",
       "      <td>878.226868</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 17:00:00</th>\n",
       "      <td>804.212708</td>\n",
       "      <td>924.250732</td>\n",
       "      <td>851.433777</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 18:00:00</th>\n",
       "      <td>767.333557</td>\n",
       "      <td>908.759644</td>\n",
       "      <td>829.771118</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 19:00:00</th>\n",
       "      <td>707.001892</td>\n",
       "      <td>814.777161</td>\n",
       "      <td>769.911011</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 20:00:00</th>\n",
       "      <td>674.843872</td>\n",
       "      <td>775.709290</td>\n",
       "      <td>724.869751</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 21:00:00</th>\n",
       "      <td>646.715271</td>\n",
       "      <td>746.359009</td>\n",
       "      <td>705.454041</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 22:00:00</th>\n",
       "      <td>617.312378</td>\n",
       "      <td>725.117188</td>\n",
       "      <td>670.558533</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-23 23:00:00</th>\n",
       "      <td>516.152161</td>\n",
       "      <td>625.151245</td>\n",
       "      <td>571.223511</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 00:00:00</th>\n",
       "      <td>439.444122</td>\n",
       "      <td>498.452606</td>\n",
       "      <td>468.866150</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 01:00:00</th>\n",
       "      <td>313.758667</td>\n",
       "      <td>382.915253</td>\n",
       "      <td>353.606964</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 02:00:00</th>\n",
       "      <td>244.308212</td>\n",
       "      <td>316.424255</td>\n",
       "      <td>279.312561</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 03:00:00</th>\n",
       "      <td>161.055817</td>\n",
       "      <td>235.823227</td>\n",
       "      <td>202.543274</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 04:00:00</th>\n",
       "      <td>93.742264</td>\n",
       "      <td>139.703781</td>\n",
       "      <td>118.084068</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 05:00:00</th>\n",
       "      <td>64.995010</td>\n",
       "      <td>115.965881</td>\n",
       "      <td>85.280388</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 06:00:00</th>\n",
       "      <td>135.188263</td>\n",
       "      <td>173.634842</td>\n",
       "      <td>154.243423</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 07:00:00</th>\n",
       "      <td>215.035339</td>\n",
       "      <td>257.674408</td>\n",
       "      <td>235.501343</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 08:00:00</th>\n",
       "      <td>301.348755</td>\n",
       "      <td>354.874969</td>\n",
       "      <td>328.906860</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 09:00:00</th>\n",
       "      <td>377.465240</td>\n",
       "      <td>434.735107</td>\n",
       "      <td>409.886292</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 10:00:00</th>\n",
       "      <td>462.269226</td>\n",
       "      <td>526.459473</td>\n",
       "      <td>496.397125</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 11:00:00</th>\n",
       "      <td>507.375732</td>\n",
       "      <td>576.650269</td>\n",
       "      <td>521.648987</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 12:00:00</th>\n",
       "      <td>547.463501</td>\n",
       "      <td>612.834900</td>\n",
       "      <td>579.540161</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 13:00:00</th>\n",
       "      <td>582.718140</td>\n",
       "      <td>665.953735</td>\n",
       "      <td>630.749817</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 14:00:00</th>\n",
       "      <td>618.815918</td>\n",
       "      <td>708.615051</td>\n",
       "      <td>661.505615</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 15:00:00</th>\n",
       "      <td>591.135315</td>\n",
       "      <td>708.124023</td>\n",
       "      <td>645.480652</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 16:00:00</th>\n",
       "      <td>600.016357</td>\n",
       "      <td>685.036682</td>\n",
       "      <td>643.159241</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 17:00:00</th>\n",
       "      <td>590.827759</td>\n",
       "      <td>697.005554</td>\n",
       "      <td>633.076477</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 18:00:00</th>\n",
       "      <td>585.057312</td>\n",
       "      <td>680.260864</td>\n",
       "      <td>622.180542</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 19:00:00</th>\n",
       "      <td>513.618591</td>\n",
       "      <td>620.904114</td>\n",
       "      <td>571.111206</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 20:00:00</th>\n",
       "      <td>410.183228</td>\n",
       "      <td>494.679688</td>\n",
       "      <td>459.829407</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 21:00:00</th>\n",
       "      <td>326.169220</td>\n",
       "      <td>427.052124</td>\n",
       "      <td>376.353241</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 22:00:00</th>\n",
       "      <td>268.580292</td>\n",
       "      <td>346.321075</td>\n",
       "      <td>321.218384</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-24 23:00:00</th>\n",
       "      <td>176.517685</td>\n",
       "      <td>232.157562</td>\n",
       "      <td>206.725662</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 00:00:00</th>\n",
       "      <td>90.089920</td>\n",
       "      <td>124.980278</td>\n",
       "      <td>106.125969</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 01:00:00</th>\n",
       "      <td>62.842960</td>\n",
       "      <td>91.194633</td>\n",
       "      <td>74.082214</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 02:00:00</th>\n",
       "      <td>56.416943</td>\n",
       "      <td>77.857574</td>\n",
       "      <td>70.515022</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 03:00:00</th>\n",
       "      <td>66.925171</td>\n",
       "      <td>86.466187</td>\n",
       "      <td>76.698158</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 04:00:00</th>\n",
       "      <td>66.711945</td>\n",
       "      <td>97.078476</td>\n",
       "      <td>77.246338</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 05:00:00</th>\n",
       "      <td>152.214371</td>\n",
       "      <td>198.589249</td>\n",
       "      <td>173.087708</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 06:00:00</th>\n",
       "      <td>337.322449</td>\n",
       "      <td>476.376862</td>\n",
       "      <td>388.476746</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 07:00:00</th>\n",
       "      <td>509.541840</td>\n",
       "      <td>660.117065</td>\n",
       "      <td>579.287720</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 08:00:00</th>\n",
       "      <td>610.099731</td>\n",
       "      <td>682.323486</td>\n",
       "      <td>639.717346</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 09:00:00</th>\n",
       "      <td>536.349121</td>\n",
       "      <td>592.578125</td>\n",
       "      <td>566.492249</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 10:00:00</th>\n",
       "      <td>536.265015</td>\n",
       "      <td>600.036926</td>\n",
       "      <td>572.249634</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 11:00:00</th>\n",
       "      <td>529.457825</td>\n",
       "      <td>605.916321</td>\n",
       "      <td>568.570068</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 12:00:00</th>\n",
       "      <td>510.405396</td>\n",
       "      <td>582.279846</td>\n",
       "      <td>544.050964</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 13:00:00</th>\n",
       "      <td>558.713745</td>\n",
       "      <td>648.643616</td>\n",
       "      <td>592.397888</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 14:00:00</th>\n",
       "      <td>635.192261</td>\n",
       "      <td>734.316284</td>\n",
       "      <td>671.230042</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 15:00:00</th>\n",
       "      <td>651.272034</td>\n",
       "      <td>762.206360</td>\n",
       "      <td>711.559631</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 16:00:00</th>\n",
       "      <td>746.824158</td>\n",
       "      <td>823.762146</td>\n",
       "      <td>783.215515</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 17:00:00</th>\n",
       "      <td>724.510071</td>\n",
       "      <td>825.506958</td>\n",
       "      <td>780.530151</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 18:00:00</th>\n",
       "      <td>662.411011</td>\n",
       "      <td>767.600708</td>\n",
       "      <td>733.461548</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 19:00:00</th>\n",
       "      <td>538.706970</td>\n",
       "      <td>615.918152</td>\n",
       "      <td>578.708923</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 20:00:00</th>\n",
       "      <td>509.265106</td>\n",
       "      <td>592.502747</td>\n",
       "      <td>553.872131</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 21:00:00</th>\n",
       "      <td>370.894257</td>\n",
       "      <td>450.194305</td>\n",
       "      <td>402.468536</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 22:00:00</th>\n",
       "      <td>268.609711</td>\n",
       "      <td>338.325562</td>\n",
       "      <td>304.317596</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-25 23:00:00</th>\n",
       "      <td>181.472778</td>\n",
       "      <td>230.187119</td>\n",
       "      <td>205.911255</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 00:00:00</th>\n",
       "      <td>114.345055</td>\n",
       "      <td>150.514236</td>\n",
       "      <td>132.938309</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 01:00:00</th>\n",
       "      <td>71.236237</td>\n",
       "      <td>105.035950</td>\n",
       "      <td>90.331749</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 02:00:00</th>\n",
       "      <td>49.860107</td>\n",
       "      <td>74.988510</td>\n",
       "      <td>63.040421</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 03:00:00</th>\n",
       "      <td>50.341316</td>\n",
       "      <td>79.797348</td>\n",
       "      <td>64.817398</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 04:00:00</th>\n",
       "      <td>53.357006</td>\n",
       "      <td>71.979874</td>\n",
       "      <td>61.041183</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 05:00:00</th>\n",
       "      <td>129.884567</td>\n",
       "      <td>178.761078</td>\n",
       "      <td>155.007202</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 06:00:00</th>\n",
       "      <td>359.905212</td>\n",
       "      <td>483.195435</td>\n",
       "      <td>402.133118</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 07:00:00</th>\n",
       "      <td>525.727661</td>\n",
       "      <td>654.793762</td>\n",
       "      <td>578.306702</td>\n",
       "      <td>417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 08:00:00</th>\n",
       "      <td>581.855469</td>\n",
       "      <td>681.522217</td>\n",
       "      <td>629.199890</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 09:00:00</th>\n",
       "      <td>518.339294</td>\n",
       "      <td>631.309692</td>\n",
       "      <td>579.226746</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 10:00:00</th>\n",
       "      <td>489.191833</td>\n",
       "      <td>578.944580</td>\n",
       "      <td>544.794067</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 11:00:00</th>\n",
       "      <td>482.649109</td>\n",
       "      <td>582.760925</td>\n",
       "      <td>534.686035</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 12:00:00</th>\n",
       "      <td>551.887207</td>\n",
       "      <td>613.929077</td>\n",
       "      <td>580.336365</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 13:00:00</th>\n",
       "      <td>601.858154</td>\n",
       "      <td>661.853516</td>\n",
       "      <td>625.453003</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 14:00:00</th>\n",
       "      <td>646.542603</td>\n",
       "      <td>740.821045</td>\n",
       "      <td>700.391174</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 15:00:00</th>\n",
       "      <td>679.524536</td>\n",
       "      <td>804.039062</td>\n",
       "      <td>753.582031</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 16:00:00</th>\n",
       "      <td>790.745605</td>\n",
       "      <td>864.417969</td>\n",
       "      <td>820.473755</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 17:00:00</th>\n",
       "      <td>752.002625</td>\n",
       "      <td>905.870239</td>\n",
       "      <td>826.324951</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 18:00:00</th>\n",
       "      <td>700.407715</td>\n",
       "      <td>821.201233</td>\n",
       "      <td>770.808655</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 19:00:00</th>\n",
       "      <td>594.738647</td>\n",
       "      <td>729.613586</td>\n",
       "      <td>665.459412</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 20:00:00</th>\n",
       "      <td>539.288818</td>\n",
       "      <td>617.799622</td>\n",
       "      <td>581.143188</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 21:00:00</th>\n",
       "      <td>425.693359</td>\n",
       "      <td>502.281677</td>\n",
       "      <td>459.083801</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 22:00:00</th>\n",
       "      <td>322.916901</td>\n",
       "      <td>392.229919</td>\n",
       "      <td>347.472443</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-26 23:00:00</th>\n",
       "      <td>193.416595</td>\n",
       "      <td>254.892395</td>\n",
       "      <td>230.890198</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 00:00:00</th>\n",
       "      <td>117.814667</td>\n",
       "      <td>157.669373</td>\n",
       "      <td>138.996292</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 01:00:00</th>\n",
       "      <td>70.827072</td>\n",
       "      <td>101.017326</td>\n",
       "      <td>86.077705</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 02:00:00</th>\n",
       "      <td>54.548908</td>\n",
       "      <td>76.836800</td>\n",
       "      <td>64.658455</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 03:00:00</th>\n",
       "      <td>50.200325</td>\n",
       "      <td>73.040794</td>\n",
       "      <td>60.371136</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 04:00:00</th>\n",
       "      <td>67.650642</td>\n",
       "      <td>83.498756</td>\n",
       "      <td>74.986496</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 05:00:00</th>\n",
       "      <td>153.760681</td>\n",
       "      <td>186.187790</td>\n",
       "      <td>169.826065</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 06:00:00</th>\n",
       "      <td>380.785217</td>\n",
       "      <td>439.392517</td>\n",
       "      <td>404.623596</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 07:00:00</th>\n",
       "      <td>575.390808</td>\n",
       "      <td>660.040649</td>\n",
       "      <td>619.889954</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 08:00:00</th>\n",
       "      <td>586.892456</td>\n",
       "      <td>673.079712</td>\n",
       "      <td>632.424927</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 09:00:00</th>\n",
       "      <td>540.917297</td>\n",
       "      <td>629.730347</td>\n",
       "      <td>582.789612</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 10:00:00</th>\n",
       "      <td>535.396606</td>\n",
       "      <td>626.247070</td>\n",
       "      <td>574.114807</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 11:00:00</th>\n",
       "      <td>544.303528</td>\n",
       "      <td>620.619385</td>\n",
       "      <td>579.564636</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 12:00:00</th>\n",
       "      <td>602.244446</td>\n",
       "      <td>681.430908</td>\n",
       "      <td>640.748169</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 13:00:00</th>\n",
       "      <td>603.100037</td>\n",
       "      <td>695.797058</td>\n",
       "      <td>652.317444</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 14:00:00</th>\n",
       "      <td>678.853821</td>\n",
       "      <td>789.523315</td>\n",
       "      <td>736.970764</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 15:00:00</th>\n",
       "      <td>705.872437</td>\n",
       "      <td>821.540771</td>\n",
       "      <td>775.517029</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 16:00:00</th>\n",
       "      <td>914.612488</td>\n",
       "      <td>1029.056763</td>\n",
       "      <td>980.928467</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 17:00:00</th>\n",
       "      <td>871.687317</td>\n",
       "      <td>994.438965</td>\n",
       "      <td>934.452148</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 18:00:00</th>\n",
       "      <td>774.861755</td>\n",
       "      <td>945.151184</td>\n",
       "      <td>868.103149</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 19:00:00</th>\n",
       "      <td>673.345032</td>\n",
       "      <td>817.248413</td>\n",
       "      <td>714.140991</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 20:00:00</th>\n",
       "      <td>551.020020</td>\n",
       "      <td>645.091675</td>\n",
       "      <td>601.282288</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 21:00:00</th>\n",
       "      <td>448.140778</td>\n",
       "      <td>564.096436</td>\n",
       "      <td>487.277557</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 22:00:00</th>\n",
       "      <td>338.968933</td>\n",
       "      <td>435.131897</td>\n",
       "      <td>380.217926</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-27 23:00:00</th>\n",
       "      <td>220.978302</td>\n",
       "      <td>300.860870</td>\n",
       "      <td>260.636383</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 00:00:00</th>\n",
       "      <td>168.095825</td>\n",
       "      <td>199.572311</td>\n",
       "      <td>184.244522</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 01:00:00</th>\n",
       "      <td>99.890068</td>\n",
       "      <td>128.883026</td>\n",
       "      <td>111.148720</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 02:00:00</th>\n",
       "      <td>68.964676</td>\n",
       "      <td>94.379524</td>\n",
       "      <td>79.556519</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 03:00:00</th>\n",
       "      <td>58.597336</td>\n",
       "      <td>90.137337</td>\n",
       "      <td>73.095024</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 04:00:00</th>\n",
       "      <td>74.640198</td>\n",
       "      <td>96.515297</td>\n",
       "      <td>87.004921</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 05:00:00</th>\n",
       "      <td>155.947266</td>\n",
       "      <td>198.275146</td>\n",
       "      <td>176.828598</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 06:00:00</th>\n",
       "      <td>368.779785</td>\n",
       "      <td>442.230957</td>\n",
       "      <td>416.575134</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 07:00:00</th>\n",
       "      <td>593.941223</td>\n",
       "      <td>698.502075</td>\n",
       "      <td>644.069214</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 08:00:00</th>\n",
       "      <td>383.950439</td>\n",
       "      <td>455.824280</td>\n",
       "      <td>415.098785</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 09:00:00</th>\n",
       "      <td>413.404175</td>\n",
       "      <td>477.536285</td>\n",
       "      <td>451.216766</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 10:00:00</th>\n",
       "      <td>435.728546</td>\n",
       "      <td>520.339233</td>\n",
       "      <td>479.807831</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 11:00:00</th>\n",
       "      <td>462.017151</td>\n",
       "      <td>549.637024</td>\n",
       "      <td>507.597229</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 12:00:00</th>\n",
       "      <td>487.503937</td>\n",
       "      <td>546.578125</td>\n",
       "      <td>509.693817</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 13:00:00</th>\n",
       "      <td>505.603394</td>\n",
       "      <td>607.625488</td>\n",
       "      <td>560.773254</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 14:00:00</th>\n",
       "      <td>609.105652</td>\n",
       "      <td>703.590515</td>\n",
       "      <td>652.341553</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 15:00:00</th>\n",
       "      <td>640.379089</td>\n",
       "      <td>747.017334</td>\n",
       "      <td>682.436035</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 16:00:00</th>\n",
       "      <td>657.870605</td>\n",
       "      <td>766.894226</td>\n",
       "      <td>714.082031</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 17:00:00</th>\n",
       "      <td>647.355652</td>\n",
       "      <td>769.897888</td>\n",
       "      <td>711.817932</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 18:00:00</th>\n",
       "      <td>626.295959</td>\n",
       "      <td>747.437927</td>\n",
       "      <td>697.460632</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 19:00:00</th>\n",
       "      <td>546.544922</td>\n",
       "      <td>649.109314</td>\n",
       "      <td>601.712036</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 20:00:00</th>\n",
       "      <td>502.933960</td>\n",
       "      <td>585.556641</td>\n",
       "      <td>546.032227</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 21:00:00</th>\n",
       "      <td>448.914276</td>\n",
       "      <td>531.762878</td>\n",
       "      <td>485.486816</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 22:00:00</th>\n",
       "      <td>375.025696</td>\n",
       "      <td>447.772644</td>\n",
       "      <td>414.948853</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-28 23:00:00</th>\n",
       "      <td>284.408112</td>\n",
       "      <td>336.888947</td>\n",
       "      <td>310.576324</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 00:00:00</th>\n",
       "      <td>195.517105</td>\n",
       "      <td>230.273483</td>\n",
       "      <td>211.476883</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 01:00:00</th>\n",
       "      <td>123.858658</td>\n",
       "      <td>156.921783</td>\n",
       "      <td>136.410767</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 02:00:00</th>\n",
       "      <td>89.464287</td>\n",
       "      <td>115.135376</td>\n",
       "      <td>102.606720</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 03:00:00</th>\n",
       "      <td>77.403107</td>\n",
       "      <td>106.326691</td>\n",
       "      <td>89.875946</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 04:00:00</th>\n",
       "      <td>57.116714</td>\n",
       "      <td>77.800819</td>\n",
       "      <td>67.049110</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 05:00:00</th>\n",
       "      <td>131.132401</td>\n",
       "      <td>161.530411</td>\n",
       "      <td>143.934525</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 06:00:00</th>\n",
       "      <td>298.399109</td>\n",
       "      <td>379.931946</td>\n",
       "      <td>334.017639</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 07:00:00</th>\n",
       "      <td>438.789978</td>\n",
       "      <td>545.591064</td>\n",
       "      <td>503.688263</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 08:00:00</th>\n",
       "      <td>381.445740</td>\n",
       "      <td>475.760132</td>\n",
       "      <td>415.115723</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 09:00:00</th>\n",
       "      <td>382.256989</td>\n",
       "      <td>484.878784</td>\n",
       "      <td>425.313629</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 10:00:00</th>\n",
       "      <td>388.494995</td>\n",
       "      <td>468.181610</td>\n",
       "      <td>418.687408</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 11:00:00</th>\n",
       "      <td>396.747894</td>\n",
       "      <td>489.303040</td>\n",
       "      <td>436.245056</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 12:00:00</th>\n",
       "      <td>473.863373</td>\n",
       "      <td>531.242615</td>\n",
       "      <td>491.782715</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 13:00:00</th>\n",
       "      <td>514.403381</td>\n",
       "      <td>598.877014</td>\n",
       "      <td>559.051392</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 14:00:00</th>\n",
       "      <td>624.626038</td>\n",
       "      <td>717.196533</td>\n",
       "      <td>661.360046</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 15:00:00</th>\n",
       "      <td>665.334961</td>\n",
       "      <td>772.515381</td>\n",
       "      <td>696.074890</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 16:00:00</th>\n",
       "      <td>727.627075</td>\n",
       "      <td>842.654175</td>\n",
       "      <td>775.181213</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 17:00:00</th>\n",
       "      <td>682.357666</td>\n",
       "      <td>826.077087</td>\n",
       "      <td>742.469055</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 18:00:00</th>\n",
       "      <td>620.747375</td>\n",
       "      <td>757.365479</td>\n",
       "      <td>693.962830</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 19:00:00</th>\n",
       "      <td>546.610474</td>\n",
       "      <td>691.143494</td>\n",
       "      <td>618.155884</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 20:00:00</th>\n",
       "      <td>516.968628</td>\n",
       "      <td>630.974121</td>\n",
       "      <td>577.412231</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 21:00:00</th>\n",
       "      <td>481.987000</td>\n",
       "      <td>588.045105</td>\n",
       "      <td>543.748535</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 22:00:00</th>\n",
       "      <td>458.623932</td>\n",
       "      <td>581.436401</td>\n",
       "      <td>518.138916</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-29 23:00:00</th>\n",
       "      <td>388.011322</td>\n",
       "      <td>494.577057</td>\n",
       "      <td>437.621857</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 00:00:00</th>\n",
       "      <td>273.600800</td>\n",
       "      <td>333.964172</td>\n",
       "      <td>300.272461</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 01:00:00</th>\n",
       "      <td>211.876495</td>\n",
       "      <td>277.551849</td>\n",
       "      <td>245.158783</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 02:00:00</th>\n",
       "      <td>161.124893</td>\n",
       "      <td>211.391617</td>\n",
       "      <td>188.726013</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 03:00:00</th>\n",
       "      <td>134.620804</td>\n",
       "      <td>177.354767</td>\n",
       "      <td>155.301208</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 04:00:00</th>\n",
       "      <td>60.275806</td>\n",
       "      <td>89.531693</td>\n",
       "      <td>76.602898</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 05:00:00</th>\n",
       "      <td>64.968880</td>\n",
       "      <td>98.962318</td>\n",
       "      <td>85.239311</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 06:00:00</th>\n",
       "      <td>117.456123</td>\n",
       "      <td>165.602737</td>\n",
       "      <td>149.671249</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 07:00:00</th>\n",
       "      <td>216.617615</td>\n",
       "      <td>298.786011</td>\n",
       "      <td>249.910507</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 08:00:00</th>\n",
       "      <td>299.182312</td>\n",
       "      <td>365.416199</td>\n",
       "      <td>334.186157</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 09:00:00</th>\n",
       "      <td>356.731995</td>\n",
       "      <td>448.286896</td>\n",
       "      <td>406.900085</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 10:00:00</th>\n",
       "      <td>410.715668</td>\n",
       "      <td>498.637573</td>\n",
       "      <td>447.724976</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 11:00:00</th>\n",
       "      <td>425.256348</td>\n",
       "      <td>513.378906</td>\n",
       "      <td>468.039948</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 12:00:00</th>\n",
       "      <td>532.180298</td>\n",
       "      <td>605.925537</td>\n",
       "      <td>563.835266</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 13:00:00</th>\n",
       "      <td>527.822693</td>\n",
       "      <td>630.653137</td>\n",
       "      <td>576.983887</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 14:00:00</th>\n",
       "      <td>601.184692</td>\n",
       "      <td>704.960693</td>\n",
       "      <td>661.703430</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 15:00:00</th>\n",
       "      <td>580.032166</td>\n",
       "      <td>707.642029</td>\n",
       "      <td>642.826660</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 16:00:00</th>\n",
       "      <td>735.769043</td>\n",
       "      <td>837.448547</td>\n",
       "      <td>791.372986</td>\n",
       "      <td>827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 17:00:00</th>\n",
       "      <td>675.194153</td>\n",
       "      <td>799.679688</td>\n",
       "      <td>743.171509</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 18:00:00</th>\n",
       "      <td>654.446777</td>\n",
       "      <td>776.352478</td>\n",
       "      <td>708.093750</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 19:00:00</th>\n",
       "      <td>611.146912</td>\n",
       "      <td>712.510681</td>\n",
       "      <td>655.590698</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 20:00:00</th>\n",
       "      <td>628.009888</td>\n",
       "      <td>701.418640</td>\n",
       "      <td>659.564331</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 21:00:00</th>\n",
       "      <td>590.508179</td>\n",
       "      <td>688.681213</td>\n",
       "      <td>639.086243</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 22:00:00</th>\n",
       "      <td>525.462341</td>\n",
       "      <td>650.203308</td>\n",
       "      <td>582.387817</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-30 23:00:00</th>\n",
       "      <td>421.954010</td>\n",
       "      <td>538.455322</td>\n",
       "      <td>476.031403</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 00:00:00</th>\n",
       "      <td>335.359802</td>\n",
       "      <td>401.921600</td>\n",
       "      <td>363.990540</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 01:00:00</th>\n",
       "      <td>236.159576</td>\n",
       "      <td>303.501251</td>\n",
       "      <td>274.743805</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 02:00:00</th>\n",
       "      <td>202.673660</td>\n",
       "      <td>261.837708</td>\n",
       "      <td>227.259201</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 03:00:00</th>\n",
       "      <td>150.995102</td>\n",
       "      <td>196.174225</td>\n",
       "      <td>169.823486</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 04:00:00</th>\n",
       "      <td>82.723785</td>\n",
       "      <td>114.306213</td>\n",
       "      <td>97.758194</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 05:00:00</th>\n",
       "      <td>52.516174</td>\n",
       "      <td>99.066185</td>\n",
       "      <td>71.999916</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 06:00:00</th>\n",
       "      <td>94.767357</td>\n",
       "      <td>148.601486</td>\n",
       "      <td>121.808449</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 07:00:00</th>\n",
       "      <td>191.393509</td>\n",
       "      <td>242.523529</td>\n",
       "      <td>215.835907</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 08:00:00</th>\n",
       "      <td>271.594879</td>\n",
       "      <td>331.099976</td>\n",
       "      <td>300.526764</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 09:00:00</th>\n",
       "      <td>364.720764</td>\n",
       "      <td>442.122192</td>\n",
       "      <td>404.367950</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 10:00:00</th>\n",
       "      <td>426.851685</td>\n",
       "      <td>523.050903</td>\n",
       "      <td>461.387604</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 11:00:00</th>\n",
       "      <td>447.630707</td>\n",
       "      <td>552.596436</td>\n",
       "      <td>506.441772</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 12:00:00</th>\n",
       "      <td>588.481262</td>\n",
       "      <td>646.788330</td>\n",
       "      <td>620.837463</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 13:00:00</th>\n",
       "      <td>568.186584</td>\n",
       "      <td>662.288574</td>\n",
       "      <td>623.023560</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 14:00:00</th>\n",
       "      <td>611.110229</td>\n",
       "      <td>719.184937</td>\n",
       "      <td>663.642273</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 15:00:00</th>\n",
       "      <td>562.354980</td>\n",
       "      <td>682.825195</td>\n",
       "      <td>621.004456</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 16:00:00</th>\n",
       "      <td>588.339600</td>\n",
       "      <td>676.361755</td>\n",
       "      <td>625.448425</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 17:00:00</th>\n",
       "      <td>519.131104</td>\n",
       "      <td>628.500610</td>\n",
       "      <td>579.857300</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 18:00:00</th>\n",
       "      <td>499.809692</td>\n",
       "      <td>636.780090</td>\n",
       "      <td>548.670959</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 19:00:00</th>\n",
       "      <td>432.873138</td>\n",
       "      <td>570.784485</td>\n",
       "      <td>498.721863</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 20:00:00</th>\n",
       "      <td>354.219543</td>\n",
       "      <td>426.650940</td>\n",
       "      <td>390.238922</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 21:00:00</th>\n",
       "      <td>288.583160</td>\n",
       "      <td>359.087646</td>\n",
       "      <td>326.323883</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 22:00:00</th>\n",
       "      <td>206.939743</td>\n",
       "      <td>299.001312</td>\n",
       "      <td>241.880188</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01 23:00:00</th>\n",
       "      <td>134.536377</td>\n",
       "      <td>191.109909</td>\n",
       "      <td>152.608627</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 00:00:00</th>\n",
       "      <td>92.412216</td>\n",
       "      <td>130.385422</td>\n",
       "      <td>108.887009</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 01:00:00</th>\n",
       "      <td>60.806515</td>\n",
       "      <td>96.517479</td>\n",
       "      <td>76.797997</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 02:00:00</th>\n",
       "      <td>45.726677</td>\n",
       "      <td>83.319870</td>\n",
       "      <td>66.278755</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 03:00:00</th>\n",
       "      <td>52.184425</td>\n",
       "      <td>80.322296</td>\n",
       "      <td>63.694977</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 04:00:00</th>\n",
       "      <td>40.157974</td>\n",
       "      <td>71.138275</td>\n",
       "      <td>54.755848</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 05:00:00</th>\n",
       "      <td>104.808929</td>\n",
       "      <td>162.238464</td>\n",
       "      <td>136.206192</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 06:00:00</th>\n",
       "      <td>203.265198</td>\n",
       "      <td>357.827454</td>\n",
       "      <td>305.798523</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 07:00:00</th>\n",
       "      <td>360.319031</td>\n",
       "      <td>528.748291</td>\n",
       "      <td>441.657349</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 08:00:00</th>\n",
       "      <td>577.150452</td>\n",
       "      <td>681.956177</td>\n",
       "      <td>629.050720</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 09:00:00</th>\n",
       "      <td>540.096985</td>\n",
       "      <td>633.971985</td>\n",
       "      <td>576.531677</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 10:00:00</th>\n",
       "      <td>531.785522</td>\n",
       "      <td>606.163208</td>\n",
       "      <td>575.487122</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 11:00:00</th>\n",
       "      <td>512.999390</td>\n",
       "      <td>597.096375</td>\n",
       "      <td>558.014282</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 12:00:00</th>\n",
       "      <td>564.476013</td>\n",
       "      <td>628.020813</td>\n",
       "      <td>593.661682</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 13:00:00</th>\n",
       "      <td>586.094421</td>\n",
       "      <td>670.852844</td>\n",
       "      <td>622.050415</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 14:00:00</th>\n",
       "      <td>631.136292</td>\n",
       "      <td>736.708740</td>\n",
       "      <td>681.066040</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 15:00:00</th>\n",
       "      <td>665.208313</td>\n",
       "      <td>756.148193</td>\n",
       "      <td>703.747742</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 16:00:00</th>\n",
       "      <td>729.424988</td>\n",
       "      <td>858.159668</td>\n",
       "      <td>782.882202</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 17:00:00</th>\n",
       "      <td>685.486023</td>\n",
       "      <td>823.770386</td>\n",
       "      <td>751.506287</td>\n",
       "      <td>815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 18:00:00</th>\n",
       "      <td>629.457642</td>\n",
       "      <td>770.206116</td>\n",
       "      <td>694.132446</td>\n",
       "      <td>874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 19:00:00</th>\n",
       "      <td>508.296814</td>\n",
       "      <td>623.452332</td>\n",
       "      <td>565.443420</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 20:00:00</th>\n",
       "      <td>420.972198</td>\n",
       "      <td>527.395813</td>\n",
       "      <td>476.045044</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 21:00:00</th>\n",
       "      <td>334.855927</td>\n",
       "      <td>450.429901</td>\n",
       "      <td>370.682709</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 22:00:00</th>\n",
       "      <td>245.380951</td>\n",
       "      <td>305.322021</td>\n",
       "      <td>270.986633</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-02 23:00:00</th>\n",
       "      <td>156.204987</td>\n",
       "      <td>216.421951</td>\n",
       "      <td>184.234741</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 00:00:00</th>\n",
       "      <td>91.924133</td>\n",
       "      <td>122.992218</td>\n",
       "      <td>108.739944</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 01:00:00</th>\n",
       "      <td>45.509907</td>\n",
       "      <td>80.997955</td>\n",
       "      <td>63.233852</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 02:00:00</th>\n",
       "      <td>39.633900</td>\n",
       "      <td>66.129959</td>\n",
       "      <td>49.819672</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 03:00:00</th>\n",
       "      <td>45.124458</td>\n",
       "      <td>67.130447</td>\n",
       "      <td>57.501228</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 04:00:00</th>\n",
       "      <td>44.020691</td>\n",
       "      <td>79.869415</td>\n",
       "      <td>57.622498</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 05:00:00</th>\n",
       "      <td>100.238647</td>\n",
       "      <td>160.769302</td>\n",
       "      <td>134.375076</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 06:00:00</th>\n",
       "      <td>282.063690</td>\n",
       "      <td>388.243408</td>\n",
       "      <td>333.054047</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 07:00:00</th>\n",
       "      <td>435.202454</td>\n",
       "      <td>568.824951</td>\n",
       "      <td>480.952759</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 08:00:00</th>\n",
       "      <td>587.125000</td>\n",
       "      <td>720.519470</td>\n",
       "      <td>637.181580</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 09:00:00</th>\n",
       "      <td>542.959595</td>\n",
       "      <td>685.468506</td>\n",
       "      <td>601.676819</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 10:00:00</th>\n",
       "      <td>506.192017</td>\n",
       "      <td>638.486267</td>\n",
       "      <td>576.214478</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 11:00:00</th>\n",
       "      <td>492.562073</td>\n",
       "      <td>593.701477</td>\n",
       "      <td>547.942566</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 12:00:00</th>\n",
       "      <td>536.846436</td>\n",
       "      <td>607.542114</td>\n",
       "      <td>583.835022</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 13:00:00</th>\n",
       "      <td>547.186584</td>\n",
       "      <td>665.138123</td>\n",
       "      <td>604.525391</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 14:00:00</th>\n",
       "      <td>608.723999</td>\n",
       "      <td>744.729065</td>\n",
       "      <td>681.227905</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 15:00:00</th>\n",
       "      <td>657.477783</td>\n",
       "      <td>792.303223</td>\n",
       "      <td>721.996338</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 16:00:00</th>\n",
       "      <td>742.156311</td>\n",
       "      <td>843.870667</td>\n",
       "      <td>788.471069</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 17:00:00</th>\n",
       "      <td>722.750427</td>\n",
       "      <td>870.908752</td>\n",
       "      <td>779.932617</td>\n",
       "      <td>925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 18:00:00</th>\n",
       "      <td>636.844910</td>\n",
       "      <td>807.800110</td>\n",
       "      <td>722.829468</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 19:00:00</th>\n",
       "      <td>530.657959</td>\n",
       "      <td>650.987427</td>\n",
       "      <td>599.280029</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 20:00:00</th>\n",
       "      <td>515.723572</td>\n",
       "      <td>600.897095</td>\n",
       "      <td>557.606812</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 21:00:00</th>\n",
       "      <td>389.827820</td>\n",
       "      <td>491.393372</td>\n",
       "      <td>446.001160</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 22:00:00</th>\n",
       "      <td>290.082794</td>\n",
       "      <td>368.562714</td>\n",
       "      <td>332.281036</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-03 23:00:00</th>\n",
       "      <td>186.841156</td>\n",
       "      <td>238.857483</td>\n",
       "      <td>218.297379</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 00:00:00</th>\n",
       "      <td>106.996422</td>\n",
       "      <td>143.168854</td>\n",
       "      <td>130.514984</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 01:00:00</th>\n",
       "      <td>70.884720</td>\n",
       "      <td>100.703850</td>\n",
       "      <td>85.730072</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 02:00:00</th>\n",
       "      <td>57.784191</td>\n",
       "      <td>80.795418</td>\n",
       "      <td>67.732758</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 03:00:00</th>\n",
       "      <td>54.885361</td>\n",
       "      <td>81.737961</td>\n",
       "      <td>67.050316</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 04:00:00</th>\n",
       "      <td>55.782135</td>\n",
       "      <td>77.434151</td>\n",
       "      <td>67.695641</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 05:00:00</th>\n",
       "      <td>138.846985</td>\n",
       "      <td>179.658340</td>\n",
       "      <td>156.144775</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 06:00:00</th>\n",
       "      <td>330.589233</td>\n",
       "      <td>394.497955</td>\n",
       "      <td>363.227570</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 07:00:00</th>\n",
       "      <td>499.236145</td>\n",
       "      <td>588.396973</td>\n",
       "      <td>542.415222</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 08:00:00</th>\n",
       "      <td>609.250610</td>\n",
       "      <td>696.036438</td>\n",
       "      <td>653.199402</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 09:00:00</th>\n",
       "      <td>550.821716</td>\n",
       "      <td>664.974121</td>\n",
       "      <td>608.147827</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 10:00:00</th>\n",
       "      <td>527.189575</td>\n",
       "      <td>635.456177</td>\n",
       "      <td>592.926147</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 11:00:00</th>\n",
       "      <td>538.016724</td>\n",
       "      <td>623.031494</td>\n",
       "      <td>581.962585</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 12:00:00</th>\n",
       "      <td>619.312622</td>\n",
       "      <td>693.579712</td>\n",
       "      <td>654.019592</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 13:00:00</th>\n",
       "      <td>622.584045</td>\n",
       "      <td>716.106323</td>\n",
       "      <td>678.510803</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 14:00:00</th>\n",
       "      <td>711.806946</td>\n",
       "      <td>812.175415</td>\n",
       "      <td>765.372864</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 15:00:00</th>\n",
       "      <td>738.423340</td>\n",
       "      <td>837.020874</td>\n",
       "      <td>771.200195</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 16:00:00</th>\n",
       "      <td>796.088074</td>\n",
       "      <td>866.965454</td>\n",
       "      <td>825.946106</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 17:00:00</th>\n",
       "      <td>780.240051</td>\n",
       "      <td>885.550171</td>\n",
       "      <td>838.215881</td>\n",
       "      <td>915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 18:00:00</th>\n",
       "      <td>736.328491</td>\n",
       "      <td>863.189575</td>\n",
       "      <td>796.374573</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 19:00:00</th>\n",
       "      <td>637.254944</td>\n",
       "      <td>733.360291</td>\n",
       "      <td>678.775391</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 20:00:00</th>\n",
       "      <td>524.414673</td>\n",
       "      <td>651.505737</td>\n",
       "      <td>582.303345</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 21:00:00</th>\n",
       "      <td>456.918457</td>\n",
       "      <td>544.270020</td>\n",
       "      <td>502.446655</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 22:00:00</th>\n",
       "      <td>364.125580</td>\n",
       "      <td>442.887787</td>\n",
       "      <td>386.591064</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-04 23:00:00</th>\n",
       "      <td>232.994400</td>\n",
       "      <td>294.683777</td>\n",
       "      <td>253.517136</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 00:00:00</th>\n",
       "      <td>153.108398</td>\n",
       "      <td>196.518799</td>\n",
       "      <td>173.787155</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 01:00:00</th>\n",
       "      <td>94.828262</td>\n",
       "      <td>124.364708</td>\n",
       "      <td>106.746010</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 02:00:00</th>\n",
       "      <td>67.408615</td>\n",
       "      <td>96.157593</td>\n",
       "      <td>82.261703</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 03:00:00</th>\n",
       "      <td>55.894943</td>\n",
       "      <td>86.539513</td>\n",
       "      <td>70.909523</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 04:00:00</th>\n",
       "      <td>57.524250</td>\n",
       "      <td>80.552223</td>\n",
       "      <td>67.944702</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 05:00:00</th>\n",
       "      <td>131.590881</td>\n",
       "      <td>172.222443</td>\n",
       "      <td>143.881607</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 06:00:00</th>\n",
       "      <td>312.950989</td>\n",
       "      <td>387.882935</td>\n",
       "      <td>344.051697</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 07:00:00</th>\n",
       "      <td>492.297150</td>\n",
       "      <td>592.355408</td>\n",
       "      <td>540.916565</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 08:00:00</th>\n",
       "      <td>599.201172</td>\n",
       "      <td>669.960876</td>\n",
       "      <td>638.401428</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 09:00:00</th>\n",
       "      <td>551.326538</td>\n",
       "      <td>638.693909</td>\n",
       "      <td>596.732544</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 10:00:00</th>\n",
       "      <td>558.900818</td>\n",
       "      <td>637.116089</td>\n",
       "      <td>602.636108</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 11:00:00</th>\n",
       "      <td>565.210876</td>\n",
       "      <td>627.003906</td>\n",
       "      <td>593.668518</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 12:00:00</th>\n",
       "      <td>596.231995</td>\n",
       "      <td>667.296814</td>\n",
       "      <td>631.155090</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 13:00:00</th>\n",
       "      <td>602.621094</td>\n",
       "      <td>708.621277</td>\n",
       "      <td>652.554321</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 14:00:00</th>\n",
       "      <td>711.704956</td>\n",
       "      <td>798.872559</td>\n",
       "      <td>742.623962</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 15:00:00</th>\n",
       "      <td>728.168030</td>\n",
       "      <td>844.754639</td>\n",
       "      <td>782.288879</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 16:00:00</th>\n",
       "      <td>854.464050</td>\n",
       "      <td>970.864014</td>\n",
       "      <td>909.049011</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 17:00:00</th>\n",
       "      <td>853.992004</td>\n",
       "      <td>979.394104</td>\n",
       "      <td>911.818054</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 18:00:00</th>\n",
       "      <td>766.359558</td>\n",
       "      <td>932.079590</td>\n",
       "      <td>847.161499</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 19:00:00</th>\n",
       "      <td>651.910522</td>\n",
       "      <td>785.919861</td>\n",
       "      <td>716.778625</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 20:00:00</th>\n",
       "      <td>633.822388</td>\n",
       "      <td>732.184204</td>\n",
       "      <td>676.821533</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 21:00:00</th>\n",
       "      <td>520.798340</td>\n",
       "      <td>622.063354</td>\n",
       "      <td>577.206909</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 22:00:00</th>\n",
       "      <td>404.701996</td>\n",
       "      <td>493.527893</td>\n",
       "      <td>442.428314</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05 23:00:00</th>\n",
       "      <td>279.530151</td>\n",
       "      <td>340.327911</td>\n",
       "      <td>302.622833</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 00:00:00</th>\n",
       "      <td>202.319199</td>\n",
       "      <td>233.205307</td>\n",
       "      <td>218.095276</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 01:00:00</th>\n",
       "      <td>120.215179</td>\n",
       "      <td>150.144318</td>\n",
       "      <td>133.603195</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 02:00:00</th>\n",
       "      <td>68.358658</td>\n",
       "      <td>106.790390</td>\n",
       "      <td>89.354256</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 03:00:00</th>\n",
       "      <td>57.863853</td>\n",
       "      <td>89.448547</td>\n",
       "      <td>77.187370</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 04:00:00</th>\n",
       "      <td>54.491833</td>\n",
       "      <td>75.233826</td>\n",
       "      <td>62.692631</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 05:00:00</th>\n",
       "      <td>128.995499</td>\n",
       "      <td>164.189011</td>\n",
       "      <td>148.108078</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 06:00:00</th>\n",
       "      <td>327.154999</td>\n",
       "      <td>406.103729</td>\n",
       "      <td>363.907898</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 07:00:00</th>\n",
       "      <td>515.011169</td>\n",
       "      <td>613.500610</td>\n",
       "      <td>569.749573</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 08:00:00</th>\n",
       "      <td>632.313660</td>\n",
       "      <td>710.108582</td>\n",
       "      <td>673.237122</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 09:00:00</th>\n",
       "      <td>606.033630</td>\n",
       "      <td>669.271362</td>\n",
       "      <td>634.343628</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 10:00:00</th>\n",
       "      <td>572.938293</td>\n",
       "      <td>650.724854</td>\n",
       "      <td>609.880127</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 11:00:00</th>\n",
       "      <td>522.546997</td>\n",
       "      <td>610.571106</td>\n",
       "      <td>559.794800</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 12:00:00</th>\n",
       "      <td>555.624573</td>\n",
       "      <td>616.487793</td>\n",
       "      <td>578.195496</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 13:00:00</th>\n",
       "      <td>591.098938</td>\n",
       "      <td>690.128662</td>\n",
       "      <td>650.628784</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 14:00:00</th>\n",
       "      <td>725.989197</td>\n",
       "      <td>832.022888</td>\n",
       "      <td>773.004883</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 15:00:00</th>\n",
       "      <td>771.891541</td>\n",
       "      <td>880.365540</td>\n",
       "      <td>829.973145</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 16:00:00</th>\n",
       "      <td>926.970703</td>\n",
       "      <td>1042.731934</td>\n",
       "      <td>985.949829</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 17:00:00</th>\n",
       "      <td>929.526001</td>\n",
       "      <td>1042.180664</td>\n",
       "      <td>1000.819580</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 18:00:00</th>\n",
       "      <td>835.557434</td>\n",
       "      <td>998.109985</td>\n",
       "      <td>924.228638</td>\n",
       "      <td>1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 19:00:00</th>\n",
       "      <td>726.587341</td>\n",
       "      <td>897.991333</td>\n",
       "      <td>782.885071</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 20:00:00</th>\n",
       "      <td>714.914185</td>\n",
       "      <td>811.253967</td>\n",
       "      <td>766.811829</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 21:00:00</th>\n",
       "      <td>634.774780</td>\n",
       "      <td>762.137146</td>\n",
       "      <td>700.754272</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 22:00:00</th>\n",
       "      <td>558.027832</td>\n",
       "      <td>708.629211</td>\n",
       "      <td>627.433838</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-06 23:00:00</th>\n",
       "      <td>454.955963</td>\n",
       "      <td>576.159790</td>\n",
       "      <td>516.321167</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 00:00:00</th>\n",
       "      <td>395.719696</td>\n",
       "      <td>465.860657</td>\n",
       "      <td>422.877014</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 01:00:00</th>\n",
       "      <td>279.482849</td>\n",
       "      <td>347.317627</td>\n",
       "      <td>314.192719</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 02:00:00</th>\n",
       "      <td>194.730637</td>\n",
       "      <td>264.689331</td>\n",
       "      <td>223.697693</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 03:00:00</th>\n",
       "      <td>153.873825</td>\n",
       "      <td>213.291748</td>\n",
       "      <td>176.136337</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 04:00:00</th>\n",
       "      <td>106.778099</td>\n",
       "      <td>139.020248</td>\n",
       "      <td>120.954170</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 05:00:00</th>\n",
       "      <td>98.391571</td>\n",
       "      <td>138.846130</td>\n",
       "      <td>115.368713</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 06:00:00</th>\n",
       "      <td>158.554810</td>\n",
       "      <td>213.712631</td>\n",
       "      <td>187.636368</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 07:00:00</th>\n",
       "      <td>254.695129</td>\n",
       "      <td>333.196503</td>\n",
       "      <td>289.541809</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 08:00:00</th>\n",
       "      <td>390.036469</td>\n",
       "      <td>452.083618</td>\n",
       "      <td>415.365692</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 09:00:00</th>\n",
       "      <td>465.347961</td>\n",
       "      <td>544.474609</td>\n",
       "      <td>497.777313</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 10:00:00</th>\n",
       "      <td>521.464233</td>\n",
       "      <td>602.480469</td>\n",
       "      <td>567.643799</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 11:00:00</th>\n",
       "      <td>531.620605</td>\n",
       "      <td>638.238403</td>\n",
       "      <td>579.110107</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 12:00:00</th>\n",
       "      <td>684.089050</td>\n",
       "      <td>763.223511</td>\n",
       "      <td>717.555115</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 13:00:00</th>\n",
       "      <td>669.256653</td>\n",
       "      <td>779.184753</td>\n",
       "      <td>721.631226</td>\n",
       "      <td>721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 14:00:00</th>\n",
       "      <td>748.917969</td>\n",
       "      <td>868.200195</td>\n",
       "      <td>806.559143</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 15:00:00</th>\n",
       "      <td>741.554382</td>\n",
       "      <td>874.772644</td>\n",
       "      <td>818.198853</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 16:00:00</th>\n",
       "      <td>828.196777</td>\n",
       "      <td>953.851868</td>\n",
       "      <td>885.966064</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 17:00:00</th>\n",
       "      <td>838.107727</td>\n",
       "      <td>959.520691</td>\n",
       "      <td>878.505554</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 18:00:00</th>\n",
       "      <td>771.189148</td>\n",
       "      <td>894.334961</td>\n",
       "      <td>848.745544</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 19:00:00</th>\n",
       "      <td>688.457458</td>\n",
       "      <td>812.653564</td>\n",
       "      <td>749.034363</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 20:00:00</th>\n",
       "      <td>712.296265</td>\n",
       "      <td>811.077576</td>\n",
       "      <td>760.389160</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 21:00:00</th>\n",
       "      <td>663.940247</td>\n",
       "      <td>757.904602</td>\n",
       "      <td>713.043396</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 22:00:00</th>\n",
       "      <td>577.717957</td>\n",
       "      <td>717.385986</td>\n",
       "      <td>666.501099</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-07 23:00:00</th>\n",
       "      <td>495.221802</td>\n",
       "      <td>607.114014</td>\n",
       "      <td>542.477783</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 00:00:00</th>\n",
       "      <td>457.650665</td>\n",
       "      <td>522.931274</td>\n",
       "      <td>491.701813</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 01:00:00</th>\n",
       "      <td>330.408966</td>\n",
       "      <td>407.687286</td>\n",
       "      <td>367.529663</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 02:00:00</th>\n",
       "      <td>252.995209</td>\n",
       "      <td>319.964691</td>\n",
       "      <td>285.736481</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 03:00:00</th>\n",
       "      <td>191.504593</td>\n",
       "      <td>248.293884</td>\n",
       "      <td>216.161423</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 04:00:00</th>\n",
       "      <td>97.333412</td>\n",
       "      <td>128.226517</td>\n",
       "      <td>112.497597</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 05:00:00</th>\n",
       "      <td>60.136826</td>\n",
       "      <td>101.142044</td>\n",
       "      <td>82.234482</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 06:00:00</th>\n",
       "      <td>116.928322</td>\n",
       "      <td>158.225677</td>\n",
       "      <td>139.940338</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 07:00:00</th>\n",
       "      <td>200.878784</td>\n",
       "      <td>252.746735</td>\n",
       "      <td>226.401154</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 08:00:00</th>\n",
       "      <td>304.111664</td>\n",
       "      <td>366.930969</td>\n",
       "      <td>336.819916</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 09:00:00</th>\n",
       "      <td>398.879242</td>\n",
       "      <td>469.818298</td>\n",
       "      <td>430.270020</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 10:00:00</th>\n",
       "      <td>489.516235</td>\n",
       "      <td>569.287720</td>\n",
       "      <td>537.004333</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 11:00:00</th>\n",
       "      <td>527.647034</td>\n",
       "      <td>639.820312</td>\n",
       "      <td>575.263672</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 12:00:00</th>\n",
       "      <td>569.446167</td>\n",
       "      <td>659.891235</td>\n",
       "      <td>621.670776</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 13:00:00</th>\n",
       "      <td>558.913147</td>\n",
       "      <td>669.059448</td>\n",
       "      <td>621.338135</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 14:00:00</th>\n",
       "      <td>599.627319</td>\n",
       "      <td>735.552124</td>\n",
       "      <td>651.512146</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 15:00:00</th>\n",
       "      <td>604.304321</td>\n",
       "      <td>708.536255</td>\n",
       "      <td>647.404602</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 16:00:00</th>\n",
       "      <td>620.757568</td>\n",
       "      <td>695.202332</td>\n",
       "      <td>659.263611</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 17:00:00</th>\n",
       "      <td>580.428284</td>\n",
       "      <td>710.324463</td>\n",
       "      <td>654.095398</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 18:00:00</th>\n",
       "      <td>542.942505</td>\n",
       "      <td>634.786987</td>\n",
       "      <td>597.330261</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 19:00:00</th>\n",
       "      <td>441.479858</td>\n",
       "      <td>551.683350</td>\n",
       "      <td>505.745819</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 20:00:00</th>\n",
       "      <td>390.355377</td>\n",
       "      <td>447.776062</td>\n",
       "      <td>413.601471</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 21:00:00</th>\n",
       "      <td>297.689331</td>\n",
       "      <td>393.954681</td>\n",
       "      <td>334.443787</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 22:00:00</th>\n",
       "      <td>238.458618</td>\n",
       "      <td>306.640656</td>\n",
       "      <td>275.339111</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-08 23:00:00</th>\n",
       "      <td>156.966537</td>\n",
       "      <td>212.538879</td>\n",
       "      <td>181.704102</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 00:00:00</th>\n",
       "      <td>113.001114</td>\n",
       "      <td>150.094955</td>\n",
       "      <td>131.133652</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 01:00:00</th>\n",
       "      <td>65.475700</td>\n",
       "      <td>97.743439</td>\n",
       "      <td>79.499878</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 02:00:00</th>\n",
       "      <td>59.626259</td>\n",
       "      <td>90.641289</td>\n",
       "      <td>70.120468</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 03:00:00</th>\n",
       "      <td>64.895050</td>\n",
       "      <td>90.194656</td>\n",
       "      <td>77.221954</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 04:00:00</th>\n",
       "      <td>62.786713</td>\n",
       "      <td>92.187889</td>\n",
       "      <td>77.937218</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 05:00:00</th>\n",
       "      <td>142.041565</td>\n",
       "      <td>207.094376</td>\n",
       "      <td>173.591553</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 06:00:00</th>\n",
       "      <td>343.364319</td>\n",
       "      <td>477.609680</td>\n",
       "      <td>412.260254</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 07:00:00</th>\n",
       "      <td>514.047546</td>\n",
       "      <td>674.695740</td>\n",
       "      <td>623.716309</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 08:00:00</th>\n",
       "      <td>632.614380</td>\n",
       "      <td>719.419922</td>\n",
       "      <td>672.914001</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 09:00:00</th>\n",
       "      <td>567.571289</td>\n",
       "      <td>643.413818</td>\n",
       "      <td>598.815552</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 10:00:00</th>\n",
       "      <td>555.667664</td>\n",
       "      <td>631.384644</td>\n",
       "      <td>585.509155</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 11:00:00</th>\n",
       "      <td>533.847656</td>\n",
       "      <td>600.224976</td>\n",
       "      <td>571.974365</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 12:00:00</th>\n",
       "      <td>544.979126</td>\n",
       "      <td>597.429443</td>\n",
       "      <td>566.822571</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 13:00:00</th>\n",
       "      <td>561.111938</td>\n",
       "      <td>658.792725</td>\n",
       "      <td>598.628418</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 14:00:00</th>\n",
       "      <td>619.313721</td>\n",
       "      <td>723.600037</td>\n",
       "      <td>668.054749</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 15:00:00</th>\n",
       "      <td>659.736633</td>\n",
       "      <td>767.478699</td>\n",
       "      <td>712.909058</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 16:00:00</th>\n",
       "      <td>798.974854</td>\n",
       "      <td>911.138184</td>\n",
       "      <td>854.885803</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 17:00:00</th>\n",
       "      <td>804.102234</td>\n",
       "      <td>919.585938</td>\n",
       "      <td>859.078735</td>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 18:00:00</th>\n",
       "      <td>717.931152</td>\n",
       "      <td>822.564575</td>\n",
       "      <td>772.522095</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 19:00:00</th>\n",
       "      <td>574.032410</td>\n",
       "      <td>665.505676</td>\n",
       "      <td>630.296021</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 20:00:00</th>\n",
       "      <td>461.963562</td>\n",
       "      <td>552.491211</td>\n",
       "      <td>496.686646</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 21:00:00</th>\n",
       "      <td>341.807434</td>\n",
       "      <td>441.386292</td>\n",
       "      <td>388.731567</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 22:00:00</th>\n",
       "      <td>262.537659</td>\n",
       "      <td>332.631805</td>\n",
       "      <td>298.958893</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-09 23:00:00</th>\n",
       "      <td>163.764389</td>\n",
       "      <td>217.876053</td>\n",
       "      <td>189.125549</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 00:00:00</th>\n",
       "      <td>107.878555</td>\n",
       "      <td>140.036652</td>\n",
       "      <td>123.463516</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 01:00:00</th>\n",
       "      <td>62.440628</td>\n",
       "      <td>94.108337</td>\n",
       "      <td>76.476326</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 02:00:00</th>\n",
       "      <td>46.135815</td>\n",
       "      <td>74.920563</td>\n",
       "      <td>61.026154</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 03:00:00</th>\n",
       "      <td>44.452835</td>\n",
       "      <td>70.288643</td>\n",
       "      <td>61.913891</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 04:00:00</th>\n",
       "      <td>49.725140</td>\n",
       "      <td>69.323441</td>\n",
       "      <td>61.282883</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 05:00:00</th>\n",
       "      <td>117.036736</td>\n",
       "      <td>169.101654</td>\n",
       "      <td>144.883316</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 06:00:00</th>\n",
       "      <td>333.973755</td>\n",
       "      <td>455.770355</td>\n",
       "      <td>377.245880</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 07:00:00</th>\n",
       "      <td>508.665985</td>\n",
       "      <td>660.094727</td>\n",
       "      <td>588.386230</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 08:00:00</th>\n",
       "      <td>615.311768</td>\n",
       "      <td>723.773010</td>\n",
       "      <td>663.401794</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 09:00:00</th>\n",
       "      <td>547.672058</td>\n",
       "      <td>634.832581</td>\n",
       "      <td>590.629578</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 10:00:00</th>\n",
       "      <td>525.215515</td>\n",
       "      <td>652.152954</td>\n",
       "      <td>588.064941</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 11:00:00</th>\n",
       "      <td>497.792267</td>\n",
       "      <td>594.471191</td>\n",
       "      <td>548.064270</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 12:00:00</th>\n",
       "      <td>578.187012</td>\n",
       "      <td>656.547424</td>\n",
       "      <td>614.674438</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 13:00:00</th>\n",
       "      <td>597.916626</td>\n",
       "      <td>675.756653</td>\n",
       "      <td>639.542908</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 14:00:00</th>\n",
       "      <td>667.520203</td>\n",
       "      <td>765.922668</td>\n",
       "      <td>713.340515</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 15:00:00</th>\n",
       "      <td>707.200439</td>\n",
       "      <td>841.281494</td>\n",
       "      <td>782.170959</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 16:00:00</th>\n",
       "      <td>763.071106</td>\n",
       "      <td>859.958252</td>\n",
       "      <td>811.613708</td>\n",
       "      <td>705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 17:00:00</th>\n",
       "      <td>784.983276</td>\n",
       "      <td>891.959473</td>\n",
       "      <td>829.387756</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 18:00:00</th>\n",
       "      <td>742.219482</td>\n",
       "      <td>865.160950</td>\n",
       "      <td>799.271973</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 19:00:00</th>\n",
       "      <td>595.949890</td>\n",
       "      <td>691.509155</td>\n",
       "      <td>644.040161</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 20:00:00</th>\n",
       "      <td>537.045471</td>\n",
       "      <td>648.674683</td>\n",
       "      <td>574.612854</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 21:00:00</th>\n",
       "      <td>438.413483</td>\n",
       "      <td>531.249756</td>\n",
       "      <td>485.233063</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 22:00:00</th>\n",
       "      <td>331.522308</td>\n",
       "      <td>414.329254</td>\n",
       "      <td>380.917145</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-10 23:00:00</th>\n",
       "      <td>213.463928</td>\n",
       "      <td>276.513306</td>\n",
       "      <td>246.525818</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 00:00:00</th>\n",
       "      <td>131.008728</td>\n",
       "      <td>160.051483</td>\n",
       "      <td>143.050797</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 01:00:00</th>\n",
       "      <td>68.464203</td>\n",
       "      <td>95.510338</td>\n",
       "      <td>82.287544</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 02:00:00</th>\n",
       "      <td>51.846783</td>\n",
       "      <td>79.242226</td>\n",
       "      <td>59.692749</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 03:00:00</th>\n",
       "      <td>54.354790</td>\n",
       "      <td>76.278320</td>\n",
       "      <td>63.340069</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 04:00:00</th>\n",
       "      <td>48.532013</td>\n",
       "      <td>74.669220</td>\n",
       "      <td>62.674747</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 05:00:00</th>\n",
       "      <td>132.899078</td>\n",
       "      <td>172.063965</td>\n",
       "      <td>153.975174</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 06:00:00</th>\n",
       "      <td>344.757965</td>\n",
       "      <td>432.291290</td>\n",
       "      <td>381.123779</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 07:00:00</th>\n",
       "      <td>550.642395</td>\n",
       "      <td>683.515198</td>\n",
       "      <td>605.781189</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 08:00:00</th>\n",
       "      <td>633.937622</td>\n",
       "      <td>716.208374</td>\n",
       "      <td>669.512512</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 09:00:00</th>\n",
       "      <td>568.747375</td>\n",
       "      <td>649.729553</td>\n",
       "      <td>612.118591</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 10:00:00</th>\n",
       "      <td>559.999390</td>\n",
       "      <td>657.673401</td>\n",
       "      <td>603.226990</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 11:00:00</th>\n",
       "      <td>537.947327</td>\n",
       "      <td>637.805298</td>\n",
       "      <td>583.320984</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 12:00:00</th>\n",
       "      <td>550.541809</td>\n",
       "      <td>636.212708</td>\n",
       "      <td>601.862854</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 13:00:00</th>\n",
       "      <td>603.656616</td>\n",
       "      <td>693.365784</td>\n",
       "      <td>645.343079</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 14:00:00</th>\n",
       "      <td>683.451477</td>\n",
       "      <td>770.529846</td>\n",
       "      <td>726.244751</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 15:00:00</th>\n",
       "      <td>697.408386</td>\n",
       "      <td>832.092346</td>\n",
       "      <td>780.294739</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 16:00:00</th>\n",
       "      <td>806.719482</td>\n",
       "      <td>932.704956</td>\n",
       "      <td>882.144836</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 17:00:00</th>\n",
       "      <td>811.464294</td>\n",
       "      <td>948.529724</td>\n",
       "      <td>882.985107</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 18:00:00</th>\n",
       "      <td>723.471741</td>\n",
       "      <td>889.038269</td>\n",
       "      <td>829.305420</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 19:00:00</th>\n",
       "      <td>626.680664</td>\n",
       "      <td>769.724548</td>\n",
       "      <td>677.482483</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 20:00:00</th>\n",
       "      <td>588.034668</td>\n",
       "      <td>687.233459</td>\n",
       "      <td>644.760742</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 21:00:00</th>\n",
       "      <td>451.012695</td>\n",
       "      <td>578.851379</td>\n",
       "      <td>520.032593</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 22:00:00</th>\n",
       "      <td>371.042053</td>\n",
       "      <td>473.727417</td>\n",
       "      <td>416.537720</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-11 23:00:00</th>\n",
       "      <td>247.260529</td>\n",
       "      <td>318.962982</td>\n",
       "      <td>276.124756</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 00:00:00</th>\n",
       "      <td>151.115616</td>\n",
       "      <td>202.067001</td>\n",
       "      <td>174.567307</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 01:00:00</th>\n",
       "      <td>87.557449</td>\n",
       "      <td>124.578491</td>\n",
       "      <td>107.208885</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 02:00:00</th>\n",
       "      <td>65.045876</td>\n",
       "      <td>92.924408</td>\n",
       "      <td>79.430649</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 03:00:00</th>\n",
       "      <td>48.594059</td>\n",
       "      <td>79.575867</td>\n",
       "      <td>65.526848</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 04:00:00</th>\n",
       "      <td>51.909393</td>\n",
       "      <td>78.968353</td>\n",
       "      <td>63.473015</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 05:00:00</th>\n",
       "      <td>133.875412</td>\n",
       "      <td>166.946335</td>\n",
       "      <td>152.662537</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 06:00:00</th>\n",
       "      <td>338.933044</td>\n",
       "      <td>419.312103</td>\n",
       "      <td>370.293335</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 07:00:00</th>\n",
       "      <td>521.369141</td>\n",
       "      <td>615.849731</td>\n",
       "      <td>563.959839</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 08:00:00</th>\n",
       "      <td>664.713684</td>\n",
       "      <td>752.061401</td>\n",
       "      <td>705.738159</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 09:00:00</th>\n",
       "      <td>588.392151</td>\n",
       "      <td>700.950745</td>\n",
       "      <td>630.338318</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 10:00:00</th>\n",
       "      <td>576.039062</td>\n",
       "      <td>663.869873</td>\n",
       "      <td>617.156616</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 11:00:00</th>\n",
       "      <td>539.629517</td>\n",
       "      <td>650.961670</td>\n",
       "      <td>598.335693</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 12:00:00</th>\n",
       "      <td>574.103210</td>\n",
       "      <td>665.703796</td>\n",
       "      <td>626.895386</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 13:00:00</th>\n",
       "      <td>599.591064</td>\n",
       "      <td>705.675781</td>\n",
       "      <td>657.953857</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 14:00:00</th>\n",
       "      <td>686.064697</td>\n",
       "      <td>811.652588</td>\n",
       "      <td>732.738220</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 15:00:00</th>\n",
       "      <td>747.082092</td>\n",
       "      <td>862.833435</td>\n",
       "      <td>793.552368</td>\n",
       "      <td>748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 16:00:00</th>\n",
       "      <td>787.713562</td>\n",
       "      <td>947.868164</td>\n",
       "      <td>882.158875</td>\n",
       "      <td>821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 17:00:00</th>\n",
       "      <td>842.723022</td>\n",
       "      <td>993.135132</td>\n",
       "      <td>913.484985</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 18:00:00</th>\n",
       "      <td>803.868896</td>\n",
       "      <td>929.487183</td>\n",
       "      <td>841.572266</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 19:00:00</th>\n",
       "      <td>631.896057</td>\n",
       "      <td>793.661865</td>\n",
       "      <td>703.319092</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 20:00:00</th>\n",
       "      <td>694.290283</td>\n",
       "      <td>844.548828</td>\n",
       "      <td>749.621399</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 21:00:00</th>\n",
       "      <td>538.969421</td>\n",
       "      <td>671.327393</td>\n",
       "      <td>593.674377</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 22:00:00</th>\n",
       "      <td>402.472717</td>\n",
       "      <td>545.472778</td>\n",
       "      <td>481.394226</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-12 23:00:00</th>\n",
       "      <td>308.186066</td>\n",
       "      <td>389.944427</td>\n",
       "      <td>343.736206</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 00:00:00</th>\n",
       "      <td>200.410065</td>\n",
       "      <td>253.066803</td>\n",
       "      <td>226.547928</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 01:00:00</th>\n",
       "      <td>120.065437</td>\n",
       "      <td>174.956467</td>\n",
       "      <td>144.402237</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 02:00:00</th>\n",
       "      <td>75.496605</td>\n",
       "      <td>111.272308</td>\n",
       "      <td>94.443321</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 03:00:00</th>\n",
       "      <td>65.894272</td>\n",
       "      <td>100.161743</td>\n",
       "      <td>84.524879</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 04:00:00</th>\n",
       "      <td>62.563793</td>\n",
       "      <td>90.542404</td>\n",
       "      <td>79.374969</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 05:00:00</th>\n",
       "      <td>142.018478</td>\n",
       "      <td>180.244080</td>\n",
       "      <td>159.758820</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 06:00:00</th>\n",
       "      <td>335.307892</td>\n",
       "      <td>430.864410</td>\n",
       "      <td>377.107025</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 07:00:00</th>\n",
       "      <td>550.377014</td>\n",
       "      <td>645.785767</td>\n",
       "      <td>594.019470</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 08:00:00</th>\n",
       "      <td>633.828186</td>\n",
       "      <td>714.749573</td>\n",
       "      <td>671.725342</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 09:00:00</th>\n",
       "      <td>578.648315</td>\n",
       "      <td>674.930969</td>\n",
       "      <td>623.229675</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 10:00:00</th>\n",
       "      <td>557.593933</td>\n",
       "      <td>643.185242</td>\n",
       "      <td>590.436157</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 11:00:00</th>\n",
       "      <td>518.329529</td>\n",
       "      <td>598.772095</td>\n",
       "      <td>560.957703</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 12:00:00</th>\n",
       "      <td>523.302856</td>\n",
       "      <td>589.036072</td>\n",
       "      <td>544.544678</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 13:00:00</th>\n",
       "      <td>578.006531</td>\n",
       "      <td>682.915833</td>\n",
       "      <td>623.314331</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 14:00:00</th>\n",
       "      <td>682.667969</td>\n",
       "      <td>794.605469</td>\n",
       "      <td>734.910828</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 15:00:00</th>\n",
       "      <td>763.243835</td>\n",
       "      <td>906.302429</td>\n",
       "      <td>813.941711</td>\n",
       "      <td>904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 16:00:00</th>\n",
       "      <td>959.824951</td>\n",
       "      <td>1077.306885</td>\n",
       "      <td>1025.359009</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 17:00:00</th>\n",
       "      <td>934.362671</td>\n",
       "      <td>1099.949463</td>\n",
       "      <td>1015.166016</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 18:00:00</th>\n",
       "      <td>899.688965</td>\n",
       "      <td>1059.415527</td>\n",
       "      <td>986.321594</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 19:00:00</th>\n",
       "      <td>748.725830</td>\n",
       "      <td>883.774963</td>\n",
       "      <td>829.267578</td>\n",
       "      <td>1148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 20:00:00</th>\n",
       "      <td>774.183899</td>\n",
       "      <td>898.995789</td>\n",
       "      <td>835.606934</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 21:00:00</th>\n",
       "      <td>674.398560</td>\n",
       "      <td>781.959351</td>\n",
       "      <td>727.330688</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 22:00:00</th>\n",
       "      <td>590.887817</td>\n",
       "      <td>706.478882</td>\n",
       "      <td>642.091003</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-13 23:00:00</th>\n",
       "      <td>485.253693</td>\n",
       "      <td>605.218811</td>\n",
       "      <td>544.037598</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 00:00:00</th>\n",
       "      <td>407.105042</td>\n",
       "      <td>471.667236</td>\n",
       "      <td>443.714081</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 01:00:00</th>\n",
       "      <td>291.112915</td>\n",
       "      <td>365.447083</td>\n",
       "      <td>325.229675</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 02:00:00</th>\n",
       "      <td>220.454636</td>\n",
       "      <td>291.861328</td>\n",
       "      <td>252.059723</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 03:00:00</th>\n",
       "      <td>152.885956</td>\n",
       "      <td>218.057098</td>\n",
       "      <td>187.058777</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 04:00:00</th>\n",
       "      <td>65.986122</td>\n",
       "      <td>106.739853</td>\n",
       "      <td>90.069618</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 05:00:00</th>\n",
       "      <td>62.192314</td>\n",
       "      <td>110.867889</td>\n",
       "      <td>83.913300</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 06:00:00</th>\n",
       "      <td>138.189011</td>\n",
       "      <td>195.660522</td>\n",
       "      <td>168.595795</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 07:00:00</th>\n",
       "      <td>253.255188</td>\n",
       "      <td>308.688354</td>\n",
       "      <td>280.434692</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 08:00:00</th>\n",
       "      <td>368.600769</td>\n",
       "      <td>430.154572</td>\n",
       "      <td>391.346710</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 09:00:00</th>\n",
       "      <td>447.833374</td>\n",
       "      <td>527.073303</td>\n",
       "      <td>487.596436</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 10:00:00</th>\n",
       "      <td>488.300354</td>\n",
       "      <td>611.561646</td>\n",
       "      <td>553.640808</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 11:00:00</th>\n",
       "      <td>520.680603</td>\n",
       "      <td>614.173401</td>\n",
       "      <td>566.385315</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 12:00:00</th>\n",
       "      <td>621.606262</td>\n",
       "      <td>693.266113</td>\n",
       "      <td>658.437683</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 13:00:00</th>\n",
       "      <td>646.090088</td>\n",
       "      <td>744.954468</td>\n",
       "      <td>688.697205</td>\n",
       "      <td>763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 14:00:00</th>\n",
       "      <td>715.945496</td>\n",
       "      <td>853.066711</td>\n",
       "      <td>766.596191</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 15:00:00</th>\n",
       "      <td>759.068848</td>\n",
       "      <td>852.721313</td>\n",
       "      <td>812.781250</td>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 16:00:00</th>\n",
       "      <td>829.765015</td>\n",
       "      <td>981.957458</td>\n",
       "      <td>898.556885</td>\n",
       "      <td>859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 17:00:00</th>\n",
       "      <td>843.880920</td>\n",
       "      <td>999.947449</td>\n",
       "      <td>903.135559</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 18:00:00</th>\n",
       "      <td>809.537415</td>\n",
       "      <td>957.754456</td>\n",
       "      <td>867.679565</td>\n",
       "      <td>923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 19:00:00</th>\n",
       "      <td>724.315674</td>\n",
       "      <td>845.237305</td>\n",
       "      <td>798.234070</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 20:00:00</th>\n",
       "      <td>739.512512</td>\n",
       "      <td>850.167419</td>\n",
       "      <td>780.087646</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 21:00:00</th>\n",
       "      <td>666.789307</td>\n",
       "      <td>827.039856</td>\n",
       "      <td>730.450378</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 22:00:00</th>\n",
       "      <td>628.490662</td>\n",
       "      <td>762.098877</td>\n",
       "      <td>665.440186</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-14 23:00:00</th>\n",
       "      <td>505.078583</td>\n",
       "      <td>630.269836</td>\n",
       "      <td>558.657776</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 00:00:00</th>\n",
       "      <td>452.993896</td>\n",
       "      <td>515.394226</td>\n",
       "      <td>486.719299</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 01:00:00</th>\n",
       "      <td>330.407898</td>\n",
       "      <td>391.353424</td>\n",
       "      <td>357.732147</td>\n",
       "      <td>498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 02:00:00</th>\n",
       "      <td>260.099487</td>\n",
       "      <td>309.972565</td>\n",
       "      <td>284.502869</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 03:00:00</th>\n",
       "      <td>180.350586</td>\n",
       "      <td>243.124725</td>\n",
       "      <td>211.912231</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 04:00:00</th>\n",
       "      <td>90.319077</td>\n",
       "      <td>144.371490</td>\n",
       "      <td>116.565376</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 05:00:00</th>\n",
       "      <td>60.762726</td>\n",
       "      <td>105.969566</td>\n",
       "      <td>83.667419</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 06:00:00</th>\n",
       "      <td>121.414001</td>\n",
       "      <td>176.694397</td>\n",
       "      <td>139.934967</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 07:00:00</th>\n",
       "      <td>199.898788</td>\n",
       "      <td>262.649170</td>\n",
       "      <td>231.560806</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 08:00:00</th>\n",
       "      <td>293.722382</td>\n",
       "      <td>342.515961</td>\n",
       "      <td>322.313354</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 09:00:00</th>\n",
       "      <td>390.903687</td>\n",
       "      <td>455.987000</td>\n",
       "      <td>424.733765</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 10:00:00</th>\n",
       "      <td>466.651062</td>\n",
       "      <td>551.783447</td>\n",
       "      <td>506.700317</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 11:00:00</th>\n",
       "      <td>548.869507</td>\n",
       "      <td>604.932617</td>\n",
       "      <td>575.026672</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 12:00:00</th>\n",
       "      <td>606.383301</td>\n",
       "      <td>680.003296</td>\n",
       "      <td>650.716675</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 13:00:00</th>\n",
       "      <td>610.136230</td>\n",
       "      <td>710.767212</td>\n",
       "      <td>653.961609</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 14:00:00</th>\n",
       "      <td>653.148865</td>\n",
       "      <td>732.449707</td>\n",
       "      <td>701.041199</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 15:00:00</th>\n",
       "      <td>634.487793</td>\n",
       "      <td>747.923401</td>\n",
       "      <td>686.016602</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 16:00:00</th>\n",
       "      <td>666.560974</td>\n",
       "      <td>757.000427</td>\n",
       "      <td>717.349670</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 17:00:00</th>\n",
       "      <td>639.118347</td>\n",
       "      <td>735.976318</td>\n",
       "      <td>690.569946</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 18:00:00</th>\n",
       "      <td>565.410522</td>\n",
       "      <td>686.010620</td>\n",
       "      <td>631.117371</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 19:00:00</th>\n",
       "      <td>468.032501</td>\n",
       "      <td>569.269653</td>\n",
       "      <td>523.083984</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 20:00:00</th>\n",
       "      <td>427.022705</td>\n",
       "      <td>518.172363</td>\n",
       "      <td>465.841858</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 21:00:00</th>\n",
       "      <td>338.080261</td>\n",
       "      <td>432.395386</td>\n",
       "      <td>388.964874</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 22:00:00</th>\n",
       "      <td>248.861923</td>\n",
       "      <td>328.411377</td>\n",
       "      <td>293.440247</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-15 23:00:00</th>\n",
       "      <td>167.315308</td>\n",
       "      <td>226.931076</td>\n",
       "      <td>203.348114</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 00:00:00</th>\n",
       "      <td>98.505836</td>\n",
       "      <td>132.609406</td>\n",
       "      <td>111.100548</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 01:00:00</th>\n",
       "      <td>66.247581</td>\n",
       "      <td>90.886200</td>\n",
       "      <td>76.812141</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 02:00:00</th>\n",
       "      <td>61.205986</td>\n",
       "      <td>92.931931</td>\n",
       "      <td>70.241035</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 03:00:00</th>\n",
       "      <td>59.211510</td>\n",
       "      <td>85.320847</td>\n",
       "      <td>70.315620</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 04:00:00</th>\n",
       "      <td>62.798813</td>\n",
       "      <td>89.687576</td>\n",
       "      <td>75.183327</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 05:00:00</th>\n",
       "      <td>134.185425</td>\n",
       "      <td>191.364853</td>\n",
       "      <td>167.903259</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 06:00:00</th>\n",
       "      <td>309.170563</td>\n",
       "      <td>451.030640</td>\n",
       "      <td>390.312408</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 07:00:00</th>\n",
       "      <td>512.274170</td>\n",
       "      <td>710.270325</td>\n",
       "      <td>622.201660</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 08:00:00</th>\n",
       "      <td>633.201660</td>\n",
       "      <td>730.029236</td>\n",
       "      <td>694.269714</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 09:00:00</th>\n",
       "      <td>568.129272</td>\n",
       "      <td>670.093628</td>\n",
       "      <td>624.197937</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 10:00:00</th>\n",
       "      <td>542.485046</td>\n",
       "      <td>621.981628</td>\n",
       "      <td>590.301086</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 11:00:00</th>\n",
       "      <td>531.626465</td>\n",
       "      <td>602.257202</td>\n",
       "      <td>571.032898</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 12:00:00</th>\n",
       "      <td>572.309265</td>\n",
       "      <td>625.648438</td>\n",
       "      <td>597.630920</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 13:00:00</th>\n",
       "      <td>607.044556</td>\n",
       "      <td>684.902771</td>\n",
       "      <td>636.206421</td>\n",
       "      <td>593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 14:00:00</th>\n",
       "      <td>680.017761</td>\n",
       "      <td>762.986206</td>\n",
       "      <td>730.597839</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 15:00:00</th>\n",
       "      <td>670.927734</td>\n",
       "      <td>812.011414</td>\n",
       "      <td>756.866638</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 16:00:00</th>\n",
       "      <td>791.563354</td>\n",
       "      <td>896.979980</td>\n",
       "      <td>834.705627</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 17:00:00</th>\n",
       "      <td>791.503479</td>\n",
       "      <td>922.022217</td>\n",
       "      <td>864.914917</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 18:00:00</th>\n",
       "      <td>725.361511</td>\n",
       "      <td>853.644226</td>\n",
       "      <td>792.106140</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 19:00:00</th>\n",
       "      <td>583.837402</td>\n",
       "      <td>668.160583</td>\n",
       "      <td>628.095154</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 20:00:00</th>\n",
       "      <td>522.810791</td>\n",
       "      <td>604.858276</td>\n",
       "      <td>557.648865</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 21:00:00</th>\n",
       "      <td>393.908264</td>\n",
       "      <td>489.167419</td>\n",
       "      <td>434.111847</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 22:00:00</th>\n",
       "      <td>294.052734</td>\n",
       "      <td>366.006012</td>\n",
       "      <td>325.794189</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-16 23:00:00</th>\n",
       "      <td>186.199768</td>\n",
       "      <td>237.136612</td>\n",
       "      <td>208.917191</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 00:00:00</th>\n",
       "      <td>116.067192</td>\n",
       "      <td>138.559982</td>\n",
       "      <td>126.783836</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 01:00:00</th>\n",
       "      <td>67.699341</td>\n",
       "      <td>90.166534</td>\n",
       "      <td>79.176712</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 02:00:00</th>\n",
       "      <td>51.177208</td>\n",
       "      <td>73.704002</td>\n",
       "      <td>64.609840</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 03:00:00</th>\n",
       "      <td>47.627720</td>\n",
       "      <td>66.390106</td>\n",
       "      <td>55.923641</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 04:00:00</th>\n",
       "      <td>53.431953</td>\n",
       "      <td>75.482086</td>\n",
       "      <td>61.196659</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 05:00:00</th>\n",
       "      <td>133.951096</td>\n",
       "      <td>177.159439</td>\n",
       "      <td>154.134232</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 06:00:00</th>\n",
       "      <td>342.561401</td>\n",
       "      <td>477.398376</td>\n",
       "      <td>396.257324</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 07:00:00</th>\n",
       "      <td>548.517212</td>\n",
       "      <td>705.049194</td>\n",
       "      <td>625.232666</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 08:00:00</th>\n",
       "      <td>654.967285</td>\n",
       "      <td>746.850098</td>\n",
       "      <td>700.101624</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 09:00:00</th>\n",
       "      <td>585.966614</td>\n",
       "      <td>679.255005</td>\n",
       "      <td>639.049744</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 10:00:00</th>\n",
       "      <td>546.151855</td>\n",
       "      <td>635.748901</td>\n",
       "      <td>579.515381</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 11:00:00</th>\n",
       "      <td>519.999817</td>\n",
       "      <td>614.048950</td>\n",
       "      <td>569.520630</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 12:00:00</th>\n",
       "      <td>573.218750</td>\n",
       "      <td>635.578186</td>\n",
       "      <td>601.197571</td>\n",
       "      <td>581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 13:00:00</th>\n",
       "      <td>585.469360</td>\n",
       "      <td>682.685181</td>\n",
       "      <td>632.684509</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 14:00:00</th>\n",
       "      <td>662.649414</td>\n",
       "      <td>760.902100</td>\n",
       "      <td>707.665955</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 15:00:00</th>\n",
       "      <td>711.928711</td>\n",
       "      <td>827.673035</td>\n",
       "      <td>759.225159</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 16:00:00</th>\n",
       "      <td>813.473572</td>\n",
       "      <td>929.153992</td>\n",
       "      <td>867.388123</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 17:00:00</th>\n",
       "      <td>829.652161</td>\n",
       "      <td>932.062561</td>\n",
       "      <td>889.323303</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 18:00:00</th>\n",
       "      <td>770.445374</td>\n",
       "      <td>901.538269</td>\n",
       "      <td>833.224304</td>\n",
       "      <td>972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 19:00:00</th>\n",
       "      <td>674.747437</td>\n",
       "      <td>791.168579</td>\n",
       "      <td>727.678467</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 20:00:00</th>\n",
       "      <td>528.522827</td>\n",
       "      <td>610.980652</td>\n",
       "      <td>572.670227</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 21:00:00</th>\n",
       "      <td>422.864929</td>\n",
       "      <td>516.943787</td>\n",
       "      <td>472.160095</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 22:00:00</th>\n",
       "      <td>336.875397</td>\n",
       "      <td>412.405182</td>\n",
       "      <td>366.071198</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-17 23:00:00</th>\n",
       "      <td>204.958694</td>\n",
       "      <td>266.649536</td>\n",
       "      <td>234.449905</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 00:00:00</th>\n",
       "      <td>127.866966</td>\n",
       "      <td>153.310150</td>\n",
       "      <td>139.452332</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 01:00:00</th>\n",
       "      <td>70.105232</td>\n",
       "      <td>100.973015</td>\n",
       "      <td>83.982506</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 02:00:00</th>\n",
       "      <td>50.325504</td>\n",
       "      <td>77.036789</td>\n",
       "      <td>64.280838</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 03:00:00</th>\n",
       "      <td>49.724049</td>\n",
       "      <td>68.962105</td>\n",
       "      <td>61.592819</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 04:00:00</th>\n",
       "      <td>46.403191</td>\n",
       "      <td>69.196877</td>\n",
       "      <td>57.153450</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 05:00:00</th>\n",
       "      <td>139.066040</td>\n",
       "      <td>167.207932</td>\n",
       "      <td>154.756027</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 06:00:00</th>\n",
       "      <td>345.587769</td>\n",
       "      <td>405.071808</td>\n",
       "      <td>370.961487</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 07:00:00</th>\n",
       "      <td>592.873962</td>\n",
       "      <td>681.020630</td>\n",
       "      <td>627.128052</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 08:00:00</th>\n",
       "      <td>646.414124</td>\n",
       "      <td>737.819641</td>\n",
       "      <td>686.751831</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 09:00:00</th>\n",
       "      <td>591.532410</td>\n",
       "      <td>684.165771</td>\n",
       "      <td>634.849548</td>\n",
       "      <td>688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 10:00:00</th>\n",
       "      <td>558.551025</td>\n",
       "      <td>668.229919</td>\n",
       "      <td>616.391052</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 11:00:00</th>\n",
       "      <td>540.029419</td>\n",
       "      <td>643.083618</td>\n",
       "      <td>583.035767</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 12:00:00</th>\n",
       "      <td>587.893799</td>\n",
       "      <td>684.980347</td>\n",
       "      <td>636.383179</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 13:00:00</th>\n",
       "      <td>615.475891</td>\n",
       "      <td>718.215515</td>\n",
       "      <td>655.546753</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 14:00:00</th>\n",
       "      <td>687.312500</td>\n",
       "      <td>784.141357</td>\n",
       "      <td>735.295471</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 15:00:00</th>\n",
       "      <td>723.926147</td>\n",
       "      <td>825.320190</td>\n",
       "      <td>774.843079</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 16:00:00</th>\n",
       "      <td>833.539429</td>\n",
       "      <td>925.830750</td>\n",
       "      <td>878.117126</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 17:00:00</th>\n",
       "      <td>842.324951</td>\n",
       "      <td>962.612061</td>\n",
       "      <td>901.369019</td>\n",
       "      <td>850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 18:00:00</th>\n",
       "      <td>758.319885</td>\n",
       "      <td>897.807556</td>\n",
       "      <td>834.021912</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 19:00:00</th>\n",
       "      <td>667.964478</td>\n",
       "      <td>790.764221</td>\n",
       "      <td>734.253601</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 20:00:00</th>\n",
       "      <td>607.014221</td>\n",
       "      <td>720.069702</td>\n",
       "      <td>648.460266</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 21:00:00</th>\n",
       "      <td>494.421600</td>\n",
       "      <td>584.285828</td>\n",
       "      <td>546.893616</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 22:00:00</th>\n",
       "      <td>381.746368</td>\n",
       "      <td>469.724121</td>\n",
       "      <td>419.707703</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-18 23:00:00</th>\n",
       "      <td>248.395416</td>\n",
       "      <td>319.444489</td>\n",
       "      <td>288.442261</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 00:00:00</th>\n",
       "      <td>155.845001</td>\n",
       "      <td>205.653702</td>\n",
       "      <td>183.187820</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 01:00:00</th>\n",
       "      <td>97.475594</td>\n",
       "      <td>127.857201</td>\n",
       "      <td>115.158508</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 02:00:00</th>\n",
       "      <td>68.631989</td>\n",
       "      <td>101.313782</td>\n",
       "      <td>82.705856</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 03:00:00</th>\n",
       "      <td>61.729275</td>\n",
       "      <td>88.839386</td>\n",
       "      <td>71.102943</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 04:00:00</th>\n",
       "      <td>56.500858</td>\n",
       "      <td>82.020103</td>\n",
       "      <td>70.365479</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 05:00:00</th>\n",
       "      <td>145.972183</td>\n",
       "      <td>179.857834</td>\n",
       "      <td>161.611481</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 06:00:00</th>\n",
       "      <td>354.728882</td>\n",
       "      <td>417.648804</td>\n",
       "      <td>401.174194</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 07:00:00</th>\n",
       "      <td>602.123108</td>\n",
       "      <td>688.030945</td>\n",
       "      <td>643.032043</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 08:00:00</th>\n",
       "      <td>636.749756</td>\n",
       "      <td>722.630981</td>\n",
       "      <td>671.234436</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 09:00:00</th>\n",
       "      <td>598.541870</td>\n",
       "      <td>686.213623</td>\n",
       "      <td>633.964905</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 10:00:00</th>\n",
       "      <td>551.874878</td>\n",
       "      <td>644.461487</td>\n",
       "      <td>603.778564</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 11:00:00</th>\n",
       "      <td>541.838379</td>\n",
       "      <td>629.014832</td>\n",
       "      <td>588.041626</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 12:00:00</th>\n",
       "      <td>607.618286</td>\n",
       "      <td>674.452332</td>\n",
       "      <td>642.639648</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 13:00:00</th>\n",
       "      <td>629.493469</td>\n",
       "      <td>721.625671</td>\n",
       "      <td>657.705444</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 14:00:00</th>\n",
       "      <td>717.862915</td>\n",
       "      <td>827.338196</td>\n",
       "      <td>763.682983</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 15:00:00</th>\n",
       "      <td>730.648926</td>\n",
       "      <td>853.177734</td>\n",
       "      <td>800.247803</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 16:00:00</th>\n",
       "      <td>827.978699</td>\n",
       "      <td>942.469116</td>\n",
       "      <td>881.436523</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 17:00:00</th>\n",
       "      <td>850.679260</td>\n",
       "      <td>1001.858948</td>\n",
       "      <td>931.978149</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 18:00:00</th>\n",
       "      <td>812.050537</td>\n",
       "      <td>984.733643</td>\n",
       "      <td>885.614990</td>\n",
       "      <td>1031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 19:00:00</th>\n",
       "      <td>706.644287</td>\n",
       "      <td>872.606995</td>\n",
       "      <td>790.551941</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 20:00:00</th>\n",
       "      <td>683.986694</td>\n",
       "      <td>814.779846</td>\n",
       "      <td>753.029236</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 21:00:00</th>\n",
       "      <td>548.263123</td>\n",
       "      <td>685.814270</td>\n",
       "      <td>606.440613</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 22:00:00</th>\n",
       "      <td>420.601410</td>\n",
       "      <td>536.253784</td>\n",
       "      <td>481.477936</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-19 23:00:00</th>\n",
       "      <td>291.388031</td>\n",
       "      <td>394.440247</td>\n",
       "      <td>342.395294</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 00:00:00</th>\n",
       "      <td>189.520538</td>\n",
       "      <td>237.135605</td>\n",
       "      <td>216.036377</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 01:00:00</th>\n",
       "      <td>118.959000</td>\n",
       "      <td>169.143127</td>\n",
       "      <td>139.284790</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 02:00:00</th>\n",
       "      <td>79.696648</td>\n",
       "      <td>115.383354</td>\n",
       "      <td>95.443810</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 03:00:00</th>\n",
       "      <td>65.268707</td>\n",
       "      <td>92.019135</td>\n",
       "      <td>82.893875</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 04:00:00</th>\n",
       "      <td>71.023880</td>\n",
       "      <td>102.863579</td>\n",
       "      <td>85.037468</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 05:00:00</th>\n",
       "      <td>145.783936</td>\n",
       "      <td>185.435257</td>\n",
       "      <td>161.761185</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 06:00:00</th>\n",
       "      <td>341.990265</td>\n",
       "      <td>431.802307</td>\n",
       "      <td>385.614502</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 07:00:00</th>\n",
       "      <td>558.070557</td>\n",
       "      <td>674.196411</td>\n",
       "      <td>601.315857</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 08:00:00</th>\n",
       "      <td>626.502991</td>\n",
       "      <td>697.305603</td>\n",
       "      <td>653.847290</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 09:00:00</th>\n",
       "      <td>559.663757</td>\n",
       "      <td>638.207397</td>\n",
       "      <td>600.990601</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 10:00:00</th>\n",
       "      <td>540.172546</td>\n",
       "      <td>624.887512</td>\n",
       "      <td>592.362976</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 11:00:00</th>\n",
       "      <td>507.165985</td>\n",
       "      <td>580.289612</td>\n",
       "      <td>541.819702</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 12:00:00</th>\n",
       "      <td>565.260742</td>\n",
       "      <td>628.406860</td>\n",
       "      <td>594.211487</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 13:00:00</th>\n",
       "      <td>641.819031</td>\n",
       "      <td>729.372314</td>\n",
       "      <td>676.458984</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 14:00:00</th>\n",
       "      <td>758.818176</td>\n",
       "      <td>847.197693</td>\n",
       "      <td>800.188538</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 15:00:00</th>\n",
       "      <td>794.869995</td>\n",
       "      <td>908.195801</td>\n",
       "      <td>845.060730</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 16:00:00</th>\n",
       "      <td>914.249695</td>\n",
       "      <td>1030.468018</td>\n",
       "      <td>968.054932</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 17:00:00</th>\n",
       "      <td>918.019287</td>\n",
       "      <td>1066.116943</td>\n",
       "      <td>987.641052</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 18:00:00</th>\n",
       "      <td>839.890381</td>\n",
       "      <td>1014.921997</td>\n",
       "      <td>942.163818</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 19:00:00</th>\n",
       "      <td>761.284363</td>\n",
       "      <td>938.822083</td>\n",
       "      <td>840.342407</td>\n",
       "      <td>1058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 20:00:00</th>\n",
       "      <td>725.497131</td>\n",
       "      <td>863.520630</td>\n",
       "      <td>784.461365</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 21:00:00</th>\n",
       "      <td>620.458618</td>\n",
       "      <td>778.719543</td>\n",
       "      <td>695.220032</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 22:00:00</th>\n",
       "      <td>549.452026</td>\n",
       "      <td>668.854736</td>\n",
       "      <td>607.428223</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-20 23:00:00</th>\n",
       "      <td>462.877502</td>\n",
       "      <td>568.806946</td>\n",
       "      <td>516.798645</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 00:00:00</th>\n",
       "      <td>373.169006</td>\n",
       "      <td>433.709961</td>\n",
       "      <td>400.648895</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 01:00:00</th>\n",
       "      <td>261.641998</td>\n",
       "      <td>322.628601</td>\n",
       "      <td>288.752838</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 02:00:00</th>\n",
       "      <td>209.072296</td>\n",
       "      <td>261.682281</td>\n",
       "      <td>229.734573</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 03:00:00</th>\n",
       "      <td>156.622528</td>\n",
       "      <td>211.027084</td>\n",
       "      <td>184.845535</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 04:00:00</th>\n",
       "      <td>99.832336</td>\n",
       "      <td>133.587006</td>\n",
       "      <td>114.080788</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 05:00:00</th>\n",
       "      <td>100.253914</td>\n",
       "      <td>140.508286</td>\n",
       "      <td>112.845192</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 06:00:00</th>\n",
       "      <td>167.760971</td>\n",
       "      <td>206.738525</td>\n",
       "      <td>187.142731</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 07:00:00</th>\n",
       "      <td>257.331238</td>\n",
       "      <td>328.655029</td>\n",
       "      <td>298.377563</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 08:00:00</th>\n",
       "      <td>352.614410</td>\n",
       "      <td>427.956696</td>\n",
       "      <td>392.500305</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 09:00:00</th>\n",
       "      <td>435.150452</td>\n",
       "      <td>518.785339</td>\n",
       "      <td>482.857147</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 10:00:00</th>\n",
       "      <td>528.283142</td>\n",
       "      <td>610.038330</td>\n",
       "      <td>561.465759</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 11:00:00</th>\n",
       "      <td>526.973816</td>\n",
       "      <td>639.978333</td>\n",
       "      <td>591.028748</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 12:00:00</th>\n",
       "      <td>599.986450</td>\n",
       "      <td>687.103943</td>\n",
       "      <td>635.771057</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 13:00:00</th>\n",
       "      <td>628.882751</td>\n",
       "      <td>718.590149</td>\n",
       "      <td>675.798767</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 14:00:00</th>\n",
       "      <td>696.013794</td>\n",
       "      <td>793.622925</td>\n",
       "      <td>753.493530</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 15:00:00</th>\n",
       "      <td>721.975037</td>\n",
       "      <td>824.891968</td>\n",
       "      <td>778.729858</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 16:00:00</th>\n",
       "      <td>782.711487</td>\n",
       "      <td>892.573853</td>\n",
       "      <td>840.547485</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 17:00:00</th>\n",
       "      <td>805.820374</td>\n",
       "      <td>966.420654</td>\n",
       "      <td>865.855713</td>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 18:00:00</th>\n",
       "      <td>789.768188</td>\n",
       "      <td>922.879517</td>\n",
       "      <td>839.013367</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 19:00:00</th>\n",
       "      <td>719.452820</td>\n",
       "      <td>869.031616</td>\n",
       "      <td>787.217102</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 20:00:00</th>\n",
       "      <td>677.880981</td>\n",
       "      <td>765.285645</td>\n",
       "      <td>721.355225</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 21:00:00</th>\n",
       "      <td>651.348267</td>\n",
       "      <td>748.219421</td>\n",
       "      <td>695.902039</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 22:00:00</th>\n",
       "      <td>599.575928</td>\n",
       "      <td>725.185791</td>\n",
       "      <td>647.712158</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-21 23:00:00</th>\n",
       "      <td>503.090332</td>\n",
       "      <td>586.442810</td>\n",
       "      <td>543.625488</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 00:00:00</th>\n",
       "      <td>334.274567</td>\n",
       "      <td>379.482605</td>\n",
       "      <td>358.612396</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 01:00:00</th>\n",
       "      <td>256.785492</td>\n",
       "      <td>320.649689</td>\n",
       "      <td>293.222198</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 02:00:00</th>\n",
       "      <td>220.759674</td>\n",
       "      <td>270.070679</td>\n",
       "      <td>250.582733</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 03:00:00</th>\n",
       "      <td>163.260956</td>\n",
       "      <td>217.158173</td>\n",
       "      <td>185.960281</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 04:00:00</th>\n",
       "      <td>75.149132</td>\n",
       "      <td>110.413559</td>\n",
       "      <td>89.906990</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 05:00:00</th>\n",
       "      <td>60.486969</td>\n",
       "      <td>94.884087</td>\n",
       "      <td>74.213150</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 06:00:00</th>\n",
       "      <td>112.617477</td>\n",
       "      <td>159.075745</td>\n",
       "      <td>134.563690</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 07:00:00</th>\n",
       "      <td>201.029449</td>\n",
       "      <td>258.573639</td>\n",
       "      <td>227.899185</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 08:00:00</th>\n",
       "      <td>279.998108</td>\n",
       "      <td>339.077637</td>\n",
       "      <td>309.651184</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 09:00:00</th>\n",
       "      <td>373.955231</td>\n",
       "      <td>448.092560</td>\n",
       "      <td>417.555298</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 10:00:00</th>\n",
       "      <td>470.201355</td>\n",
       "      <td>546.102661</td>\n",
       "      <td>507.953735</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 11:00:00</th>\n",
       "      <td>501.348083</td>\n",
       "      <td>588.135742</td>\n",
       "      <td>545.689331</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 12:00:00</th>\n",
       "      <td>503.078613</td>\n",
       "      <td>582.229004</td>\n",
       "      <td>542.668823</td>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 13:00:00</th>\n",
       "      <td>530.042664</td>\n",
       "      <td>606.810608</td>\n",
       "      <td>566.479736</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 14:00:00</th>\n",
       "      <td>558.354919</td>\n",
       "      <td>665.496094</td>\n",
       "      <td>609.247559</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 15:00:00</th>\n",
       "      <td>592.060425</td>\n",
       "      <td>691.826782</td>\n",
       "      <td>626.054321</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 16:00:00</th>\n",
       "      <td>600.648132</td>\n",
       "      <td>662.434937</td>\n",
       "      <td>627.423340</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 17:00:00</th>\n",
       "      <td>588.096741</td>\n",
       "      <td>680.280090</td>\n",
       "      <td>631.337341</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 18:00:00</th>\n",
       "      <td>541.947205</td>\n",
       "      <td>645.100586</td>\n",
       "      <td>593.872559</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 19:00:00</th>\n",
       "      <td>486.251221</td>\n",
       "      <td>591.395203</td>\n",
       "      <td>540.287476</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 20:00:00</th>\n",
       "      <td>402.119293</td>\n",
       "      <td>469.883728</td>\n",
       "      <td>431.913605</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 21:00:00</th>\n",
       "      <td>329.418671</td>\n",
       "      <td>433.747711</td>\n",
       "      <td>365.248413</td>\n",
       "      <td>459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 22:00:00</th>\n",
       "      <td>239.221741</td>\n",
       "      <td>315.529785</td>\n",
       "      <td>281.473602</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-22 23:00:00</th>\n",
       "      <td>146.989670</td>\n",
       "      <td>210.259827</td>\n",
       "      <td>171.678375</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 00:00:00</th>\n",
       "      <td>88.484940</td>\n",
       "      <td>134.183533</td>\n",
       "      <td>118.684540</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 01:00:00</th>\n",
       "      <td>57.361664</td>\n",
       "      <td>93.229759</td>\n",
       "      <td>75.810799</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 02:00:00</th>\n",
       "      <td>52.069485</td>\n",
       "      <td>82.805069</td>\n",
       "      <td>69.211266</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 03:00:00</th>\n",
       "      <td>50.991432</td>\n",
       "      <td>80.417213</td>\n",
       "      <td>68.277756</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 04:00:00</th>\n",
       "      <td>58.483891</td>\n",
       "      <td>85.259735</td>\n",
       "      <td>69.954613</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 05:00:00</th>\n",
       "      <td>124.938293</td>\n",
       "      <td>193.579895</td>\n",
       "      <td>150.848389</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 06:00:00</th>\n",
       "      <td>298.098938</td>\n",
       "      <td>434.006775</td>\n",
       "      <td>360.124817</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 07:00:00</th>\n",
       "      <td>467.276947</td>\n",
       "      <td>635.268677</td>\n",
       "      <td>552.658142</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 08:00:00</th>\n",
       "      <td>442.202393</td>\n",
       "      <td>533.110168</td>\n",
       "      <td>479.271973</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 09:00:00</th>\n",
       "      <td>430.703857</td>\n",
       "      <td>508.979156</td>\n",
       "      <td>467.704071</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 10:00:00</th>\n",
       "      <td>431.759460</td>\n",
       "      <td>499.953491</td>\n",
       "      <td>461.030487</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 11:00:00</th>\n",
       "      <td>432.381073</td>\n",
       "      <td>512.841614</td>\n",
       "      <td>466.644135</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 12:00:00</th>\n",
       "      <td>510.220154</td>\n",
       "      <td>574.414246</td>\n",
       "      <td>526.613831</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 13:00:00</th>\n",
       "      <td>538.179321</td>\n",
       "      <td>604.114807</td>\n",
       "      <td>575.487610</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 14:00:00</th>\n",
       "      <td>605.748474</td>\n",
       "      <td>676.181946</td>\n",
       "      <td>642.537903</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 15:00:00</th>\n",
       "      <td>640.366821</td>\n",
       "      <td>723.280457</td>\n",
       "      <td>688.738953</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 16:00:00</th>\n",
       "      <td>773.989380</td>\n",
       "      <td>882.521057</td>\n",
       "      <td>835.548218</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 17:00:00</th>\n",
       "      <td>764.413086</td>\n",
       "      <td>881.161133</td>\n",
       "      <td>834.907654</td>\n",
       "      <td>816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 18:00:00</th>\n",
       "      <td>669.354126</td>\n",
       "      <td>825.829468</td>\n",
       "      <td>741.925537</td>\n",
       "      <td>774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 19:00:00</th>\n",
       "      <td>513.864990</td>\n",
       "      <td>655.036194</td>\n",
       "      <td>575.960999</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 20:00:00</th>\n",
       "      <td>470.903412</td>\n",
       "      <td>544.570374</td>\n",
       "      <td>514.835815</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 21:00:00</th>\n",
       "      <td>371.359497</td>\n",
       "      <td>450.728516</td>\n",
       "      <td>409.548065</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 22:00:00</th>\n",
       "      <td>250.322876</td>\n",
       "      <td>319.737915</td>\n",
       "      <td>290.510529</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23 23:00:00</th>\n",
       "      <td>149.604797</td>\n",
       "      <td>213.967514</td>\n",
       "      <td>182.404312</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 00:00:00</th>\n",
       "      <td>111.747070</td>\n",
       "      <td>139.810318</td>\n",
       "      <td>124.634300</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 01:00:00</th>\n",
       "      <td>67.136902</td>\n",
       "      <td>88.543900</td>\n",
       "      <td>77.396965</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 02:00:00</th>\n",
       "      <td>54.113541</td>\n",
       "      <td>77.893814</td>\n",
       "      <td>64.059486</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 03:00:00</th>\n",
       "      <td>50.406845</td>\n",
       "      <td>73.142525</td>\n",
       "      <td>63.105865</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 04:00:00</th>\n",
       "      <td>54.814289</td>\n",
       "      <td>76.049591</td>\n",
       "      <td>64.036690</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 05:00:00</th>\n",
       "      <td>113.639816</td>\n",
       "      <td>156.219727</td>\n",
       "      <td>132.276138</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 06:00:00</th>\n",
       "      <td>287.726715</td>\n",
       "      <td>384.454315</td>\n",
       "      <td>327.503113</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 07:00:00</th>\n",
       "      <td>441.180298</td>\n",
       "      <td>579.721375</td>\n",
       "      <td>510.702637</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 08:00:00</th>\n",
       "      <td>412.132477</td>\n",
       "      <td>503.445648</td>\n",
       "      <td>442.868530</td>\n",
       "      <td>340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 09:00:00</th>\n",
       "      <td>378.199005</td>\n",
       "      <td>512.691162</td>\n",
       "      <td>425.742706</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 10:00:00</th>\n",
       "      <td>392.825989</td>\n",
       "      <td>503.208771</td>\n",
       "      <td>445.814514</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 11:00:00</th>\n",
       "      <td>408.163971</td>\n",
       "      <td>506.863403</td>\n",
       "      <td>458.023010</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 12:00:00</th>\n",
       "      <td>517.057922</td>\n",
       "      <td>571.885803</td>\n",
       "      <td>553.988159</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 13:00:00</th>\n",
       "      <td>518.144043</td>\n",
       "      <td>598.440369</td>\n",
       "      <td>567.080994</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 14:00:00</th>\n",
       "      <td>597.454956</td>\n",
       "      <td>702.576904</td>\n",
       "      <td>644.559509</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 15:00:00</th>\n",
       "      <td>614.689453</td>\n",
       "      <td>739.500122</td>\n",
       "      <td>670.850708</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 16:00:00</th>\n",
       "      <td>825.556519</td>\n",
       "      <td>947.631714</td>\n",
       "      <td>873.311523</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 17:00:00</th>\n",
       "      <td>773.283264</td>\n",
       "      <td>892.223816</td>\n",
       "      <td>824.690063</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 18:00:00</th>\n",
       "      <td>692.410950</td>\n",
       "      <td>841.654053</td>\n",
       "      <td>761.742798</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 19:00:00</th>\n",
       "      <td>575.505188</td>\n",
       "      <td>731.080566</td>\n",
       "      <td>663.016663</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 20:00:00</th>\n",
       "      <td>498.543457</td>\n",
       "      <td>599.924011</td>\n",
       "      <td>545.690613</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 21:00:00</th>\n",
       "      <td>406.872162</td>\n",
       "      <td>507.425751</td>\n",
       "      <td>453.218964</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 22:00:00</th>\n",
       "      <td>325.605804</td>\n",
       "      <td>411.166901</td>\n",
       "      <td>365.119965</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24 23:00:00</th>\n",
       "      <td>193.330688</td>\n",
       "      <td>244.622406</td>\n",
       "      <td>224.769089</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 00:00:00</th>\n",
       "      <td>157.848602</td>\n",
       "      <td>185.851059</td>\n",
       "      <td>169.173340</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 01:00:00</th>\n",
       "      <td>77.666321</td>\n",
       "      <td>111.242012</td>\n",
       "      <td>101.393372</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 02:00:00</th>\n",
       "      <td>61.557137</td>\n",
       "      <td>85.513504</td>\n",
       "      <td>73.729088</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 03:00:00</th>\n",
       "      <td>53.511650</td>\n",
       "      <td>72.272659</td>\n",
       "      <td>61.548897</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 04:00:00</th>\n",
       "      <td>62.490768</td>\n",
       "      <td>86.329865</td>\n",
       "      <td>73.594658</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 05:00:00</th>\n",
       "      <td>135.511475</td>\n",
       "      <td>158.481781</td>\n",
       "      <td>145.837753</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 06:00:00</th>\n",
       "      <td>288.575378</td>\n",
       "      <td>348.307343</td>\n",
       "      <td>310.043182</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 07:00:00</th>\n",
       "      <td>483.621338</td>\n",
       "      <td>563.446106</td>\n",
       "      <td>524.576294</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 08:00:00</th>\n",
       "      <td>289.408508</td>\n",
       "      <td>370.079163</td>\n",
       "      <td>337.369476</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 09:00:00</th>\n",
       "      <td>323.095490</td>\n",
       "      <td>425.840515</td>\n",
       "      <td>370.569580</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 10:00:00</th>\n",
       "      <td>401.258484</td>\n",
       "      <td>469.520264</td>\n",
       "      <td>432.148590</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 11:00:00</th>\n",
       "      <td>391.806763</td>\n",
       "      <td>488.201721</td>\n",
       "      <td>439.542755</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 12:00:00</th>\n",
       "      <td>352.493622</td>\n",
       "      <td>424.369812</td>\n",
       "      <td>388.975433</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 13:00:00</th>\n",
       "      <td>398.318665</td>\n",
       "      <td>486.453247</td>\n",
       "      <td>448.004700</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 14:00:00</th>\n",
       "      <td>472.154572</td>\n",
       "      <td>565.442871</td>\n",
       "      <td>521.794006</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 15:00:00</th>\n",
       "      <td>496.017883</td>\n",
       "      <td>625.626282</td>\n",
       "      <td>551.059998</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 16:00:00</th>\n",
       "      <td>429.330170</td>\n",
       "      <td>524.003906</td>\n",
       "      <td>487.612030</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 17:00:00</th>\n",
       "      <td>427.207581</td>\n",
       "      <td>559.024536</td>\n",
       "      <td>504.096771</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 18:00:00</th>\n",
       "      <td>454.689606</td>\n",
       "      <td>552.104553</td>\n",
       "      <td>488.113525</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 19:00:00</th>\n",
       "      <td>409.692596</td>\n",
       "      <td>510.946716</td>\n",
       "      <td>459.360016</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 20:00:00</th>\n",
       "      <td>347.158020</td>\n",
       "      <td>407.331848</td>\n",
       "      <td>380.194519</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 21:00:00</th>\n",
       "      <td>329.304810</td>\n",
       "      <td>429.403076</td>\n",
       "      <td>387.502258</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 22:00:00</th>\n",
       "      <td>324.264404</td>\n",
       "      <td>384.867493</td>\n",
       "      <td>353.240021</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25 23:00:00</th>\n",
       "      <td>226.460129</td>\n",
       "      <td>272.995697</td>\n",
       "      <td>249.452408</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 00:00:00</th>\n",
       "      <td>118.241920</td>\n",
       "      <td>150.293365</td>\n",
       "      <td>131.432266</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 01:00:00</th>\n",
       "      <td>78.639442</td>\n",
       "      <td>102.835701</td>\n",
       "      <td>91.236671</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 02:00:00</th>\n",
       "      <td>54.820911</td>\n",
       "      <td>79.877419</td>\n",
       "      <td>68.995316</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 03:00:00</th>\n",
       "      <td>52.524181</td>\n",
       "      <td>71.499992</td>\n",
       "      <td>63.501060</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 04:00:00</th>\n",
       "      <td>38.415901</td>\n",
       "      <td>56.120575</td>\n",
       "      <td>48.004051</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 05:00:00</th>\n",
       "      <td>106.640953</td>\n",
       "      <td>133.090790</td>\n",
       "      <td>120.781357</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 06:00:00</th>\n",
       "      <td>243.715485</td>\n",
       "      <td>298.199341</td>\n",
       "      <td>273.409637</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 07:00:00</th>\n",
       "      <td>388.739410</td>\n",
       "      <td>492.351074</td>\n",
       "      <td>446.106079</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 08:00:00</th>\n",
       "      <td>363.000061</td>\n",
       "      <td>431.073059</td>\n",
       "      <td>394.191132</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 09:00:00</th>\n",
       "      <td>372.148499</td>\n",
       "      <td>436.722687</td>\n",
       "      <td>406.354187</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 10:00:00</th>\n",
       "      <td>394.247681</td>\n",
       "      <td>452.569427</td>\n",
       "      <td>421.210327</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 11:00:00</th>\n",
       "      <td>370.028503</td>\n",
       "      <td>432.185120</td>\n",
       "      <td>404.801941</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 12:00:00</th>\n",
       "      <td>451.701202</td>\n",
       "      <td>518.508911</td>\n",
       "      <td>481.362854</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 13:00:00</th>\n",
       "      <td>483.198639</td>\n",
       "      <td>553.844604</td>\n",
       "      <td>518.722961</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 14:00:00</th>\n",
       "      <td>516.055176</td>\n",
       "      <td>628.237244</td>\n",
       "      <td>579.185181</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 15:00:00</th>\n",
       "      <td>527.705444</td>\n",
       "      <td>648.472961</td>\n",
       "      <td>585.489624</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 16:00:00</th>\n",
       "      <td>621.999817</td>\n",
       "      <td>742.630249</td>\n",
       "      <td>656.552795</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 17:00:00</th>\n",
       "      <td>558.951416</td>\n",
       "      <td>679.017456</td>\n",
       "      <td>611.504395</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 18:00:00</th>\n",
       "      <td>488.539886</td>\n",
       "      <td>619.363770</td>\n",
       "      <td>572.355164</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 19:00:00</th>\n",
       "      <td>414.641296</td>\n",
       "      <td>545.469116</td>\n",
       "      <td>490.724426</td>\n",
       "      <td>636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 20:00:00</th>\n",
       "      <td>414.867310</td>\n",
       "      <td>522.178162</td>\n",
       "      <td>457.891052</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 21:00:00</th>\n",
       "      <td>349.002563</td>\n",
       "      <td>464.029694</td>\n",
       "      <td>413.849091</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 22:00:00</th>\n",
       "      <td>320.510681</td>\n",
       "      <td>402.958649</td>\n",
       "      <td>357.643616</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26 23:00:00</th>\n",
       "      <td>210.251862</td>\n",
       "      <td>300.942474</td>\n",
       "      <td>264.366272</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 00:00:00</th>\n",
       "      <td>142.126068</td>\n",
       "      <td>195.164749</td>\n",
       "      <td>158.939697</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 01:00:00</th>\n",
       "      <td>92.427963</td>\n",
       "      <td>144.647034</td>\n",
       "      <td>116.905586</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 02:00:00</th>\n",
       "      <td>76.682465</td>\n",
       "      <td>114.553093</td>\n",
       "      <td>97.380501</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 03:00:00</th>\n",
       "      <td>81.646545</td>\n",
       "      <td>111.800034</td>\n",
       "      <td>95.281334</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 04:00:00</th>\n",
       "      <td>55.147423</td>\n",
       "      <td>79.786995</td>\n",
       "      <td>68.041039</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 05:00:00</th>\n",
       "      <td>103.727249</td>\n",
       "      <td>143.335373</td>\n",
       "      <td>120.285934</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 06:00:00</th>\n",
       "      <td>187.368164</td>\n",
       "      <td>311.578705</td>\n",
       "      <td>224.487976</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 07:00:00</th>\n",
       "      <td>296.063873</td>\n",
       "      <td>453.445953</td>\n",
       "      <td>355.049011</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 08:00:00</th>\n",
       "      <td>305.543365</td>\n",
       "      <td>390.865387</td>\n",
       "      <td>353.120361</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 09:00:00</th>\n",
       "      <td>282.350647</td>\n",
       "      <td>385.469391</td>\n",
       "      <td>330.511505</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 10:00:00</th>\n",
       "      <td>297.558472</td>\n",
       "      <td>391.901550</td>\n",
       "      <td>337.096130</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 11:00:00</th>\n",
       "      <td>300.983002</td>\n",
       "      <td>385.258118</td>\n",
       "      <td>332.350525</td>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 12:00:00</th>\n",
       "      <td>379.100281</td>\n",
       "      <td>444.974854</td>\n",
       "      <td>415.455719</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 13:00:00</th>\n",
       "      <td>397.185394</td>\n",
       "      <td>499.923187</td>\n",
       "      <td>458.897797</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 14:00:00</th>\n",
       "      <td>469.142242</td>\n",
       "      <td>567.861877</td>\n",
       "      <td>521.183533</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 15:00:00</th>\n",
       "      <td>439.928436</td>\n",
       "      <td>562.114624</td>\n",
       "      <td>497.692688</td>\n",
       "      <td>696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 16:00:00</th>\n",
       "      <td>616.266113</td>\n",
       "      <td>748.506958</td>\n",
       "      <td>681.428223</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 17:00:00</th>\n",
       "      <td>533.730774</td>\n",
       "      <td>647.426453</td>\n",
       "      <td>601.664856</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 18:00:00</th>\n",
       "      <td>496.826172</td>\n",
       "      <td>605.454956</td>\n",
       "      <td>531.227234</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 19:00:00</th>\n",
       "      <td>378.789978</td>\n",
       "      <td>506.667267</td>\n",
       "      <td>435.439575</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 20:00:00</th>\n",
       "      <td>472.131317</td>\n",
       "      <td>564.479431</td>\n",
       "      <td>521.051697</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 21:00:00</th>\n",
       "      <td>431.651794</td>\n",
       "      <td>528.167358</td>\n",
       "      <td>475.305145</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 22:00:00</th>\n",
       "      <td>390.152435</td>\n",
       "      <td>489.793488</td>\n",
       "      <td>440.187592</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27 23:00:00</th>\n",
       "      <td>339.841431</td>\n",
       "      <td>408.009155</td>\n",
       "      <td>374.056610</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 00:00:00</th>\n",
       "      <td>252.091858</td>\n",
       "      <td>306.386993</td>\n",
       "      <td>279.534882</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 01:00:00</th>\n",
       "      <td>192.398499</td>\n",
       "      <td>237.373383</td>\n",
       "      <td>218.318619</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 02:00:00</th>\n",
       "      <td>155.391312</td>\n",
       "      <td>203.067657</td>\n",
       "      <td>177.588089</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 03:00:00</th>\n",
       "      <td>131.740265</td>\n",
       "      <td>167.118958</td>\n",
       "      <td>152.666183</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 04:00:00</th>\n",
       "      <td>77.401459</td>\n",
       "      <td>103.937271</td>\n",
       "      <td>85.156052</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 05:00:00</th>\n",
       "      <td>81.824013</td>\n",
       "      <td>105.014633</td>\n",
       "      <td>94.871674</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 06:00:00</th>\n",
       "      <td>129.130219</td>\n",
       "      <td>159.391632</td>\n",
       "      <td>144.233154</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 07:00:00</th>\n",
       "      <td>227.114990</td>\n",
       "      <td>258.435669</td>\n",
       "      <td>242.802475</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 08:00:00</th>\n",
       "      <td>329.364655</td>\n",
       "      <td>386.500488</td>\n",
       "      <td>347.645538</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 09:00:00</th>\n",
       "      <td>399.701843</td>\n",
       "      <td>482.568390</td>\n",
       "      <td>446.276611</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 10:00:00</th>\n",
       "      <td>465.890106</td>\n",
       "      <td>541.651794</td>\n",
       "      <td>507.462463</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 11:00:00</th>\n",
       "      <td>423.281677</td>\n",
       "      <td>526.434326</td>\n",
       "      <td>484.421906</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 12:00:00</th>\n",
       "      <td>456.657104</td>\n",
       "      <td>546.053894</td>\n",
       "      <td>509.071136</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 13:00:00</th>\n",
       "      <td>472.053192</td>\n",
       "      <td>587.095154</td>\n",
       "      <td>528.442749</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 14:00:00</th>\n",
       "      <td>526.142578</td>\n",
       "      <td>641.233032</td>\n",
       "      <td>573.701721</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 15:00:00</th>\n",
       "      <td>529.291809</td>\n",
       "      <td>653.783813</td>\n",
       "      <td>601.475830</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 16:00:00</th>\n",
       "      <td>604.561768</td>\n",
       "      <td>719.545898</td>\n",
       "      <td>670.385132</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 17:00:00</th>\n",
       "      <td>593.750183</td>\n",
       "      <td>694.481812</td>\n",
       "      <td>647.214783</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 18:00:00</th>\n",
       "      <td>581.115845</td>\n",
       "      <td>702.604553</td>\n",
       "      <td>633.704102</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 19:00:00</th>\n",
       "      <td>521.421753</td>\n",
       "      <td>642.821289</td>\n",
       "      <td>574.727722</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 20:00:00</th>\n",
       "      <td>498.946472</td>\n",
       "      <td>612.301514</td>\n",
       "      <td>559.678711</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 21:00:00</th>\n",
       "      <td>496.617981</td>\n",
       "      <td>590.326355</td>\n",
       "      <td>545.122864</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 22:00:00</th>\n",
       "      <td>448.028503</td>\n",
       "      <td>561.608215</td>\n",
       "      <td>503.263947</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-28 23:00:00</th>\n",
       "      <td>380.518188</td>\n",
       "      <td>452.301910</td>\n",
       "      <td>409.139618</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 00:00:00</th>\n",
       "      <td>313.653656</td>\n",
       "      <td>378.803284</td>\n",
       "      <td>349.761475</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 01:00:00</th>\n",
       "      <td>225.781723</td>\n",
       "      <td>281.388702</td>\n",
       "      <td>255.212921</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 02:00:00</th>\n",
       "      <td>182.773010</td>\n",
       "      <td>224.168564</td>\n",
       "      <td>207.690277</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 03:00:00</th>\n",
       "      <td>135.481476</td>\n",
       "      <td>179.628189</td>\n",
       "      <td>153.110703</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 04:00:00</th>\n",
       "      <td>98.054901</td>\n",
       "      <td>126.494934</td>\n",
       "      <td>113.357491</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 05:00:00</th>\n",
       "      <td>69.744263</td>\n",
       "      <td>104.057892</td>\n",
       "      <td>86.005997</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 06:00:00</th>\n",
       "      <td>94.114815</td>\n",
       "      <td>124.986115</td>\n",
       "      <td>110.654221</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 07:00:00</th>\n",
       "      <td>161.975571</td>\n",
       "      <td>199.098679</td>\n",
       "      <td>183.262695</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 08:00:00</th>\n",
       "      <td>249.960602</td>\n",
       "      <td>288.608459</td>\n",
       "      <td>266.312286</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 09:00:00</th>\n",
       "      <td>324.259033</td>\n",
       "      <td>396.780914</td>\n",
       "      <td>357.214478</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 10:00:00</th>\n",
       "      <td>398.677032</td>\n",
       "      <td>487.519775</td>\n",
       "      <td>433.044586</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 11:00:00</th>\n",
       "      <td>427.967133</td>\n",
       "      <td>511.907867</td>\n",
       "      <td>458.694550</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 12:00:00</th>\n",
       "      <td>449.001892</td>\n",
       "      <td>526.566406</td>\n",
       "      <td>474.105225</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 13:00:00</th>\n",
       "      <td>458.402863</td>\n",
       "      <td>542.933105</td>\n",
       "      <td>502.767548</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 14:00:00</th>\n",
       "      <td>508.778320</td>\n",
       "      <td>587.509949</td>\n",
       "      <td>542.185181</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 15:00:00</th>\n",
       "      <td>490.421204</td>\n",
       "      <td>597.446777</td>\n",
       "      <td>534.027832</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 16:00:00</th>\n",
       "      <td>576.612488</td>\n",
       "      <td>642.805298</td>\n",
       "      <td>601.535034</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 17:00:00</th>\n",
       "      <td>540.298767</td>\n",
       "      <td>616.177856</td>\n",
       "      <td>582.534363</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 18:00:00</th>\n",
       "      <td>494.445099</td>\n",
       "      <td>600.547607</td>\n",
       "      <td>557.978882</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 19:00:00</th>\n",
       "      <td>447.373505</td>\n",
       "      <td>539.182678</td>\n",
       "      <td>502.821350</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 20:00:00</th>\n",
       "      <td>372.631714</td>\n",
       "      <td>446.759125</td>\n",
       "      <td>411.410034</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 21:00:00</th>\n",
       "      <td>331.315613</td>\n",
       "      <td>399.686737</td>\n",
       "      <td>355.974365</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 22:00:00</th>\n",
       "      <td>256.375488</td>\n",
       "      <td>319.084442</td>\n",
       "      <td>289.467651</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-29 23:00:00</th>\n",
       "      <td>158.332077</td>\n",
       "      <td>213.340836</td>\n",
       "      <td>188.418045</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 00:00:00</th>\n",
       "      <td>114.943336</td>\n",
       "      <td>153.879028</td>\n",
       "      <td>130.834335</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 01:00:00</th>\n",
       "      <td>71.518715</td>\n",
       "      <td>112.928673</td>\n",
       "      <td>95.848030</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 02:00:00</th>\n",
       "      <td>72.108109</td>\n",
       "      <td>97.397980</td>\n",
       "      <td>82.692284</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 03:00:00</th>\n",
       "      <td>67.986549</td>\n",
       "      <td>90.895164</td>\n",
       "      <td>79.347206</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 04:00:00</th>\n",
       "      <td>43.803242</td>\n",
       "      <td>69.949287</td>\n",
       "      <td>60.618645</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 05:00:00</th>\n",
       "      <td>95.648628</td>\n",
       "      <td>139.790375</td>\n",
       "      <td>118.276619</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 06:00:00</th>\n",
       "      <td>205.395401</td>\n",
       "      <td>282.191711</td>\n",
       "      <td>241.210602</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 07:00:00</th>\n",
       "      <td>322.215637</td>\n",
       "      <td>452.433105</td>\n",
       "      <td>395.113220</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 08:00:00</th>\n",
       "      <td>418.243652</td>\n",
       "      <td>502.149689</td>\n",
       "      <td>460.631714</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 09:00:00</th>\n",
       "      <td>390.294952</td>\n",
       "      <td>459.062073</td>\n",
       "      <td>420.528290</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 10:00:00</th>\n",
       "      <td>401.436493</td>\n",
       "      <td>467.812897</td>\n",
       "      <td>430.379120</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 11:00:00</th>\n",
       "      <td>402.342590</td>\n",
       "      <td>471.130829</td>\n",
       "      <td>427.346924</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 12:00:00</th>\n",
       "      <td>520.786743</td>\n",
       "      <td>578.845032</td>\n",
       "      <td>542.841003</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 13:00:00</th>\n",
       "      <td>542.862244</td>\n",
       "      <td>615.338562</td>\n",
       "      <td>575.010559</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 14:00:00</th>\n",
       "      <td>620.423340</td>\n",
       "      <td>725.685364</td>\n",
       "      <td>666.004822</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 15:00:00</th>\n",
       "      <td>608.844238</td>\n",
       "      <td>712.077209</td>\n",
       "      <td>666.136719</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 16:00:00</th>\n",
       "      <td>749.988953</td>\n",
       "      <td>826.740662</td>\n",
       "      <td>786.078918</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 17:00:00</th>\n",
       "      <td>699.215881</td>\n",
       "      <td>824.938171</td>\n",
       "      <td>769.568115</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 18:00:00</th>\n",
       "      <td>598.392151</td>\n",
       "      <td>732.967102</td>\n",
       "      <td>674.885132</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 19:00:00</th>\n",
       "      <td>474.417175</td>\n",
       "      <td>592.017029</td>\n",
       "      <td>523.965942</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 20:00:00</th>\n",
       "      <td>398.819519</td>\n",
       "      <td>456.135529</td>\n",
       "      <td>423.351929</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 21:00:00</th>\n",
       "      <td>333.280090</td>\n",
       "      <td>397.833130</td>\n",
       "      <td>363.601837</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 22:00:00</th>\n",
       "      <td>252.404144</td>\n",
       "      <td>318.033997</td>\n",
       "      <td>282.609711</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 23:00:00</th>\n",
       "      <td>163.982468</td>\n",
       "      <td>211.150635</td>\n",
       "      <td>190.355408</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 00:00:00</th>\n",
       "      <td>139.430527</td>\n",
       "      <td>165.567261</td>\n",
       "      <td>155.229752</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 01:00:00</th>\n",
       "      <td>89.786247</td>\n",
       "      <td>118.653595</td>\n",
       "      <td>103.180527</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 02:00:00</th>\n",
       "      <td>67.129555</td>\n",
       "      <td>95.270805</td>\n",
       "      <td>83.075569</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 03:00:00</th>\n",
       "      <td>65.702599</td>\n",
       "      <td>86.533867</td>\n",
       "      <td>75.235252</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 04:00:00</th>\n",
       "      <td>51.088810</td>\n",
       "      <td>65.580620</td>\n",
       "      <td>57.685837</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 05:00:00</th>\n",
       "      <td>95.972000</td>\n",
       "      <td>121.111137</td>\n",
       "      <td>106.453598</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 06:00:00</th>\n",
       "      <td>214.874176</td>\n",
       "      <td>295.776123</td>\n",
       "      <td>251.114532</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 07:00:00</th>\n",
       "      <td>361.004181</td>\n",
       "      <td>478.299957</td>\n",
       "      <td>410.789032</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 08:00:00</th>\n",
       "      <td>408.001801</td>\n",
       "      <td>465.988342</td>\n",
       "      <td>430.336090</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 09:00:00</th>\n",
       "      <td>388.139740</td>\n",
       "      <td>471.577118</td>\n",
       "      <td>419.174744</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 10:00:00</th>\n",
       "      <td>388.657349</td>\n",
       "      <td>457.722168</td>\n",
       "      <td>416.137054</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 11:00:00</th>\n",
       "      <td>394.808105</td>\n",
       "      <td>450.991943</td>\n",
       "      <td>421.736542</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 12:00:00</th>\n",
       "      <td>508.777100</td>\n",
       "      <td>566.741516</td>\n",
       "      <td>534.735901</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 13:00:00</th>\n",
       "      <td>517.721069</td>\n",
       "      <td>598.235107</td>\n",
       "      <td>557.690125</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 14:00:00</th>\n",
       "      <td>580.189270</td>\n",
       "      <td>673.516052</td>\n",
       "      <td>630.302673</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 15:00:00</th>\n",
       "      <td>604.505188</td>\n",
       "      <td>700.743164</td>\n",
       "      <td>661.422668</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 16:00:00</th>\n",
       "      <td>758.910278</td>\n",
       "      <td>833.884399</td>\n",
       "      <td>795.726257</td>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 17:00:00</th>\n",
       "      <td>739.096863</td>\n",
       "      <td>844.749756</td>\n",
       "      <td>788.702942</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 18:00:00</th>\n",
       "      <td>638.894287</td>\n",
       "      <td>765.752625</td>\n",
       "      <td>703.856262</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 19:00:00</th>\n",
       "      <td>534.957214</td>\n",
       "      <td>650.045166</td>\n",
       "      <td>590.147522</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 20:00:00</th>\n",
       "      <td>673.310303</td>\n",
       "      <td>759.357910</td>\n",
       "      <td>725.795532</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:00:00</th>\n",
       "      <td>526.002197</td>\n",
       "      <td>614.086670</td>\n",
       "      <td>568.259766</td>\n",
       "      <td>901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 22:00:00</th>\n",
       "      <td>389.931152</td>\n",
       "      <td>457.252563</td>\n",
       "      <td>413.418854</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:00:00</th>\n",
       "      <td>247.327560</td>\n",
       "      <td>300.414856</td>\n",
       "      <td>273.066620</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>363.445648</td>\n",
       "      <td>396.971588</td>\n",
       "      <td>382.042084</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 01:00:00</th>\n",
       "      <td>206.080887</td>\n",
       "      <td>250.019379</td>\n",
       "      <td>228.404114</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 02:00:00</th>\n",
       "      <td>125.629654</td>\n",
       "      <td>163.194672</td>\n",
       "      <td>140.192780</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 03:00:00</th>\n",
       "      <td>84.509987</td>\n",
       "      <td>108.815651</td>\n",
       "      <td>96.510323</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0.1          0.9          0.5  count\n",
       "2019-11-01 00:00:00  212.151169   265.435028   241.570862    397\n",
       "2019-11-01 01:00:00  124.617722   171.000305   145.031357    320\n",
       "2019-11-01 02:00:00   80.706589   117.129768   101.627487    228\n",
       "2019-11-01 03:00:00   72.566772    97.084290    85.603622    173\n",
       "2019-11-01 04:00:00   98.508514   131.258377   114.383095    155\n",
       "2019-11-01 05:00:00  153.487030   186.792969   168.263992    110\n",
       "2019-11-01 06:00:00  334.848877   438.448975   384.286133    174\n",
       "2019-11-01 07:00:00  563.527161   669.975586   615.068115    372\n",
       "2019-11-01 08:00:00  655.870667   734.443359   685.650879    676\n",
       "2019-11-01 09:00:00  593.185181   675.854431   633.049072    712\n",
       "2019-11-01 10:00:00  546.174805   649.930481   608.360718    710\n",
       "2019-11-01 11:00:00  550.857788   622.386414   588.267212    626\n",
       "2019-11-01 12:00:00  507.769958   573.518677   534.737244    576\n",
       "2019-11-01 13:00:00  590.475769   691.678406   633.467346    548\n",
       "2019-11-01 14:00:00  693.076416   816.870117   748.113464    619\n",
       "2019-11-01 15:00:00  763.526672   880.894409   829.899658    758\n",
       "2019-11-01 16:00:00  898.578918  1030.268311   972.444885    888\n",
       "2019-11-01 17:00:00  884.743408  1023.133301   958.861206   1020\n",
       "2019-11-01 18:00:00  818.326294   956.415710   884.686401   1046\n",
       "2019-11-01 19:00:00  706.503662   832.738525   769.550232    958\n",
       "2019-11-01 20:00:00  741.083984   858.501709   795.321533    928\n",
       "2019-11-01 21:00:00  645.237305   760.188354   695.020081    904\n",
       "2019-11-01 22:00:00  602.483826   752.955017   663.901306    795\n",
       "2019-11-01 23:00:00  478.145905   589.286926   542.303345    666\n",
       "2019-11-02 00:00:00  408.892822   482.716125   435.279327    570\n",
       "2019-11-02 01:00:00  313.713440   379.960632   351.702209    469\n",
       "2019-11-02 02:00:00  230.462128   321.196228   273.053070    354\n",
       "2019-11-02 03:00:00  174.236008   245.430084   206.434677    277\n",
       "2019-11-02 04:00:00  100.757751   144.895813   114.460846    192\n",
       "2019-11-02 05:00:00   86.865906   124.313004   105.222527    110\n",
       "2019-11-02 06:00:00  166.591248   216.678085   193.810745    108\n",
       "2019-11-02 07:00:00  267.266479   341.752289   312.071411    193\n",
       "2019-11-02 08:00:00  394.480743   477.315582   444.336365    345\n",
       "2019-11-02 09:00:00  457.281403   551.453125   511.633148    482\n",
       "2019-11-02 10:00:00  530.850708   616.243896   580.063171    561\n",
       "2019-11-02 11:00:00  558.110168   663.672302   607.130981    563\n",
       "2019-11-02 12:00:00  547.548462   617.364319   580.791931    607\n",
       "2019-11-02 13:00:00  590.203064   697.570435   641.759705    707\n",
       "2019-11-02 14:00:00  650.398865   778.394592   711.513611    683\n",
       "2019-11-02 15:00:00  692.957642   835.818115   757.624023    761\n",
       "2019-11-02 16:00:00  833.570801   937.508484   870.561768    818\n",
       "2019-11-02 17:00:00  821.340332   925.030029   869.725403    805\n",
       "2019-11-02 18:00:00  787.757141   924.330261   856.678101    818\n",
       "2019-11-02 19:00:00  717.452942   836.199768   781.360840    860\n",
       "2019-11-02 20:00:00  708.614563   814.070068   755.186890    776\n",
       "2019-11-02 21:00:00  657.911438   781.517761   742.128662    754\n",
       "2019-11-02 22:00:00  640.446716   764.049622   708.591064    729\n",
       "2019-11-02 23:00:00  534.640747   652.010010   598.371338    744\n",
       "2019-11-03 00:00:00  469.679871   522.212097   494.708160    623\n",
       "2019-11-03 01:00:00  366.600067   439.302338   398.490204    821\n",
       "2019-11-03 02:00:00  280.029999   348.320435   305.244049    301\n",
       "2019-11-03 03:00:00  206.901184   260.846069   233.235596    262\n",
       "2019-11-03 04:00:00   83.720001   129.534988   108.139076    182\n",
       "2019-11-03 05:00:00   58.763992   115.180321    86.348465    118\n",
       "2019-11-03 06:00:00  122.418961   169.800049   142.571381    104\n",
       "2019-11-03 07:00:00  183.394272   256.729492   208.879776    153\n",
       "2019-11-03 08:00:00  319.129883   371.760986   351.146118    241\n",
       "2019-11-03 09:00:00  396.730835   464.542267   429.755859    335\n",
       "2019-11-03 10:00:00  458.333679   558.716431   516.946045    397\n",
       "2019-11-03 11:00:00  541.452087   626.103943   589.593689    442\n",
       "2019-11-03 12:00:00  434.587952   534.832153   473.315552    471\n",
       "2019-11-03 13:00:00  493.805084   589.574768   530.802979    505\n",
       "2019-11-03 14:00:00  537.532471   669.916687   589.283691    522\n",
       "2019-11-03 15:00:00  535.189575   661.083252   599.898071    594\n",
       "2019-11-03 16:00:00  557.234924   649.444580   589.072937    548\n",
       "2019-11-03 17:00:00  538.160339   640.778442   586.345276    539\n",
       "2019-11-03 18:00:00  528.790405   622.005432   561.862671    578\n",
       "2019-11-03 19:00:00  441.208771   537.989563   491.431580    578\n",
       "2019-11-03 20:00:00  418.342834   495.579773   460.463806    509\n",
       "2019-11-03 21:00:00  329.583862   417.679016   368.612518    465\n",
       "2019-11-03 22:00:00  281.123596   356.403473   307.804077    352\n",
       "2019-11-03 23:00:00  179.053497   245.611755   208.257462    248\n",
       "2019-11-04 00:00:00  104.897591   141.045822   127.497467    170\n",
       "2019-11-04 01:00:00   42.550190    83.516304    59.457638    127\n",
       "2019-11-04 02:00:00   39.986168    73.008492    54.659710     95\n",
       "2019-11-04 03:00:00   52.418156    80.028168    64.212364     65\n",
       "2019-11-04 04:00:00   67.633774   102.236618    89.398979     93\n",
       "2019-11-04 05:00:00  144.536011   193.651993   161.373459     85\n",
       "2019-11-04 06:00:00  307.106689   442.968475   377.248199    196\n",
       "2019-11-04 07:00:00  505.471466   687.522339   591.716614    469\n",
       "2019-11-04 08:00:00  629.330261   706.005249   669.411072    648\n",
       "2019-11-04 09:00:00  553.165039   642.921631   603.028259    670\n",
       "2019-11-04 10:00:00  534.608154   611.047791   569.143494    595\n",
       "2019-11-04 11:00:00  524.049500   592.215393   555.732483    608\n",
       "2019-11-04 12:00:00  514.754395   575.532776   545.493835    557\n",
       "2019-11-04 13:00:00  556.463806   641.497803   599.640259    530\n",
       "2019-11-04 14:00:00  618.048096   720.984314   670.913940    613\n",
       "2019-11-04 15:00:00  642.504944   769.530273   708.591736    735\n",
       "2019-11-04 16:00:00  796.927673   894.509460   837.782776    762\n",
       "2019-11-04 17:00:00  776.996582   908.238159   848.273560    833\n",
       "2019-11-04 18:00:00  708.485107   810.544739   766.801514    851\n",
       "2019-11-04 19:00:00  558.686584   654.514526   609.074646    781\n",
       "2019-11-04 20:00:00  457.181885   539.295715   496.521057    607\n",
       "2019-11-04 21:00:00  329.727203   450.412689   369.331879    503\n",
       "2019-11-04 22:00:00  259.671661   337.403564   295.137024    400\n",
       "2019-11-04 23:00:00  173.489700   218.762894   197.697357    295\n",
       "2019-11-05 00:00:00  108.979530   149.128189   137.404282    185\n",
       "2019-11-05 01:00:00   59.994556    90.051125    73.762138    114\n",
       "2019-11-05 02:00:00   45.241249    81.345375    64.898956     66\n",
       "2019-11-05 03:00:00   48.226395    73.105370    58.358112     57\n",
       "2019-11-05 04:00:00   58.689766    89.441925    71.687904     74\n",
       "2019-11-05 05:00:00  122.034019   169.612518   148.789978     78\n",
       "2019-11-05 06:00:00  283.883057   454.023529   362.460358    183\n",
       "2019-11-05 07:00:00  467.842224   677.171631   578.935059    416\n",
       "2019-11-05 08:00:00  517.682251   606.523499   567.640198    556\n",
       "2019-11-05 09:00:00  439.667847   594.560364   513.100342    598\n",
       "2019-11-05 10:00:00  452.616180   569.199463   497.151794    597\n",
       "2019-11-05 11:00:00  447.268188   542.818420   497.370850    565\n",
       "2019-11-05 12:00:00  494.067474   559.515564   525.105286    558\n",
       "2019-11-05 13:00:00  541.179688   640.637207   585.461731    589\n",
       "2019-11-05 14:00:00  614.883240   720.580078   661.853577    676\n",
       "2019-11-05 15:00:00  638.115540   781.339417   711.907959    675\n",
       "2019-11-05 16:00:00  781.289062   911.383057   821.457275    759\n",
       "2019-11-05 17:00:00  767.261963   877.763062   825.121887    786\n",
       "2019-11-05 18:00:00  704.924988   822.701355   778.994324    808\n",
       "2019-11-05 19:00:00  579.822388   705.210510   653.335083    691\n",
       "2019-11-05 20:00:00  480.613556   581.362244   536.001160    626\n",
       "2019-11-05 21:00:00  401.420532   503.094696   448.434265    519\n",
       "2019-11-05 22:00:00  320.104523   403.460968   351.242523    396\n",
       "2019-11-05 23:00:00  199.496109   249.488251   225.587173    295\n",
       "2019-11-06 00:00:00  120.031593   146.098389   131.185440    189\n",
       "2019-11-06 01:00:00   58.011932    98.257179    76.553833    113\n",
       "2019-11-06 02:00:00   51.237808    81.880455    66.909622     68\n",
       "2019-11-06 03:00:00   53.616142    78.925842    66.148415     50\n",
       "2019-11-06 04:00:00   55.049976    78.230728    69.545937     47\n",
       "2019-11-06 05:00:00  146.967224   187.262360   165.158997     86\n",
       "2019-11-06 06:00:00  357.051361   422.437134   388.167328    176\n",
       "2019-11-06 07:00:00  546.798523   653.593628   601.051025    473\n",
       "2019-11-06 08:00:00  677.068542   740.314087   696.623230    648\n",
       "2019-11-06 09:00:00  597.453003   665.578186   628.451050    681\n",
       "2019-11-06 10:00:00  558.205811   670.933350   600.798645    630\n",
       "2019-11-06 11:00:00  563.632935   655.452271   606.896240    584\n",
       "2019-11-06 12:00:00  546.450073   605.394165   579.993408    594\n",
       "2019-11-06 13:00:00  607.052185   686.951599   643.829651    632\n",
       "2019-11-06 14:00:00  676.973572   772.525330   712.500000    625\n",
       "2019-11-06 15:00:00  710.632812   844.251160   763.569214    719\n",
       "2019-11-06 16:00:00  832.351379   929.862183   865.121521    803\n",
       "2019-11-06 17:00:00  805.690308   901.933105   854.013489    846\n",
       "2019-11-06 18:00:00  685.079102   832.651001   773.900879    894\n",
       "2019-11-06 19:00:00  614.313660   751.472412   667.147522    820\n",
       "2019-11-06 20:00:00  510.294617   602.173645   564.842102    656\n",
       "2019-11-06 21:00:00  416.878815   508.102173   460.133698    600\n",
       "2019-11-06 22:00:00  332.888855   407.371674   366.571869    484\n",
       "2019-11-06 23:00:00  209.562500   281.781647   247.874451    377\n",
       "2019-11-07 00:00:00  154.536621   198.352615   178.672531    251\n",
       "2019-11-07 01:00:00   85.836197   126.214890   107.461296    134\n",
       "2019-11-07 02:00:00   71.176331   105.507431    84.500954    100\n",
       "2019-11-07 03:00:00   67.799973    91.843002    80.639732     57\n",
       "2019-11-07 04:00:00   65.261620    96.153046    73.442726     66\n",
       "2019-11-07 05:00:00  148.667099   196.631104   166.629425     74\n",
       "2019-11-07 06:00:00  346.158478   456.121307   415.816681    188\n",
       "2019-11-07 07:00:00  580.023376   671.577148   637.341736    434\n",
       "2019-11-07 08:00:00  625.740784   707.583069   660.976196    644\n",
       "2019-11-07 09:00:00  590.964355   666.621338   638.090210    688\n",
       "2019-11-07 10:00:00  551.853516   651.369507   603.440979    659\n",
       "2019-11-07 11:00:00  550.025635   638.355591   590.331116    637\n",
       "2019-11-07 12:00:00  531.618225   596.649658   566.733276    586\n",
       "2019-11-07 13:00:00  592.300049   676.227234   628.538147    692\n",
       "2019-11-07 14:00:00  655.613159   778.002197   708.070190    660\n",
       "2019-11-07 15:00:00  729.469666   858.990967   790.451172    792\n",
       "2019-11-07 16:00:00  848.008850   958.843933   908.770752    835\n",
       "2019-11-07 17:00:00  828.153809   955.943542   890.027466    976\n",
       "2019-11-07 18:00:00  759.265442   912.148438   841.728577   1099\n",
       "2019-11-07 19:00:00  633.085083   762.429932   696.952942    941\n",
       "2019-11-07 20:00:00  615.296204   755.263367   685.636169    788\n",
       "2019-11-07 21:00:00  513.299866   619.183411   552.914246    680\n",
       "2019-11-07 22:00:00  401.491943   528.994873   455.643738    569\n",
       "2019-11-07 23:00:00  286.002106   379.272400   316.988434    419\n",
       "2019-11-08 00:00:00  216.311035   265.578247   240.572296    348\n",
       "2019-11-08 01:00:00  125.647949   178.717133   151.827621    214\n",
       "2019-11-08 02:00:00   91.302414   150.843582   125.870430    118\n",
       "2019-11-08 03:00:00   80.746521   122.041779   101.483696     84\n",
       "2019-11-08 04:00:00   72.219185    99.779999    84.560417     85\n",
       "2019-11-08 05:00:00  140.748047   188.298416   164.161041     72\n",
       "2019-11-08 06:00:00  346.441010   450.229736   390.335297    167\n",
       "2019-11-08 07:00:00  541.184937   689.708252   620.493835    440\n",
       "2019-11-08 08:00:00  685.413147   767.049927   728.522888    726\n",
       "2019-11-08 09:00:00  606.388123   740.309509   670.823303    713\n",
       "2019-11-08 10:00:00  565.399475   664.160095   609.643799    669\n",
       "2019-11-08 11:00:00  522.497437   635.116516   565.146973    587\n",
       "2019-11-08 12:00:00  527.740417   598.593994   566.652466    565\n",
       "2019-11-08 13:00:00  591.035767   690.077881   638.404114    582\n",
       "2019-11-08 14:00:00  680.250977   802.069336   748.117981    656\n",
       "2019-11-08 15:00:00  781.884460   892.557251   836.887817    826\n",
       "2019-11-08 16:00:00  954.487000  1056.618652   999.263489    944\n",
       "2019-11-08 17:00:00  944.237732  1102.287842  1027.949829    997\n",
       "2019-11-08 18:00:00  829.673096  1033.464111   922.947754   1055\n",
       "2019-11-08 19:00:00  727.593079   922.356750   821.852966    964\n",
       "2019-11-08 20:00:00  724.739136   864.636658   794.931152    883\n",
       "2019-11-08 21:00:00  640.078979   780.604187   706.869934    830\n",
       "2019-11-08 22:00:00  559.934326   696.958008   651.765747    720\n",
       "2019-11-08 23:00:00  474.933441   569.112488   530.630981    736\n",
       "2019-11-09 00:00:00  472.708466   538.798950   507.038513    627\n",
       "2019-11-09 01:00:00  325.890076   409.356720   362.316010    418\n",
       "2019-11-09 02:00:00  225.057129   288.190033   262.066803    310\n",
       "2019-11-09 03:00:00  169.345169   233.352875   199.389526    230\n",
       "2019-11-09 04:00:00   82.911011   122.478500   102.418190    178\n",
       "2019-11-09 05:00:00   91.324623   130.142319   103.620216     93\n",
       "2019-11-09 06:00:00  155.198181   211.265564   191.414825    124\n",
       "2019-11-09 07:00:00  276.863037   362.651917   311.501495    200\n",
       "2019-11-09 08:00:00  406.641052   481.822205   441.901978    347\n",
       "2019-11-09 09:00:00  449.298859   539.086670   518.014038    510\n",
       "2019-11-09 10:00:00  502.651672   595.182922   550.196411    564\n",
       "2019-11-09 11:00:00  539.595337   641.658691   584.984619    580\n",
       "2019-11-09 12:00:00  554.368408   665.646179   619.336060    610\n",
       "2019-11-09 13:00:00  593.122192   685.328491   648.962769    724\n",
       "2019-11-09 14:00:00  681.046814   781.319153   737.911926    710\n",
       "2019-11-09 15:00:00  722.749268   822.251099   772.750854    817\n",
       "2019-11-09 16:00:00  813.462585   916.153320   864.611938    818\n",
       "2019-11-09 17:00:00  794.333069   913.083984   856.340637    904\n",
       "2019-11-09 18:00:00  774.540527   898.513550   850.328064    877\n",
       "2019-11-09 19:00:00  704.035706   843.543762   778.419067    832\n",
       "2019-11-09 20:00:00  682.676819   795.357666   737.287231    740\n",
       "2019-11-09 21:00:00  647.068542   755.810059   700.130432    723\n",
       "2019-11-09 22:00:00  607.219604   744.663513   679.067810    722\n",
       "2019-11-09 23:00:00  549.046753   661.324524   595.794556    706\n",
       "2019-11-10 00:00:00  472.163025   541.086487   500.898712    573\n",
       "2019-11-10 01:00:00  329.601776   396.785645   366.160950    412\n",
       "2019-11-10 02:00:00  252.260056   312.343018   283.109009    331\n",
       "2019-11-10 03:00:00  186.352310   241.111099   214.908035    274\n",
       "2019-11-10 04:00:00   90.110725   126.257774   109.557350    191\n",
       "2019-11-10 05:00:00   72.234131   105.504532    85.594711    104\n",
       "2019-11-10 06:00:00  131.988098   176.546295   159.610718     92\n",
       "2019-11-10 07:00:00  218.160950   278.169861   247.190491    134\n",
       "2019-11-10 08:00:00  302.984497   370.279541   329.934235    227\n",
       "2019-11-10 09:00:00  370.293457   460.314301   419.945862    349\n",
       "2019-11-10 10:00:00  456.932159   529.503296   496.747681    461\n",
       "2019-11-10 11:00:00  494.625824   605.215210   541.106384    547\n",
       "2019-11-10 12:00:00  542.617737   612.394470   572.842163    559\n",
       "2019-11-10 13:00:00  546.836609   631.236816   587.873657    527\n",
       "2019-11-10 14:00:00  586.843567   688.770081   636.194214    663\n",
       "2019-11-10 15:00:00  594.695312   663.920654   627.134216    674\n",
       "2019-11-10 16:00:00  647.064453   715.802368   674.659729    666\n",
       "2019-11-10 17:00:00  624.477661   725.753662   672.417725    660\n",
       "2019-11-10 18:00:00  565.092529   663.934875   608.751221    650\n",
       "2019-11-10 19:00:00  486.441345   577.528442   537.940918    597\n",
       "2019-11-10 20:00:00  441.562286   531.713867   486.197998    563\n",
       "2019-11-10 21:00:00  330.798645   436.581543   389.749725    431\n",
       "2019-11-10 22:00:00  256.957550   347.151581   306.080933    378\n",
       "2019-11-10 23:00:00  156.929611   225.900726   186.497772    310\n",
       "2019-11-11 00:00:00   98.868301   141.759506   119.272026    211\n",
       "2019-11-11 01:00:00   69.057045    98.020447    85.814384    162\n",
       "2019-11-11 02:00:00   56.073143    89.553551    73.738991    101\n",
       "2019-11-11 03:00:00   67.731056    94.442680    79.609016     86\n",
       "2019-11-11 04:00:00   64.172104    90.432983    78.413132     69\n",
       "2019-11-11 05:00:00  145.597275   194.443130   167.357254     50\n",
       "2019-11-11 06:00:00  350.462402   443.151123   397.169495    169\n",
       "2019-11-11 07:00:00  532.997009   665.842102   590.862610    280\n",
       "2019-11-11 08:00:00  502.730286   589.255493   543.144043    454\n",
       "2019-11-11 09:00:00  501.687317   565.274597   526.506531    574\n",
       "2019-11-11 10:00:00  477.691986   555.596191   519.750244    510\n",
       "2019-11-11 11:00:00  486.958923   552.466125   520.641174    531\n",
       "2019-11-11 12:00:00  513.621094   566.088257   539.088074    529\n",
       "2019-11-11 13:00:00  564.873535   641.765564   602.929626    564\n",
       "2019-11-11 14:00:00  631.119324   728.172424   679.637634    633\n",
       "2019-11-11 15:00:00  662.249390   768.316895   709.871521    646\n",
       "2019-11-11 16:00:00  689.765625   784.072876   740.893066    657\n",
       "2019-11-11 17:00:00  703.969971   814.275085   757.804260    749\n",
       "2019-11-11 18:00:00  616.069397   780.550598   684.234497    705\n",
       "2019-11-11 19:00:00  502.926910   633.561340   574.293274    642\n",
       "2019-11-11 20:00:00  412.217316   468.016693   434.893066    478\n",
       "2019-11-11 21:00:00  313.454468   393.833618   353.484375    444\n",
       "2019-11-11 22:00:00  253.086960   311.782227   284.046387    328\n",
       "2019-11-11 23:00:00  163.677246   222.381256   187.368637    261\n",
       "2019-11-12 00:00:00   92.997696   121.225052   105.589607    178\n",
       "2019-11-12 01:00:00   55.013069    80.672028    68.910080    123\n",
       "2019-11-12 02:00:00   44.510807    71.778755    58.205940     72\n",
       "2019-11-12 03:00:00   50.509586    67.464462    56.910385     37\n",
       "2019-11-12 04:00:00   51.212807    80.510567    65.784660     60\n",
       "2019-11-12 05:00:00  120.214867   185.925400   154.281494     71\n",
       "2019-11-12 06:00:00  298.990204   451.302734   356.705658    175\n",
       "2019-11-12 07:00:00  472.283447   655.076904   550.988586    485\n",
       "2019-11-12 08:00:00  625.706787   712.308472   669.471191    664\n",
       "2019-11-12 09:00:00  557.222107   646.499573   603.588562    746\n",
       "2019-11-12 10:00:00  530.656311   606.561768   572.209473    702\n",
       "2019-11-12 11:00:00  509.791046   615.314941   552.793518    638\n",
       "2019-11-12 12:00:00  537.059265   597.193176   568.340759    569\n",
       "2019-11-12 13:00:00  581.884521   674.031433   622.044067    620\n",
       "2019-11-12 14:00:00  652.532898   760.202454   693.924500    678\n",
       "2019-11-12 15:00:00  701.014648   808.185730   741.425781    700\n",
       "2019-11-12 16:00:00  805.074097   926.988525   863.221985    829\n",
       "2019-11-12 17:00:00  757.110718   903.366028   824.181335    850\n",
       "2019-11-12 18:00:00  677.882141   791.606079   746.876099    987\n",
       "2019-11-12 19:00:00  575.325928   692.378296   635.688599    865\n",
       "2019-11-12 20:00:00  550.372253   646.367493   590.811584    791\n",
       "2019-11-12 21:00:00  422.111053   511.087799   456.586609    594\n",
       "2019-11-12 22:00:00  315.982666   379.714294   344.751007    508\n",
       "2019-11-12 23:00:00  193.745560   246.658310   216.899887    377\n",
       "2019-11-13 00:00:00  127.678139   163.216888   145.436203    257\n",
       "2019-11-13 01:00:00   74.433022   104.926094    88.219749    125\n",
       "2019-11-13 02:00:00   50.371597    77.954056    63.215240     90\n",
       "2019-11-13 03:00:00   47.115952    74.686996    58.403812     80\n",
       "2019-11-13 04:00:00   59.012058    81.569733    69.999168     59\n",
       "2019-11-13 05:00:00  142.382431   184.495728   164.100021     54\n",
       "2019-11-13 06:00:00  359.465240   445.897278   392.824005    179\n",
       "2019-11-13 07:00:00  562.465332   650.278625   605.039856    443\n",
       "2019-11-13 08:00:00  664.981384   739.423340   707.561768    657\n",
       "2019-11-13 09:00:00  600.001526   670.844543   632.665344    641\n",
       "2019-11-13 10:00:00  552.037842   665.454163   612.575012    615\n",
       "2019-11-13 11:00:00  540.401062   640.866699   587.055359    575\n",
       "2019-11-13 12:00:00  552.965393   645.652588   601.896301    604\n",
       "2019-11-13 13:00:00  604.983521   691.587524   647.518799    629\n",
       "2019-11-13 14:00:00  643.346924   765.916199   718.642212    688\n",
       "2019-11-13 15:00:00  694.054382   825.515320   764.467285    741\n",
       "2019-11-13 16:00:00  798.205261   954.942505   869.037659    788\n",
       "2019-11-13 17:00:00  833.882080   979.820312   890.515503    854\n",
       "2019-11-13 18:00:00  743.527100   919.586426   812.757202    882\n",
       "2019-11-13 19:00:00  630.419617   763.779419   684.730042    836\n",
       "2019-11-13 20:00:00  542.754578   647.749695   606.519958    720\n",
       "2019-11-13 21:00:00  460.097412   550.009338   509.743683    632\n",
       "2019-11-13 22:00:00  336.638092   434.125244   387.591858    520\n",
       "2019-11-13 23:00:00  219.857635   285.535065   260.881409    389\n",
       "2019-11-14 00:00:00  130.310181   165.668411   144.483322    243\n",
       "2019-11-14 01:00:00   72.023186   113.809998    94.985321    143\n",
       "2019-11-14 02:00:00   49.612030    82.024452    66.154922     88\n",
       "2019-11-14 03:00:00   46.524910    81.880669    60.514610     64\n",
       "2019-11-14 04:00:00   57.040627    82.259880    69.102821     51\n",
       "2019-11-14 05:00:00  157.385361   193.012695   176.948685     79\n",
       "2019-11-14 06:00:00  383.475311   456.195160   420.891174    149\n",
       "2019-11-14 07:00:00  600.530762   689.361633   641.130737    436\n",
       "2019-11-14 08:00:00  665.016296   743.239258   712.009583    668\n",
       "2019-11-14 09:00:00  611.017883   704.338989   653.070251    691\n",
       "2019-11-14 10:00:00  572.902649   682.917114   626.562073    582\n",
       "2019-11-14 11:00:00  546.969971   678.589478   620.037964    619\n",
       "2019-11-14 12:00:00  596.245483   678.811035   634.298706    645\n",
       "2019-11-14 13:00:00  638.752563   713.090088   680.392212    652\n",
       "2019-11-14 14:00:00  701.680176   803.443115   747.501465    710\n",
       "2019-11-14 15:00:00  767.198486   892.097656   831.141113    766\n",
       "2019-11-14 16:00:00  826.754028   934.964844   881.136230    834\n",
       "2019-11-14 17:00:00  826.583008  1014.542236   932.579041    908\n",
       "2019-11-14 18:00:00  760.097900   916.594543   860.503967   1025\n",
       "2019-11-14 19:00:00  680.189941   792.296631   741.832581    942\n",
       "2019-11-14 20:00:00  605.156738   709.878113   643.846252    745\n",
       "2019-11-14 21:00:00  488.508972   627.792053   539.246460    675\n",
       "2019-11-14 22:00:00  383.711975   507.046906   447.236572    531\n",
       "2019-11-14 23:00:00  280.653961   367.943665   323.708710    460\n",
       "2019-11-15 00:00:00  157.857147   215.625381   191.810867    299\n",
       "2019-11-15 01:00:00   97.114685   150.968826   125.746796    214\n",
       "2019-11-15 02:00:00   70.796295   116.234482    92.882469    113\n",
       "2019-11-15 03:00:00   69.083099    98.680397    83.712082     93\n",
       "2019-11-15 04:00:00   59.883839    90.025452    74.485519     80\n",
       "2019-11-15 05:00:00  150.790619   193.561172   168.423172     62\n",
       "2019-11-15 06:00:00  370.706360   451.938171   398.718964    190\n",
       "2019-11-15 07:00:00  583.132568   664.897705   619.178284    444\n",
       "2019-11-15 08:00:00  636.968750   735.667480   682.452515    637\n",
       "2019-11-15 09:00:00  583.406860   684.837952   630.868652    672\n",
       "2019-11-15 10:00:00  547.098083   632.901733   585.331360    646\n",
       "2019-11-15 11:00:00  500.434570   596.432251   555.796082    580\n",
       "2019-11-15 12:00:00  509.675140   572.860535   550.030762    513\n",
       "2019-11-15 13:00:00  574.954651   670.782715   615.967529    509\n",
       "2019-11-15 14:00:00  664.219238   774.336548   732.848145    661\n",
       "2019-11-15 15:00:00  742.513123   875.042786   802.982666    796\n",
       "2019-11-15 16:00:00  906.130676  1015.041992   947.623413    884\n",
       "2019-11-15 17:00:00  912.188477  1035.558228   967.317139    999\n",
       "2019-11-15 18:00:00  773.162354   942.331909   875.274902   1020\n",
       "2019-11-15 19:00:00  705.770630   860.500000   791.481995    975\n",
       "2019-11-15 20:00:00  708.868958   829.030762   795.346130    881\n",
       "2019-11-15 21:00:00  642.337585   753.226501   698.943420    807\n",
       "2019-11-15 22:00:00  601.446350   719.828247   665.463745    724\n",
       "2019-11-15 23:00:00  490.471954   617.198730   542.746887    696\n",
       "2019-11-16 00:00:00  426.521637   505.080658   452.747192    607\n",
       "2019-11-16 01:00:00  299.614075   365.197784   336.737671    444\n",
       "2019-11-16 02:00:00  222.902817   290.945435   262.126648    339\n",
       "2019-11-16 03:00:00  164.342972   217.796661   193.819611    258\n",
       "2019-11-16 04:00:00   96.093185   134.544739   114.373779    210\n",
       "2019-11-16 05:00:00  103.792213   148.075287   121.661423     84\n",
       "2019-11-16 06:00:00  185.082428   233.767242   209.132187    116\n",
       "2019-11-16 07:00:00  277.166687   350.629517   311.882812    184\n",
       "2019-11-16 08:00:00  411.263397   470.733826   450.512817    323\n",
       "2019-11-16 09:00:00  468.384094   554.779297   507.166992    396\n",
       "2019-11-16 10:00:00  473.830475   616.650391   540.708679    568\n",
       "2019-11-16 11:00:00  511.302979   625.882996   551.622742    601\n",
       "2019-11-16 12:00:00  572.206787   663.882202   618.897949    589\n",
       "2019-11-16 13:00:00  624.700256   720.819946   678.494385    636\n",
       "2019-11-16 14:00:00  665.879822   809.910400   729.595337    684\n",
       "2019-11-16 15:00:00  732.552551   859.530090   783.139343    818\n",
       "2019-11-16 16:00:00  832.455444   934.107056   873.149902    831\n",
       "2019-11-16 17:00:00  831.791931   935.273865   871.964111    860\n",
       "2019-11-16 18:00:00  790.175293   932.517456   866.154968    862\n",
       "2019-11-16 19:00:00  710.069763   843.748108   793.813049    843\n",
       "2019-11-16 20:00:00  699.477234   803.047913   756.997559    815\n",
       "2019-11-16 21:00:00  678.414062   779.792419   733.048706    792\n",
       "2019-11-16 22:00:00  639.285950   765.783020   693.330566    779\n",
       "2019-11-16 23:00:00  553.411133   639.964661   598.062256    689\n",
       "2019-11-17 00:00:00  454.387604   509.243195   481.773895    540\n",
       "2019-11-17 01:00:00  317.227142   373.606201   337.391418    461\n",
       "2019-11-17 02:00:00  257.525238   309.290192   284.483704    365\n",
       "2019-11-17 03:00:00  187.868713   230.130280   212.144638    318\n",
       "2019-11-17 04:00:00  102.910812   137.835892   121.004227    232\n",
       "2019-11-17 05:00:00   64.931946   105.024109    86.708420    109\n",
       "2019-11-17 06:00:00  126.597168   165.024475   143.089386     85\n",
       "2019-11-17 07:00:00  188.380051   233.311966   211.395401    137\n",
       "2019-11-17 08:00:00  298.686157   341.757477   316.368439    227\n",
       "2019-11-17 09:00:00  378.337524   452.041595   411.653198    336\n",
       "2019-11-17 10:00:00  444.136810   544.290039   497.480774    432\n",
       "2019-11-17 11:00:00  492.014008   576.518555   536.234497    536\n",
       "2019-11-17 12:00:00  504.211853   592.019104   549.141602    543\n",
       "2019-11-17 13:00:00  557.244385   655.817139   613.673218    625\n",
       "2019-11-17 14:00:00  584.856384   699.270874   643.837097    649\n",
       "2019-11-17 15:00:00  571.307922   689.639282   633.010864    681\n",
       "2019-11-17 16:00:00  638.705200   719.445068   681.265564    707\n",
       "2019-11-17 17:00:00  611.494263   722.499817   655.048096    660\n",
       "2019-11-17 18:00:00  538.364258   666.686401   609.277283    612\n",
       "2019-11-17 19:00:00  476.688904   579.612793   531.010620    550\n",
       "2019-11-17 20:00:00  413.410156   510.624359   461.364471    552\n",
       "2019-11-17 21:00:00  326.086975   407.307617   374.282074    481\n",
       "2019-11-17 22:00:00  269.497894   337.588562   295.700714    337\n",
       "2019-11-17 23:00:00  167.542053   222.602707   190.866226    302\n",
       "2019-11-18 00:00:00  112.281212   145.291641   130.520493    186\n",
       "2019-11-18 01:00:00   79.664871   111.313797    95.746857    110\n",
       "2019-11-18 02:00:00   70.011192    97.400299    82.663750     70\n",
       "2019-11-18 03:00:00   68.744553    88.463638    76.626465     57\n",
       "2019-11-18 04:00:00   57.914291    79.318764    69.557709     75\n",
       "2019-11-18 05:00:00  132.601715   190.234283   160.508774     80\n",
       "2019-11-18 06:00:00  330.341919   451.195160   385.567810    189\n",
       "2019-11-18 07:00:00  510.342804   660.863037   589.871704    449\n",
       "2019-11-18 08:00:00  649.801086   739.118042   682.301697    688\n",
       "2019-11-18 09:00:00  596.811035   667.443115   634.144958    678\n",
       "2019-11-18 10:00:00  567.804077   635.269043   603.513672    572\n",
       "2019-11-18 11:00:00  536.453003   609.592041   569.277893    593\n",
       "2019-11-18 12:00:00  549.714783   621.237183   583.025940    584\n",
       "2019-11-18 13:00:00  610.913635   699.868774   644.330261    600\n",
       "2019-11-18 14:00:00  648.339783   766.585938   706.716614    687\n",
       "2019-11-18 15:00:00  676.807617   792.781799   748.426819    716\n",
       "2019-11-18 16:00:00  710.478149   808.829834   751.438599    663\n",
       "2019-11-18 17:00:00  686.794617   815.898132   760.970215    863\n",
       "2019-11-18 18:00:00  648.511963   745.936157   695.302795    854\n",
       "2019-11-18 19:00:00  538.808289   632.938293   587.019226    873\n",
       "2019-11-18 20:00:00  518.977722   626.348877   563.536865    715\n",
       "2019-11-18 21:00:00  386.875275   471.995514   428.357910    575\n",
       "2019-11-18 22:00:00  287.591248   376.628265   322.035492    405\n",
       "2019-11-18 23:00:00  182.161179   241.539459   201.269989    286\n",
       "2019-11-19 00:00:00  110.426590   151.429291   126.437698    224\n",
       "2019-11-19 01:00:00   68.504028    99.955765    82.232506    112\n",
       "2019-11-19 02:00:00   53.972496    84.896835    64.288849     73\n",
       "2019-11-19 03:00:00   50.848763    73.292473    64.727219     40\n",
       "2019-11-19 04:00:00   46.975395    70.409256    60.882046     45\n",
       "2019-11-19 05:00:00  129.871490   193.354294   164.304413     61\n",
       "2019-11-19 06:00:00  360.350983   476.450012   424.289276    148\n",
       "2019-11-19 07:00:00  523.748779   682.397522   612.596619    432\n",
       "2019-11-19 08:00:00  604.976562   685.714844   645.196411    654\n",
       "2019-11-19 09:00:00  565.604431   655.461182   608.251892    679\n",
       "2019-11-19 10:00:00  535.591431   636.132629   597.789490    597\n",
       "2019-11-19 11:00:00  525.749817   610.850159   563.263306    564\n",
       "2019-11-19 12:00:00  531.508362   589.415222   564.949341    569\n",
       "2019-11-19 13:00:00  594.492676   678.468262   639.930603    586\n",
       "2019-11-19 14:00:00  661.619263   749.077087   693.953247    610\n",
       "2019-11-19 15:00:00  706.041077   824.545471   749.347595    663\n",
       "2019-11-19 16:00:00  798.786621   905.143799   842.283447    778\n",
       "2019-11-19 17:00:00  787.253906   914.925232   848.521545    818\n",
       "2019-11-19 18:00:00  707.693237   846.089233   797.088379    814\n",
       "2019-11-19 19:00:00  624.398987   737.184937   700.679260    802\n",
       "2019-11-19 20:00:00  520.391357   617.737732   563.439026    648\n",
       "2019-11-19 21:00:00  398.245270   502.409302   443.915588    538\n",
       "2019-11-19 22:00:00  307.989868   382.626282   343.061127    456\n",
       "2019-11-19 23:00:00  194.475906   242.037628   219.869736    369\n",
       "2019-11-20 00:00:00  131.127563   166.989838   148.580551    275\n",
       "2019-11-20 01:00:00   68.895241   102.957901    88.702950    178\n",
       "2019-11-20 02:00:00   55.415977    79.418182    67.537598     91\n",
       "2019-11-20 03:00:00   48.995090    72.402496    59.445457     68\n",
       "2019-11-20 04:00:00   55.530949    76.064819    67.129555     55\n",
       "2019-11-20 05:00:00  156.585373   186.195312   169.248306     60\n",
       "2019-11-20 06:00:00  378.287048   437.810272   408.951538    156\n",
       "2019-11-20 07:00:00  609.318054   678.881653   637.242432    416\n",
       "2019-11-20 08:00:00  638.136108   709.254639   666.178589    655\n",
       "2019-11-20 09:00:00  570.856689   660.452576   616.909119    731\n",
       "2019-11-20 10:00:00  567.313904   631.683105   592.989014    580\n",
       "2019-11-20 11:00:00  541.593628   646.835693   594.951355    609\n",
       "2019-11-20 12:00:00  557.188232   625.802734   599.724060    549\n",
       "2019-11-20 13:00:00  601.852783   695.171265   636.329102    640\n",
       "2019-11-20 14:00:00  671.096497   770.412170   714.347473    671\n",
       "2019-11-20 15:00:00  737.260132   846.901245   791.043945    770\n",
       "2019-11-20 16:00:00  808.965149   888.931946   846.600830    755\n",
       "2019-11-20 17:00:00  811.322205   927.212646   858.196167    884\n",
       "2019-11-20 18:00:00  716.444763   868.762451   806.518372    870\n",
       "2019-11-20 19:00:00  620.887146   749.929138   687.845520    923\n",
       "2019-11-20 20:00:00  612.935547   738.387695   657.797607    795\n",
       "2019-11-20 21:00:00  483.737885   584.921875   535.219360    619\n",
       "2019-11-20 22:00:00  358.007599   463.413513   409.647888    496\n",
       "2019-11-20 23:00:00  240.340881   308.140442   271.249695    416\n",
       "2019-11-21 00:00:00  145.766586   193.303101   163.900742    264\n",
       "2019-11-21 01:00:00   86.773560   121.033112   103.646523    170\n",
       "2019-11-21 02:00:00   63.563557    87.660103    72.427376     86\n",
       "2019-11-21 03:00:00   56.354462    79.380539    68.421402     85\n",
       "2019-11-21 04:00:00   56.676003    83.367607    70.486702     68\n",
       "2019-11-21 05:00:00  155.287109   185.630783   168.857910     62\n",
       "2019-11-21 06:00:00  385.746735   457.697968   422.707031    170\n",
       "2019-11-21 07:00:00  606.175354   711.371277   652.471069    415\n",
       "2019-11-21 08:00:00  657.260071   731.021973   685.524109    677\n",
       "2019-11-21 09:00:00  585.758972   674.330444   630.065063    676\n",
       "2019-11-21 10:00:00  566.792664   651.230591   606.014709    631\n",
       "2019-11-21 11:00:00  550.820190   627.223389   589.945129    656\n",
       "2019-11-21 12:00:00  604.445618   667.948914   636.034668    633\n",
       "2019-11-21 13:00:00  643.609924   724.495178   675.631348    635\n",
       "2019-11-21 14:00:00  721.349976   804.291138   758.392822    690\n",
       "2019-11-21 15:00:00  763.210938   866.914307   805.694519    761\n",
       "2019-11-21 16:00:00  870.339783   961.377197   909.817810    823\n",
       "2019-11-21 17:00:00  823.449890   990.989868   910.317871    912\n",
       "2019-11-21 18:00:00  780.369995   943.137634   877.593750    860\n",
       "2019-11-21 19:00:00  674.775024   804.879944   730.710449    858\n",
       "2019-11-21 20:00:00  587.509949   692.333618   639.141418    749\n",
       "2019-11-21 21:00:00  470.061340   578.008301   533.997742    699\n",
       "2019-11-21 22:00:00  405.714661   494.944183   451.549225    560\n",
       "2019-11-21 23:00:00  295.985291   364.951691   315.420868    420\n",
       "2019-11-22 00:00:00  220.009399   256.195099   232.972214    345\n",
       "2019-11-22 01:00:00  135.737656   174.115829   156.369904    190\n",
       "2019-11-22 02:00:00  100.321609   142.613586   115.786026    124\n",
       "2019-11-22 03:00:00   79.869514   112.332222    99.429764     87\n",
       "2019-11-22 04:00:00   54.676895    85.738495    71.682671     71\n",
       "2019-11-22 05:00:00  152.936447   190.833725   165.341187     71\n",
       "2019-11-22 06:00:00  350.228973   435.288513   394.114532    185\n",
       "2019-11-22 07:00:00  583.196716   688.140869   631.182861    460\n",
       "2019-11-22 08:00:00  640.196472   716.322327   675.425964    660\n",
       "2019-11-22 09:00:00  567.881775   665.379333   614.304077    725\n",
       "2019-11-22 10:00:00  544.551636   656.852661   576.812256    687\n",
       "2019-11-22 11:00:00  500.404755   585.007080   540.063721    641\n",
       "2019-11-22 12:00:00  563.920532   642.464050   601.761414    613\n",
       "2019-11-22 13:00:00  627.982910   731.190186   674.915588    620\n",
       "2019-11-22 14:00:00  739.152649   851.722229   790.049377    636\n",
       "2019-11-22 15:00:00  811.806519   932.414062   875.377686    769\n",
       "2019-11-22 16:00:00  877.071228   992.965820   934.060303    848\n",
       "2019-11-22 17:00:00  863.430420  1023.212463   944.624084   1005\n",
       "2019-11-22 18:00:00  843.328491  1010.029114   905.899963   1099\n",
       "2019-11-22 19:00:00  763.513123   909.813354   825.429016   1028\n",
       "2019-11-22 20:00:00  749.755615   843.647583   796.971375    865\n",
       "2019-11-22 21:00:00  610.669739   764.434082   698.379761    784\n",
       "2019-11-22 22:00:00  588.844116   725.149048   652.940491    739\n",
       "2019-11-22 23:00:00  484.914429   594.270996   544.455078    665\n",
       "2019-11-23 00:00:00  381.635498   455.075745   425.778168    544\n",
       "2019-11-23 01:00:00  302.625458   361.940704   329.158173    419\n",
       "2019-11-23 02:00:00  239.850937   299.721191   264.626953    330\n",
       "2019-11-23 03:00:00  172.216949   227.718491   191.648804    231\n",
       "2019-11-23 04:00:00   85.721771   129.768921   111.778168    203\n",
       "2019-11-23 05:00:00   90.068893   131.841919   110.070625    102\n",
       "2019-11-23 06:00:00  169.011078   214.696533   189.685760    119\n",
       "2019-11-23 07:00:00  282.025696   347.401306   310.489441    197\n",
       "2019-11-23 08:00:00  363.988739   447.275757   409.794312    288\n",
       "2019-11-23 09:00:00  439.243988   530.112000   483.091125    433\n",
       "2019-11-23 10:00:00  483.932343   588.460449   537.843994    525\n",
       "2019-11-23 11:00:00  510.336456   617.759338   561.084717    557\n",
       "2019-11-23 12:00:00  608.067322   691.558838   659.118286    628\n",
       "2019-11-23 13:00:00  605.931213   721.008728   677.076355    676\n",
       "2019-11-23 14:00:00  690.671143   796.933655   742.841980    705\n",
       "2019-11-23 15:00:00  728.555603   823.986755   775.218628    845\n",
       "2019-11-23 16:00:00  811.094910   920.398560   878.226868    804\n",
       "2019-11-23 17:00:00  804.212708   924.250732   851.433777    823\n",
       "2019-11-23 18:00:00  767.333557   908.759644   829.771118    850\n",
       "2019-11-23 19:00:00  707.001892   814.777161   769.911011    787\n",
       "2019-11-23 20:00:00  674.843872   775.709290   724.869751    748\n",
       "2019-11-23 21:00:00  646.715271   746.359009   705.454041    805\n",
       "2019-11-23 22:00:00  617.312378   725.117188   670.558533    759\n",
       "2019-11-23 23:00:00  516.152161   625.151245   571.223511    700\n",
       "2019-11-24 00:00:00  439.444122   498.452606   468.866150    570\n",
       "2019-11-24 01:00:00  313.758667   382.915253   353.606964    480\n",
       "2019-11-24 02:00:00  244.308212   316.424255   279.312561    361\n",
       "2019-11-24 03:00:00  161.055817   235.823227   202.543274    259\n",
       "2019-11-24 04:00:00   93.742264   139.703781   118.084068    222\n",
       "2019-11-24 05:00:00   64.995010   115.965881    85.280388     95\n",
       "2019-11-24 06:00:00  135.188263   173.634842   154.243423     96\n",
       "2019-11-24 07:00:00  215.035339   257.674408   235.501343    123\n",
       "2019-11-24 08:00:00  301.348755   354.874969   328.906860    238\n",
       "2019-11-24 09:00:00  377.465240   434.735107   409.886292    335\n",
       "2019-11-24 10:00:00  462.269226   526.459473   496.397125    417\n",
       "2019-11-24 11:00:00  507.375732   576.650269   521.648987    483\n",
       "2019-11-24 12:00:00  547.463501   612.834900   579.540161    584\n",
       "2019-11-24 13:00:00  582.718140   665.953735   630.749817    605\n",
       "2019-11-24 14:00:00  618.815918   708.615051   661.505615    574\n",
       "2019-11-24 15:00:00  591.135315   708.124023   645.480652    672\n",
       "2019-11-24 16:00:00  600.016357   685.036682   643.159241    630\n",
       "2019-11-24 17:00:00  590.827759   697.005554   633.076477    622\n",
       "2019-11-24 18:00:00  585.057312   680.260864   622.180542    574\n",
       "2019-11-24 19:00:00  513.618591   620.904114   571.111206    562\n",
       "2019-11-24 20:00:00  410.183228   494.679688   459.829407    473\n",
       "2019-11-24 21:00:00  326.169220   427.052124   376.353241    419\n",
       "2019-11-24 22:00:00  268.580292   346.321075   321.218384    343\n",
       "2019-11-24 23:00:00  176.517685   232.157562   206.725662    235\n",
       "2019-11-25 00:00:00   90.089920   124.980278   106.125969    158\n",
       "2019-11-25 01:00:00   62.842960    91.194633    74.082214    137\n",
       "2019-11-25 02:00:00   56.416943    77.857574    70.515022     88\n",
       "2019-11-25 03:00:00   66.925171    86.466187    76.698158     86\n",
       "2019-11-25 04:00:00   66.711945    97.078476    77.246338     81\n",
       "2019-11-25 05:00:00  152.214371   198.589249   173.087708     72\n",
       "2019-11-25 06:00:00  337.322449   476.376862   388.476746    162\n",
       "2019-11-25 07:00:00  509.541840   660.117065   579.287720    450\n",
       "2019-11-25 08:00:00  610.099731   682.323486   639.717346    601\n",
       "2019-11-25 09:00:00  536.349121   592.578125   566.492249    612\n",
       "2019-11-25 10:00:00  536.265015   600.036926   572.249634    597\n",
       "2019-11-25 11:00:00  529.457825   605.916321   568.570068    522\n",
       "2019-11-25 12:00:00  510.405396   582.279846   544.050964    524\n",
       "2019-11-25 13:00:00  558.713745   648.643616   592.397888    566\n",
       "2019-11-25 14:00:00  635.192261   734.316284   671.230042    601\n",
       "2019-11-25 15:00:00  651.272034   762.206360   711.559631    661\n",
       "2019-11-25 16:00:00  746.824158   823.762146   783.215515    720\n",
       "2019-11-25 17:00:00  724.510071   825.506958   780.530151    856\n",
       "2019-11-25 18:00:00  662.411011   767.600708   733.461548    845\n",
       "2019-11-25 19:00:00  538.706970   615.918152   578.708923    784\n",
       "2019-11-25 20:00:00  509.265106   592.502747   553.872131    681\n",
       "2019-11-25 21:00:00  370.894257   450.194305   402.468536    540\n",
       "2019-11-25 22:00:00  268.609711   338.325562   304.317596    460\n",
       "2019-11-25 23:00:00  181.472778   230.187119   205.911255    299\n",
       "2019-11-26 00:00:00  114.345055   150.514236   132.938309    207\n",
       "2019-11-26 01:00:00   71.236237   105.035950    90.331749    126\n",
       "2019-11-26 02:00:00   49.860107    74.988510    63.040421     61\n",
       "2019-11-26 03:00:00   50.341316    79.797348    64.817398     52\n",
       "2019-11-26 04:00:00   53.357006    71.979874    61.041183     51\n",
       "2019-11-26 05:00:00  129.884567   178.761078   155.007202     66\n",
       "2019-11-26 06:00:00  359.905212   483.195435   402.133118    159\n",
       "2019-11-26 07:00:00  525.727661   654.793762   578.306702    417\n",
       "2019-11-26 08:00:00  581.855469   681.522217   629.199890    600\n",
       "2019-11-26 09:00:00  518.339294   631.309692   579.226746    642\n",
       "2019-11-26 10:00:00  489.191833   578.944580   544.794067    615\n",
       "2019-11-26 11:00:00  482.649109   582.760925   534.686035    587\n",
       "2019-11-26 12:00:00  551.887207   613.929077   580.336365    585\n",
       "2019-11-26 13:00:00  601.858154   661.853516   625.453003    633\n",
       "2019-11-26 14:00:00  646.542603   740.821045   700.391174    652\n",
       "2019-11-26 15:00:00  679.524536   804.039062   753.582031    725\n",
       "2019-11-26 16:00:00  790.745605   864.417969   820.473755    755\n",
       "2019-11-26 17:00:00  752.002625   905.870239   826.324951    865\n",
       "2019-11-26 18:00:00  700.407715   821.201233   770.808655    813\n",
       "2019-11-26 19:00:00  594.738647   729.613586   665.459412    853\n",
       "2019-11-26 20:00:00  539.288818   617.799622   581.143188    703\n",
       "2019-11-26 21:00:00  425.693359   502.281677   459.083801    596\n",
       "2019-11-26 22:00:00  322.916901   392.229919   347.472443    449\n",
       "2019-11-26 23:00:00  193.416595   254.892395   230.890198    337\n",
       "2019-11-27 00:00:00  117.814667   157.669373   138.996292    239\n",
       "2019-11-27 01:00:00   70.827072   101.017326    86.077705    161\n",
       "2019-11-27 02:00:00   54.548908    76.836800    64.658455     97\n",
       "2019-11-27 03:00:00   50.200325    73.040794    60.371136     60\n",
       "2019-11-27 04:00:00   67.650642    83.498756    74.986496     79\n",
       "2019-11-27 05:00:00  153.760681   186.187790   169.826065     72\n",
       "2019-11-27 06:00:00  380.785217   439.392517   404.623596    166\n",
       "2019-11-27 07:00:00  575.390808   660.040649   619.889954    360\n",
       "2019-11-27 08:00:00  586.892456   673.079712   632.424927    585\n",
       "2019-11-27 09:00:00  540.917297   629.730347   582.789612    678\n",
       "2019-11-27 10:00:00  535.396606   626.247070   574.114807    656\n",
       "2019-11-27 11:00:00  544.303528   620.619385   579.564636    650\n",
       "2019-11-27 12:00:00  602.244446   681.430908   640.748169    613\n",
       "2019-11-27 13:00:00  603.100037   695.797058   652.317444    710\n",
       "2019-11-27 14:00:00  678.853821   789.523315   736.970764    784\n",
       "2019-11-27 15:00:00  705.872437   821.540771   775.517029    898\n",
       "2019-11-27 16:00:00  914.612488  1029.056763   980.928467    946\n",
       "2019-11-27 17:00:00  871.687317   994.438965   934.452148    945\n",
       "2019-11-27 18:00:00  774.861755   945.151184   868.103149    885\n",
       "2019-11-27 19:00:00  673.345032   817.248413   714.140991    786\n",
       "2019-11-27 20:00:00  551.020020   645.091675   601.282288    696\n",
       "2019-11-27 21:00:00  448.140778   564.096436   487.277557    540\n",
       "2019-11-27 22:00:00  338.968933   435.131897   380.217926    501\n",
       "2019-11-27 23:00:00  220.978302   300.860870   260.636383    452\n",
       "2019-11-28 00:00:00  168.095825   199.572311   184.244522    304\n",
       "2019-11-28 01:00:00   99.890068   128.883026   111.148720    213\n",
       "2019-11-28 02:00:00   68.964676    94.379524    79.556519    160\n",
       "2019-11-28 03:00:00   58.597336    90.137337    73.095024    112\n",
       "2019-11-28 04:00:00   74.640198    96.515297    87.004921     99\n",
       "2019-11-28 05:00:00  155.947266   198.275146   176.828598     93\n",
       "2019-11-28 06:00:00  368.779785   442.230957   416.575134    104\n",
       "2019-11-28 07:00:00  593.941223   698.502075   644.069214    158\n",
       "2019-11-28 08:00:00  383.950439   455.824280   415.098785    227\n",
       "2019-11-28 09:00:00  413.404175   477.536285   451.216766    262\n",
       "2019-11-28 10:00:00  435.728546   520.339233   479.807831    328\n",
       "2019-11-28 11:00:00  462.017151   549.637024   507.597229    405\n",
       "2019-11-28 12:00:00  487.503937   546.578125   509.693817    457\n",
       "2019-11-28 13:00:00  505.603394   607.625488   560.773254    509\n",
       "2019-11-28 14:00:00  609.105652   703.590515   652.341553    540\n",
       "2019-11-28 15:00:00  640.379089   747.017334   682.436035    640\n",
       "2019-11-28 16:00:00  657.870605   766.894226   714.082031    609\n",
       "2019-11-28 17:00:00  647.355652   769.897888   711.817932    635\n",
       "2019-11-28 18:00:00  626.295959   747.437927   697.460632    607\n",
       "2019-11-28 19:00:00  546.544922   649.109314   601.712036    616\n",
       "2019-11-28 20:00:00  502.933960   585.556641   546.032227    595\n",
       "2019-11-28 21:00:00  448.914276   531.762878   485.486816    555\n",
       "2019-11-28 22:00:00  375.025696   447.772644   414.948853    543\n",
       "2019-11-28 23:00:00  284.408112   336.888947   310.576324    457\n",
       "2019-11-29 00:00:00  195.517105   230.273483   211.476883    306\n",
       "2019-11-29 01:00:00  123.858658   156.921783   136.410767    201\n",
       "2019-11-29 02:00:00   89.464287   115.135376   102.606720    140\n",
       "2019-11-29 03:00:00   77.403107   106.326691    89.875946     90\n",
       "2019-11-29 04:00:00   57.116714    77.800819    67.049110     68\n",
       "2019-11-29 05:00:00  131.132401   161.530411   143.934525     55\n",
       "2019-11-29 06:00:00  298.399109   379.931946   334.017639     95\n",
       "2019-11-29 07:00:00  438.789978   545.591064   503.688263    181\n",
       "2019-11-29 08:00:00  381.445740   475.760132   415.115723    335\n",
       "2019-11-29 09:00:00  382.256989   484.878784   425.313629    385\n",
       "2019-11-29 10:00:00  388.494995   468.181610   418.687408    434\n",
       "2019-11-29 11:00:00  396.747894   489.303040   436.245056    509\n",
       "2019-11-29 12:00:00  473.863373   531.242615   491.782715    465\n",
       "2019-11-29 13:00:00  514.403381   598.877014   559.051392    463\n",
       "2019-11-29 14:00:00  624.626038   717.196533   661.360046    568\n",
       "2019-11-29 15:00:00  665.334961   772.515381   696.074890    739\n",
       "2019-11-29 16:00:00  727.627075   842.654175   775.181213    729\n",
       "2019-11-29 17:00:00  682.357666   826.077087   742.469055    801\n",
       "2019-11-29 18:00:00  620.747375   757.365479   693.962830    691\n",
       "2019-11-29 19:00:00  546.610474   691.143494   618.155884    716\n",
       "2019-11-29 20:00:00  516.968628   630.974121   577.412231    597\n",
       "2019-11-29 21:00:00  481.987000   588.045105   543.748535    565\n",
       "2019-11-29 22:00:00  458.623932   581.436401   518.138916    527\n",
       "2019-11-29 23:00:00  388.011322   494.577057   437.621857    437\n",
       "2019-11-30 00:00:00  273.600800   333.964172   300.272461    363\n",
       "2019-11-30 01:00:00  211.876495   277.551849   245.158783    263\n",
       "2019-11-30 02:00:00  161.124893   211.391617   188.726013    211\n",
       "2019-11-30 03:00:00  134.620804   177.354767   155.301208    185\n",
       "2019-11-30 04:00:00   60.275806    89.531693    76.602898    138\n",
       "2019-11-30 05:00:00   64.968880    98.962318    85.239311     81\n",
       "2019-11-30 06:00:00  117.456123   165.602737   149.671249     94\n",
       "2019-11-30 07:00:00  216.617615   298.786011   249.910507    129\n",
       "2019-11-30 08:00:00  299.182312   365.416199   334.186157    209\n",
       "2019-11-30 09:00:00  356.731995   448.286896   406.900085    354\n",
       "2019-11-30 10:00:00  410.715668   498.637573   447.724976    469\n",
       "2019-11-30 11:00:00  425.256348   513.378906   468.039948    575\n",
       "2019-11-30 12:00:00  532.180298   605.925537   563.835266    544\n",
       "2019-11-30 13:00:00  527.822693   630.653137   576.983887    678\n",
       "2019-11-30 14:00:00  601.184692   704.960693   661.703430    696\n",
       "2019-11-30 15:00:00  580.032166   707.642029   642.826660    764\n",
       "2019-11-30 16:00:00  735.769043   837.448547   791.372986    827\n",
       "2019-11-30 17:00:00  675.194153   799.679688   743.171509    773\n",
       "2019-11-30 18:00:00  654.446777   776.352478   708.093750    771\n",
       "2019-11-30 19:00:00  611.146912   712.510681   655.590698    777\n",
       "2019-11-30 20:00:00  628.009888   701.418640   659.564331    688\n",
       "2019-11-30 21:00:00  590.508179   688.681213   639.086243    657\n",
       "2019-11-30 22:00:00  525.462341   650.203308   582.387817    620\n",
       "2019-11-30 23:00:00  421.954010   538.455322   476.031403    547\n",
       "2019-12-01 00:00:00  335.359802   401.921600   363.990540    419\n",
       "2019-12-01 01:00:00  236.159576   303.501251   274.743805    355\n",
       "2019-12-01 02:00:00  202.673660   261.837708   227.259201    264\n",
       "2019-12-01 03:00:00  150.995102   196.174225   169.823486    228\n",
       "2019-12-01 04:00:00   82.723785   114.306213    97.758194    191\n",
       "2019-12-01 05:00:00   52.516174    99.066185    71.999916     80\n",
       "2019-12-01 06:00:00   94.767357   148.601486   121.808449     64\n",
       "2019-12-01 07:00:00  191.393509   242.523529   215.835907    115\n",
       "2019-12-01 08:00:00  271.594879   331.099976   300.526764    189\n",
       "2019-12-01 09:00:00  364.720764   442.122192   404.367950    342\n",
       "2019-12-01 10:00:00  426.851685   523.050903   461.387604    444\n",
       "2019-12-01 11:00:00  447.630707   552.596436   506.441772    520\n",
       "2019-12-01 12:00:00  588.481262   646.788330   620.837463    621\n",
       "2019-12-01 13:00:00  568.186584   662.288574   623.023560    696\n",
       "2019-12-01 14:00:00  611.110229   719.184937   663.642273    635\n",
       "2019-12-01 15:00:00  562.354980   682.825195   621.004456    668\n",
       "2019-12-01 16:00:00  588.339600   676.361755   625.448425    639\n",
       "2019-12-01 17:00:00  519.131104   628.500610   579.857300    647\n",
       "2019-12-01 18:00:00  499.809692   636.780090   548.670959    641\n",
       "2019-12-01 19:00:00  432.873138   570.784485   498.721863    534\n",
       "2019-12-01 20:00:00  354.219543   426.650940   390.238922    414\n",
       "2019-12-01 21:00:00  288.583160   359.087646   326.323883    318\n",
       "2019-12-01 22:00:00  206.939743   299.001312   241.880188    263\n",
       "2019-12-01 23:00:00  134.536377   191.109909   152.608627    200\n",
       "2019-12-02 00:00:00   92.412216   130.385422   108.887009    164\n",
       "2019-12-02 01:00:00   60.806515    96.517479    76.797997     80\n",
       "2019-12-02 02:00:00   45.726677    83.319870    66.278755     41\n",
       "2019-12-02 03:00:00   52.184425    80.322296    63.694977     49\n",
       "2019-12-02 04:00:00   40.157974    71.138275    54.755848     58\n",
       "2019-12-02 05:00:00  104.808929   162.238464   136.206192     77\n",
       "2019-12-02 06:00:00  203.265198   357.827454   305.798523    169\n",
       "2019-12-02 07:00:00  360.319031   528.748291   441.657349    433\n",
       "2019-12-02 08:00:00  577.150452   681.956177   629.050720    648\n",
       "2019-12-02 09:00:00  540.096985   633.971985   576.531677    671\n",
       "2019-12-02 10:00:00  531.785522   606.163208   575.487122    638\n",
       "2019-12-02 11:00:00  512.999390   597.096375   558.014282    590\n",
       "2019-12-02 12:00:00  564.476013   628.020813   593.661682    575\n",
       "2019-12-02 13:00:00  586.094421   670.852844   622.050415    635\n",
       "2019-12-02 14:00:00  631.136292   736.708740   681.066040    669\n",
       "2019-12-02 15:00:00  665.208313   756.148193   703.747742    731\n",
       "2019-12-02 16:00:00  729.424988   858.159668   782.882202    706\n",
       "2019-12-02 17:00:00  685.486023   823.770386   751.506287    815\n",
       "2019-12-02 18:00:00  629.457642   770.206116   694.132446    874\n",
       "2019-12-02 19:00:00  508.296814   623.452332   565.443420    784\n",
       "2019-12-02 20:00:00  420.972198   527.395813   476.045044    581\n",
       "2019-12-02 21:00:00  334.855927   450.429901   370.682709    425\n",
       "2019-12-02 22:00:00  245.380951   305.322021   270.986633    323\n",
       "2019-12-02 23:00:00  156.204987   216.421951   184.234741    258\n",
       "2019-12-03 00:00:00   91.924133   122.992218   108.739944    154\n",
       "2019-12-03 01:00:00   45.509907    80.997955    63.233852     99\n",
       "2019-12-03 02:00:00   39.633900    66.129959    49.819672     62\n",
       "2019-12-03 03:00:00   45.124458    67.130447    57.501228     40\n",
       "2019-12-03 04:00:00   44.020691    79.869415    57.622498     45\n",
       "2019-12-03 05:00:00  100.238647   160.769302   134.375076     58\n",
       "2019-12-03 06:00:00  282.063690   388.243408   333.054047    153\n",
       "2019-12-03 07:00:00  435.202454   568.824951   480.952759    433\n",
       "2019-12-03 08:00:00  587.125000   720.519470   637.181580    652\n",
       "2019-12-03 09:00:00  542.959595   685.468506   601.676819    703\n",
       "2019-12-03 10:00:00  506.192017   638.486267   576.214478    613\n",
       "2019-12-03 11:00:00  492.562073   593.701477   547.942566    569\n",
       "2019-12-03 12:00:00  536.846436   607.542114   583.835022    556\n",
       "2019-12-03 13:00:00  547.186584   665.138123   604.525391    625\n",
       "2019-12-03 14:00:00  608.723999   744.729065   681.227905    624\n",
       "2019-12-03 15:00:00  657.477783   792.303223   721.996338    698\n",
       "2019-12-03 16:00:00  742.156311   843.870667   788.471069    782\n",
       "2019-12-03 17:00:00  722.750427   870.908752   779.932617    925\n",
       "2019-12-03 18:00:00  636.844910   807.800110   722.829468    912\n",
       "2019-12-03 19:00:00  530.657959   650.987427   599.280029    852\n",
       "2019-12-03 20:00:00  515.723572   600.897095   557.606812    711\n",
       "2019-12-03 21:00:00  389.827820   491.393372   446.001160    593\n",
       "2019-12-03 22:00:00  290.082794   368.562714   332.281036    503\n",
       "2019-12-03 23:00:00  186.841156   238.857483   218.297379    359\n",
       "2019-12-04 00:00:00  106.996422   143.168854   130.514984    207\n",
       "2019-12-04 01:00:00   70.884720   100.703850    85.730072    131\n",
       "2019-12-04 02:00:00   57.784191    80.795418    67.732758     73\n",
       "2019-12-04 03:00:00   54.885361    81.737961    67.050316     43\n",
       "2019-12-04 04:00:00   55.782135    77.434151    67.695641     61\n",
       "2019-12-04 05:00:00  138.846985   179.658340   156.144775     59\n",
       "2019-12-04 06:00:00  330.589233   394.497955   363.227570    159\n",
       "2019-12-04 07:00:00  499.236145   588.396973   542.415222    374\n",
       "2019-12-04 08:00:00  609.250610   696.036438   653.199402    627\n",
       "2019-12-04 09:00:00  550.821716   664.974121   608.147827    701\n",
       "2019-12-04 10:00:00  527.189575   635.456177   592.926147    628\n",
       "2019-12-04 11:00:00  538.016724   623.031494   581.962585    657\n",
       "2019-12-04 12:00:00  619.312622   693.579712   654.019592    614\n",
       "2019-12-04 13:00:00  622.584045   716.106323   678.510803    660\n",
       "2019-12-04 14:00:00  711.806946   812.175415   765.372864    670\n",
       "2019-12-04 15:00:00  738.423340   837.020874   771.200195    751\n",
       "2019-12-04 16:00:00  796.088074   866.965454   825.946106    742\n",
       "2019-12-04 17:00:00  780.240051   885.550171   838.215881    915\n",
       "2019-12-04 18:00:00  736.328491   863.189575   796.374573    917\n",
       "2019-12-04 19:00:00  637.254944   733.360291   678.775391    887\n",
       "2019-12-04 20:00:00  524.414673   651.505737   582.303345    692\n",
       "2019-12-04 21:00:00  456.918457   544.270020   502.446655    628\n",
       "2019-12-04 22:00:00  364.125580   442.887787   386.591064    515\n",
       "2019-12-04 23:00:00  232.994400   294.683777   253.517136    402\n",
       "2019-12-05 00:00:00  153.108398   196.518799   173.787155    287\n",
       "2019-12-05 01:00:00   94.828262   124.364708   106.746010    149\n",
       "2019-12-05 02:00:00   67.408615    96.157593    82.261703    100\n",
       "2019-12-05 03:00:00   55.894943    86.539513    70.909523     74\n",
       "2019-12-05 04:00:00   57.524250    80.552223    67.944702     60\n",
       "2019-12-05 05:00:00  131.590881   172.222443   143.881607     62\n",
       "2019-12-05 06:00:00  312.950989   387.882935   344.051697    135\n",
       "2019-12-05 07:00:00  492.297150   592.355408   540.916565    432\n",
       "2019-12-05 08:00:00  599.201172   669.960876   638.401428    616\n",
       "2019-12-05 09:00:00  551.326538   638.693909   596.732544    655\n",
       "2019-12-05 10:00:00  558.900818   637.116089   602.636108    646\n",
       "2019-12-05 11:00:00  565.210876   627.003906   593.668518    628\n",
       "2019-12-05 12:00:00  596.231995   667.296814   631.155090    591\n",
       "2019-12-05 13:00:00  602.621094   708.621277   652.554321    697\n",
       "2019-12-05 14:00:00  711.704956   798.872559   742.623962    703\n",
       "2019-12-05 15:00:00  728.168030   844.754639   782.288879    791\n",
       "2019-12-05 16:00:00  854.464050   970.864014   909.049011    828\n",
       "2019-12-05 17:00:00  853.992004   979.394104   911.818054    852\n",
       "2019-12-05 18:00:00  766.359558   932.079590   847.161499   1032\n",
       "2019-12-05 19:00:00  651.910522   785.919861   716.778625    977\n",
       "2019-12-05 20:00:00  633.822388   732.184204   676.821533    791\n",
       "2019-12-05 21:00:00  520.798340   622.063354   577.206909    701\n",
       "2019-12-05 22:00:00  404.701996   493.527893   442.428314    541\n",
       "2019-12-05 23:00:00  279.530151   340.327911   302.622833    510\n",
       "2019-12-06 00:00:00  202.319199   233.205307   218.095276    361\n",
       "2019-12-06 01:00:00  120.215179   150.144318   133.603195    211\n",
       "2019-12-06 02:00:00   68.358658   106.790390    89.354256    118\n",
       "2019-12-06 03:00:00   57.863853    89.448547    77.187370     68\n",
       "2019-12-06 04:00:00   54.491833    75.233826    62.692631     68\n",
       "2019-12-06 05:00:00  128.995499   164.189011   148.108078     68\n",
       "2019-12-06 06:00:00  327.154999   406.103729   363.907898    149\n",
       "2019-12-06 07:00:00  515.011169   613.500610   569.749573    441\n",
       "2019-12-06 08:00:00  632.313660   710.108582   673.237122    667\n",
       "2019-12-06 09:00:00  606.033630   669.271362   634.343628    684\n",
       "2019-12-06 10:00:00  572.938293   650.724854   609.880127    593\n",
       "2019-12-06 11:00:00  522.546997   610.571106   559.794800    594\n",
       "2019-12-06 12:00:00  555.624573   616.487793   578.195496    540\n",
       "2019-12-06 13:00:00  591.098938   690.128662   650.628784    582\n",
       "2019-12-06 14:00:00  725.989197   832.022888   773.004883    676\n",
       "2019-12-06 15:00:00  771.891541   880.365540   829.973145    839\n",
       "2019-12-06 16:00:00  926.970703  1042.731934   985.949829    916\n",
       "2019-12-06 17:00:00  929.526001  1042.180664  1000.819580   1077\n",
       "2019-12-06 18:00:00  835.557434   998.109985   924.228638   1090\n",
       "2019-12-06 19:00:00  726.587341   897.991333   782.885071    998\n",
       "2019-12-06 20:00:00  714.914185   811.253967   766.811829    875\n",
       "2019-12-06 21:00:00  634.774780   762.137146   700.754272    817\n",
       "2019-12-06 22:00:00  558.027832   708.629211   627.433838    718\n",
       "2019-12-06 23:00:00  454.955963   576.159790   516.321167    645\n",
       "2019-12-07 00:00:00  395.719696   465.860657   422.877014    618\n",
       "2019-12-07 01:00:00  279.482849   347.317627   314.192719    499\n",
       "2019-12-07 02:00:00  194.730637   264.689331   223.697693    317\n",
       "2019-12-07 03:00:00  153.873825   213.291748   176.136337    258\n",
       "2019-12-07 04:00:00  106.778099   139.020248   120.954170    236\n",
       "2019-12-07 05:00:00   98.391571   138.846130   115.368713    106\n",
       "2019-12-07 06:00:00  158.554810   213.712631   187.636368    118\n",
       "2019-12-07 07:00:00  254.695129   333.196503   289.541809    188\n",
       "2019-12-07 08:00:00  390.036469   452.083618   415.365692    305\n",
       "2019-12-07 09:00:00  465.347961   544.474609   497.777313    473\n",
       "2019-12-07 10:00:00  521.464233   602.480469   567.643799    516\n",
       "2019-12-07 11:00:00  531.620605   638.238403   579.110107    665\n",
       "2019-12-07 12:00:00  684.089050   763.223511   717.555115    665\n",
       "2019-12-07 13:00:00  669.256653   779.184753   721.631226    721\n",
       "2019-12-07 14:00:00  748.917969   868.200195   806.559143    700\n",
       "2019-12-07 15:00:00  741.554382   874.772644   818.198853    804\n",
       "2019-12-07 16:00:00  828.196777   953.851868   885.966064    876\n",
       "2019-12-07 17:00:00  838.107727   959.520691   878.505554    900\n",
       "2019-12-07 18:00:00  771.189148   894.334961   848.745544    921\n",
       "2019-12-07 19:00:00  688.457458   812.653564   749.034363    938\n",
       "2019-12-07 20:00:00  712.296265   811.077576   760.389160    797\n",
       "2019-12-07 21:00:00  663.940247   757.904602   713.043396    818\n",
       "2019-12-07 22:00:00  577.717957   717.385986   666.501099    761\n",
       "2019-12-07 23:00:00  495.221802   607.114014   542.477783    741\n",
       "2019-12-08 00:00:00  457.650665   522.931274   491.701813    643\n",
       "2019-12-08 01:00:00  330.408966   407.687286   367.529663    506\n",
       "2019-12-08 02:00:00  252.995209   319.964691   285.736481    398\n",
       "2019-12-08 03:00:00  191.504593   248.293884   216.161423    313\n",
       "2019-12-08 04:00:00   97.333412   128.226517   112.497597    214\n",
       "2019-12-08 05:00:00   60.136826   101.142044    82.234482    112\n",
       "2019-12-08 06:00:00  116.928322   158.225677   139.940338     87\n",
       "2019-12-08 07:00:00  200.878784   252.746735   226.401154    139\n",
       "2019-12-08 08:00:00  304.111664   366.930969   336.819916    215\n",
       "2019-12-08 09:00:00  398.879242   469.818298   430.270020    326\n",
       "2019-12-08 10:00:00  489.516235   569.287720   537.004333    452\n",
       "2019-12-08 11:00:00  527.647034   639.820312   575.263672    546\n",
       "2019-12-08 12:00:00  569.446167   659.891235   621.670776    567\n",
       "2019-12-08 13:00:00  558.913147   669.059448   621.338135    572\n",
       "2019-12-08 14:00:00  599.627319   735.552124   651.512146    602\n",
       "2019-12-08 15:00:00  604.304321   708.536255   647.404602    624\n",
       "2019-12-08 16:00:00  620.757568   695.202332   659.263611    676\n",
       "2019-12-08 17:00:00  580.428284   710.324463   654.095398    657\n",
       "2019-12-08 18:00:00  542.942505   634.786987   597.330261    686\n",
       "2019-12-08 19:00:00  441.479858   551.683350   505.745819    598\n",
       "2019-12-08 20:00:00  390.355377   447.776062   413.601471    497\n",
       "2019-12-08 21:00:00  297.689331   393.954681   334.443787    475\n",
       "2019-12-08 22:00:00  238.458618   306.640656   275.339111    365\n",
       "2019-12-08 23:00:00  156.966537   212.538879   181.704102    304\n",
       "2019-12-09 00:00:00  113.001114   150.094955   131.133652    206\n",
       "2019-12-09 01:00:00   65.475700    97.743439    79.499878    125\n",
       "2019-12-09 02:00:00   59.626259    90.641289    70.120468     82\n",
       "2019-12-09 03:00:00   64.895050    90.194656    77.221954     80\n",
       "2019-12-09 04:00:00   62.786713    92.187889    77.937218     82\n",
       "2019-12-09 05:00:00  142.041565   207.094376   173.591553     81\n",
       "2019-12-09 06:00:00  343.364319   477.609680   412.260254    160\n",
       "2019-12-09 07:00:00  514.047546   674.695740   623.716309    418\n",
       "2019-12-09 08:00:00  632.614380   719.419922   672.914001    672\n",
       "2019-12-09 09:00:00  567.571289   643.413818   598.815552    731\n",
       "2019-12-09 10:00:00  555.667664   631.384644   585.509155    591\n",
       "2019-12-09 11:00:00  533.847656   600.224976   571.974365    553\n",
       "2019-12-09 12:00:00  544.979126   597.429443   566.822571    510\n",
       "2019-12-09 13:00:00  561.111938   658.792725   598.628418    551\n",
       "2019-12-09 14:00:00  619.313721   723.600037   668.054749    607\n",
       "2019-12-09 15:00:00  659.736633   767.478699   712.909058    713\n",
       "2019-12-09 16:00:00  798.974854   911.138184   854.885803    781\n",
       "2019-12-09 17:00:00  804.102234   919.585938   859.078735    940\n",
       "2019-12-09 18:00:00  717.931152   822.564575   772.522095    961\n",
       "2019-12-09 19:00:00  574.032410   665.505676   630.296021    895\n",
       "2019-12-09 20:00:00  461.963562   552.491211   496.686646    581\n",
       "2019-12-09 21:00:00  341.807434   441.386292   388.731567    458\n",
       "2019-12-09 22:00:00  262.537659   332.631805   298.958893    404\n",
       "2019-12-09 23:00:00  163.764389   217.876053   189.125549    316\n",
       "2019-12-10 00:00:00  107.878555   140.036652   123.463516    199\n",
       "2019-12-10 01:00:00   62.440628    94.108337    76.476326    132\n",
       "2019-12-10 02:00:00   46.135815    74.920563    61.026154     69\n",
       "2019-12-10 03:00:00   44.452835    70.288643    61.913891     49\n",
       "2019-12-10 04:00:00   49.725140    69.323441    61.282883     62\n",
       "2019-12-10 05:00:00  117.036736   169.101654   144.883316     57\n",
       "2019-12-10 06:00:00  333.973755   455.770355   377.245880    142\n",
       "2019-12-10 07:00:00  508.665985   660.094727   588.386230    398\n",
       "2019-12-10 08:00:00  615.311768   723.773010   663.401794    643\n",
       "2019-12-10 09:00:00  547.672058   634.832581   590.629578    682\n",
       "2019-12-10 10:00:00  525.215515   652.152954   588.064941    601\n",
       "2019-12-10 11:00:00  497.792267   594.471191   548.064270    566\n",
       "2019-12-10 12:00:00  578.187012   656.547424   614.674438    624\n",
       "2019-12-10 13:00:00  597.916626   675.756653   639.542908    638\n",
       "2019-12-10 14:00:00  667.520203   765.922668   713.340515    599\n",
       "2019-12-10 15:00:00  707.200439   841.281494   782.170959    722\n",
       "2019-12-10 16:00:00  763.071106   859.958252   811.613708    705\n",
       "2019-12-10 17:00:00  784.983276   891.959473   829.387756    859\n",
       "2019-12-10 18:00:00  742.219482   865.160950   799.271973    913\n",
       "2019-12-10 19:00:00  595.949890   691.509155   644.040161    816\n",
       "2019-12-10 20:00:00  537.045471   648.674683   574.612854    702\n",
       "2019-12-10 21:00:00  438.413483   531.249756   485.233063    591\n",
       "2019-12-10 22:00:00  331.522308   414.329254   380.917145    443\n",
       "2019-12-10 23:00:00  213.463928   276.513306   246.525818    411\n",
       "2019-12-11 00:00:00  131.008728   160.051483   143.050797    233\n",
       "2019-12-11 01:00:00   68.464203    95.510338    82.287544    133\n",
       "2019-12-11 02:00:00   51.846783    79.242226    59.692749     75\n",
       "2019-12-11 03:00:00   54.354790    76.278320    63.340069     74\n",
       "2019-12-11 04:00:00   48.532013    74.669220    62.674747     54\n",
       "2019-12-11 05:00:00  132.899078   172.063965   153.975174     55\n",
       "2019-12-11 06:00:00  344.757965   432.291290   381.123779    148\n",
       "2019-12-11 07:00:00  550.642395   683.515198   605.781189    363\n",
       "2019-12-11 08:00:00  633.937622   716.208374   669.512512    615\n",
       "2019-12-11 09:00:00  568.747375   649.729553   612.118591    665\n",
       "2019-12-11 10:00:00  559.999390   657.673401   603.226990    593\n",
       "2019-12-11 11:00:00  537.947327   637.805298   583.320984    533\n",
       "2019-12-11 12:00:00  550.541809   636.212708   601.862854    559\n",
       "2019-12-11 13:00:00  603.656616   693.365784   645.343079    586\n",
       "2019-12-11 14:00:00  683.451477   770.529846   726.244751    670\n",
       "2019-12-11 15:00:00  697.408386   832.092346   780.294739    716\n",
       "2019-12-11 16:00:00  806.719482   932.704956   882.144836    824\n",
       "2019-12-11 17:00:00  811.464294   948.529724   882.985107    856\n",
       "2019-12-11 18:00:00  723.471741   889.038269   829.305420    893\n",
       "2019-12-11 19:00:00  626.680664   769.724548   677.482483    926\n",
       "2019-12-11 20:00:00  588.034668   687.233459   644.760742    763\n",
       "2019-12-11 21:00:00  451.012695   578.851379   520.032593    660\n",
       "2019-12-11 22:00:00  371.042053   473.727417   416.537720    545\n",
       "2019-12-11 23:00:00  247.260529   318.962982   276.124756    434\n",
       "2019-12-12 00:00:00  151.115616   202.067001   174.567307    300\n",
       "2019-12-12 01:00:00   87.557449   124.578491   107.208885    186\n",
       "2019-12-12 02:00:00   65.045876    92.924408    79.430649    125\n",
       "2019-12-12 03:00:00   48.594059    79.575867    65.526848     64\n",
       "2019-12-12 04:00:00   51.909393    78.968353    63.473015     58\n",
       "2019-12-12 05:00:00  133.875412   166.946335   152.662537     69\n",
       "2019-12-12 06:00:00  338.933044   419.312103   370.293335    165\n",
       "2019-12-12 07:00:00  521.369141   615.849731   563.959839    397\n",
       "2019-12-12 08:00:00  664.713684   752.061401   705.738159    749\n",
       "2019-12-12 09:00:00  588.392151   700.950745   630.338318    723\n",
       "2019-12-12 10:00:00  576.039062   663.869873   617.156616    709\n",
       "2019-12-12 11:00:00  539.629517   650.961670   598.335693    634\n",
       "2019-12-12 12:00:00  574.103210   665.703796   626.895386    603\n",
       "2019-12-12 13:00:00  599.591064   705.675781   657.953857    602\n",
       "2019-12-12 14:00:00  686.064697   811.652588   732.738220    687\n",
       "2019-12-12 15:00:00  747.082092   862.833435   793.552368    748\n",
       "2019-12-12 16:00:00  787.713562   947.868164   882.158875    821\n",
       "2019-12-12 17:00:00  842.723022   993.135132   913.484985   1017\n",
       "2019-12-12 18:00:00  803.868896   929.487183   841.572266    984\n",
       "2019-12-12 19:00:00  631.896057   793.661865   703.319092    936\n",
       "2019-12-12 20:00:00  694.290283   844.548828   749.621399    933\n",
       "2019-12-12 21:00:00  538.969421   671.327393   593.674377    723\n",
       "2019-12-12 22:00:00  402.472717   545.472778   481.394226    612\n",
       "2019-12-12 23:00:00  308.186066   389.944427   343.736206    478\n",
       "2019-12-13 00:00:00  200.410065   253.066803   226.547928    356\n",
       "2019-12-13 01:00:00  120.065437   174.956467   144.402237    224\n",
       "2019-12-13 02:00:00   75.496605   111.272308    94.443321    143\n",
       "2019-12-13 03:00:00   65.894272   100.161743    84.524879     91\n",
       "2019-12-13 04:00:00   62.563793    90.542404    79.374969     89\n",
       "2019-12-13 05:00:00  142.018478   180.244080   159.758820     84\n",
       "2019-12-13 06:00:00  335.307892   430.864410   377.107025    159\n",
       "2019-12-13 07:00:00  550.377014   645.785767   594.019470    406\n",
       "2019-12-13 08:00:00  633.828186   714.749573   671.725342    661\n",
       "2019-12-13 09:00:00  578.648315   674.930969   623.229675    687\n",
       "2019-12-13 10:00:00  557.593933   643.185242   590.436157    625\n",
       "2019-12-13 11:00:00  518.329529   598.772095   560.957703    572\n",
       "2019-12-13 12:00:00  523.302856   589.036072   544.544678    543\n",
       "2019-12-13 13:00:00  578.006531   682.915833   623.314331    527\n",
       "2019-12-13 14:00:00  682.667969   794.605469   734.910828    664\n",
       "2019-12-13 15:00:00  763.243835   906.302429   813.941711    904\n",
       "2019-12-13 16:00:00  959.824951  1077.306885  1025.359009    930\n",
       "2019-12-13 17:00:00  934.362671  1099.949463  1015.166016   1071\n",
       "2019-12-13 18:00:00  899.688965  1059.415527   986.321594   1130\n",
       "2019-12-13 19:00:00  748.725830   883.774963   829.267578   1148\n",
       "2019-12-13 20:00:00  774.183899   898.995789   835.606934    987\n",
       "2019-12-13 21:00:00  674.398560   781.959351   727.330688    876\n",
       "2019-12-13 22:00:00  590.887817   706.478882   642.091003    800\n",
       "2019-12-13 23:00:00  485.253693   605.218811   544.037598    678\n",
       "2019-12-14 00:00:00  407.105042   471.667236   443.714081    582\n",
       "2019-12-14 01:00:00  291.112915   365.447083   325.229675    411\n",
       "2019-12-14 02:00:00  220.454636   291.861328   252.059723    284\n",
       "2019-12-14 03:00:00  152.885956   218.057098   187.058777    215\n",
       "2019-12-14 04:00:00   65.986122   106.739853    90.069618    164\n",
       "2019-12-14 05:00:00   62.192314   110.867889    83.913300     93\n",
       "2019-12-14 06:00:00  138.189011   195.660522   168.595795    104\n",
       "2019-12-14 07:00:00  253.255188   308.688354   280.434692    171\n",
       "2019-12-14 08:00:00  368.600769   430.154572   391.346710    296\n",
       "2019-12-14 09:00:00  447.833374   527.073303   487.596436    460\n",
       "2019-12-14 10:00:00  488.300354   611.561646   553.640808    552\n",
       "2019-12-14 11:00:00  520.680603   614.173401   566.385315    632\n",
       "2019-12-14 12:00:00  621.606262   693.266113   658.437683    636\n",
       "2019-12-14 13:00:00  646.090088   744.954468   688.697205    763\n",
       "2019-12-14 14:00:00  715.945496   853.066711   766.596191    780\n",
       "2019-12-14 15:00:00  759.068848   852.721313   812.781250    806\n",
       "2019-12-14 16:00:00  829.765015   981.957458   898.556885    859\n",
       "2019-12-14 17:00:00  843.880920   999.947449   903.135559    900\n",
       "2019-12-14 18:00:00  809.537415   957.754456   867.679565    923\n",
       "2019-12-14 19:00:00  724.315674   845.237305   798.234070    879\n",
       "2019-12-14 20:00:00  739.512512   850.167419   780.087646    813\n",
       "2019-12-14 21:00:00  666.789307   827.039856   730.450378    751\n",
       "2019-12-14 22:00:00  628.490662   762.098877   665.440186    779\n",
       "2019-12-14 23:00:00  505.078583   630.269836   558.657776    699\n",
       "2019-12-15 00:00:00  452.993896   515.394226   486.719299    630\n",
       "2019-12-15 01:00:00  330.407898   391.353424   357.732147    498\n",
       "2019-12-15 02:00:00  260.099487   309.972565   284.502869    348\n",
       "2019-12-15 03:00:00  180.350586   243.124725   211.912231    317\n",
       "2019-12-15 04:00:00   90.319077   144.371490   116.565376    218\n",
       "2019-12-15 05:00:00   60.762726   105.969566    83.667419    109\n",
       "2019-12-15 06:00:00  121.414001   176.694397   139.934967     96\n",
       "2019-12-15 07:00:00  199.898788   262.649170   231.560806    117\n",
       "2019-12-15 08:00:00  293.722382   342.515961   322.313354    209\n",
       "2019-12-15 09:00:00  390.903687   455.987000   424.733765    310\n",
       "2019-12-15 10:00:00  466.651062   551.783447   506.700317    475\n",
       "2019-12-15 11:00:00  548.869507   604.932617   575.026672    563\n",
       "2019-12-15 12:00:00  606.383301   680.003296   650.716675    614\n",
       "2019-12-15 13:00:00  610.136230   710.767212   653.961609    659\n",
       "2019-12-15 14:00:00  653.148865   732.449707   701.041199    677\n",
       "2019-12-15 15:00:00  634.487793   747.923401   686.016602    704\n",
       "2019-12-15 16:00:00  666.560974   757.000427   717.349670    706\n",
       "2019-12-15 17:00:00  639.118347   735.976318   690.569946    735\n",
       "2019-12-15 18:00:00  565.410522   686.010620   631.117371    740\n",
       "2019-12-15 19:00:00  468.032501   569.269653   523.083984    617\n",
       "2019-12-15 20:00:00  427.022705   518.172363   465.841858    621\n",
       "2019-12-15 21:00:00  338.080261   432.395386   388.964874    489\n",
       "2019-12-15 22:00:00  248.861923   328.411377   293.440247    434\n",
       "2019-12-15 23:00:00  167.315308   226.931076   203.348114    319\n",
       "2019-12-16 00:00:00   98.505836   132.609406   111.100548    169\n",
       "2019-12-16 01:00:00   66.247581    90.886200    76.812141    120\n",
       "2019-12-16 02:00:00   61.205986    92.931931    70.241035     70\n",
       "2019-12-16 03:00:00   59.211510    85.320847    70.315620     66\n",
       "2019-12-16 04:00:00   62.798813    89.687576    75.183327     64\n",
       "2019-12-16 05:00:00  134.185425   191.364853   167.903259     74\n",
       "2019-12-16 06:00:00  309.170563   451.030640   390.312408    187\n",
       "2019-12-16 07:00:00  512.274170   710.270325   622.201660    414\n",
       "2019-12-16 08:00:00  633.201660   730.029236   694.269714    694\n",
       "2019-12-16 09:00:00  568.129272   670.093628   624.197937    709\n",
       "2019-12-16 10:00:00  542.485046   621.981628   590.301086    646\n",
       "2019-12-16 11:00:00  531.626465   602.257202   571.032898    569\n",
       "2019-12-16 12:00:00  572.309265   625.648438   597.630920    559\n",
       "2019-12-16 13:00:00  607.044556   684.902771   636.206421    593\n",
       "2019-12-16 14:00:00  680.017761   762.986206   730.597839    642\n",
       "2019-12-16 15:00:00  670.927734   812.011414   756.866638    690\n",
       "2019-12-16 16:00:00  791.563354   896.979980   834.705627    727\n",
       "2019-12-16 17:00:00  791.503479   922.022217   864.914917    784\n",
       "2019-12-16 18:00:00  725.361511   853.644226   792.106140    926\n",
       "2019-12-16 19:00:00  583.837402   668.160583   628.095154    869\n",
       "2019-12-16 20:00:00  522.810791   604.858276   557.648865    756\n",
       "2019-12-16 21:00:00  393.908264   489.167419   434.111847    583\n",
       "2019-12-16 22:00:00  294.052734   366.006012   325.794189    453\n",
       "2019-12-16 23:00:00  186.199768   237.136612   208.917191    286\n",
       "2019-12-17 00:00:00  116.067192   138.559982   126.783836    207\n",
       "2019-12-17 01:00:00   67.699341    90.166534    79.176712    107\n",
       "2019-12-17 02:00:00   51.177208    73.704002    64.609840     61\n",
       "2019-12-17 03:00:00   47.627720    66.390106    55.923641     46\n",
       "2019-12-17 04:00:00   53.431953    75.482086    61.196659     54\n",
       "2019-12-17 05:00:00  133.951096   177.159439   154.134232     65\n",
       "2019-12-17 06:00:00  342.561401   477.398376   396.257324    138\n",
       "2019-12-17 07:00:00  548.517212   705.049194   625.232666    412\n",
       "2019-12-17 08:00:00  654.967285   746.850098   700.101624    682\n",
       "2019-12-17 09:00:00  585.966614   679.255005   639.049744    728\n",
       "2019-12-17 10:00:00  546.151855   635.748901   579.515381    646\n",
       "2019-12-17 11:00:00  519.999817   614.048950   569.520630    619\n",
       "2019-12-17 12:00:00  573.218750   635.578186   601.197571    581\n",
       "2019-12-17 13:00:00  585.469360   682.685181   632.684509    668\n",
       "2019-12-17 14:00:00  662.649414   760.902100   707.665955    689\n",
       "2019-12-17 15:00:00  711.928711   827.673035   759.225159    734\n",
       "2019-12-17 16:00:00  813.473572   929.153992   867.388123    750\n",
       "2019-12-17 17:00:00  829.652161   932.062561   889.323303    911\n",
       "2019-12-17 18:00:00  770.445374   901.538269   833.224304    972\n",
       "2019-12-17 19:00:00  674.747437   791.168579   727.678467    817\n",
       "2019-12-17 20:00:00  528.522827   610.980652   572.670227    675\n",
       "2019-12-17 21:00:00  422.864929   516.943787   472.160095    610\n",
       "2019-12-17 22:00:00  336.875397   412.405182   366.071198    474\n",
       "2019-12-17 23:00:00  204.958694   266.649536   234.449905    376\n",
       "2019-12-18 00:00:00  127.866966   153.310150   139.452332    235\n",
       "2019-12-18 01:00:00   70.105232   100.973015    83.982506    126\n",
       "2019-12-18 02:00:00   50.325504    77.036789    64.280838     80\n",
       "2019-12-18 03:00:00   49.724049    68.962105    61.592819     61\n",
       "2019-12-18 04:00:00   46.403191    69.196877    57.153450     46\n",
       "2019-12-18 05:00:00  139.066040   167.207932   154.756027     56\n",
       "2019-12-18 06:00:00  345.587769   405.071808   370.961487    168\n",
       "2019-12-18 07:00:00  592.873962   681.020630   627.128052    382\n",
       "2019-12-18 08:00:00  646.414124   737.819641   686.751831    638\n",
       "2019-12-18 09:00:00  591.532410   684.165771   634.849548    688\n",
       "2019-12-18 10:00:00  558.551025   668.229919   616.391052    616\n",
       "2019-12-18 11:00:00  540.029419   643.083618   583.035767    588\n",
       "2019-12-18 12:00:00  587.893799   684.980347   636.383179    595\n",
       "2019-12-18 13:00:00  615.475891   718.215515   655.546753    643\n",
       "2019-12-18 14:00:00  687.312500   784.141357   735.295471    660\n",
       "2019-12-18 15:00:00  723.926147   825.320190   774.843079    786\n",
       "2019-12-18 16:00:00  833.539429   925.830750   878.117126    776\n",
       "2019-12-18 17:00:00  842.324951   962.612061   901.369019    850\n",
       "2019-12-18 18:00:00  758.319885   897.807556   834.021912    950\n",
       "2019-12-18 19:00:00  667.964478   790.764221   734.253601    917\n",
       "2019-12-18 20:00:00  607.014221   720.069702   648.460266    798\n",
       "2019-12-18 21:00:00  494.421600   584.285828   546.893616    642\n",
       "2019-12-18 22:00:00  381.746368   469.724121   419.707703    551\n",
       "2019-12-18 23:00:00  248.395416   319.444489   288.442261    463\n",
       "2019-12-19 00:00:00  155.845001   205.653702   183.187820    292\n",
       "2019-12-19 01:00:00   97.475594   127.857201   115.158508    185\n",
       "2019-12-19 02:00:00   68.631989   101.313782    82.705856    113\n",
       "2019-12-19 03:00:00   61.729275    88.839386    71.102943     72\n",
       "2019-12-19 04:00:00   56.500858    82.020103    70.365479     60\n",
       "2019-12-19 05:00:00  145.972183   179.857834   161.611481     70\n",
       "2019-12-19 06:00:00  354.728882   417.648804   401.174194    173\n",
       "2019-12-19 07:00:00  602.123108   688.030945   643.032043    403\n",
       "2019-12-19 08:00:00  636.749756   722.630981   671.234436    653\n",
       "2019-12-19 09:00:00  598.541870   686.213623   633.964905    700\n",
       "2019-12-19 10:00:00  551.874878   644.461487   603.778564    643\n",
       "2019-12-19 11:00:00  541.838379   629.014832   588.041626    697\n",
       "2019-12-19 12:00:00  607.618286   674.452332   642.639648    622\n",
       "2019-12-19 13:00:00  629.493469   721.625671   657.705444    640\n",
       "2019-12-19 14:00:00  717.862915   827.338196   763.682983    709\n",
       "2019-12-19 15:00:00  730.648926   853.177734   800.247803    784\n",
       "2019-12-19 16:00:00  827.978699   942.469116   881.436523    808\n",
       "2019-12-19 17:00:00  850.679260  1001.858948   931.978149   1015\n",
       "2019-12-19 18:00:00  812.050537   984.733643   885.614990   1031\n",
       "2019-12-19 19:00:00  706.644287   872.606995   790.551941    993\n",
       "2019-12-19 20:00:00  683.986694   814.779846   753.029236    933\n",
       "2019-12-19 21:00:00  548.263123   685.814270   606.440613    750\n",
       "2019-12-19 22:00:00  420.601410   536.253784   481.477936    650\n",
       "2019-12-19 23:00:00  291.388031   394.440247   342.395294    487\n",
       "2019-12-20 00:00:00  189.520538   237.135605   216.036377    327\n",
       "2019-12-20 01:00:00  118.959000   169.143127   139.284790    240\n",
       "2019-12-20 02:00:00   79.696648   115.383354    95.443810    111\n",
       "2019-12-20 03:00:00   65.268707    92.019135    82.893875     89\n",
       "2019-12-20 04:00:00   71.023880   102.863579    85.037468    109\n",
       "2019-12-20 05:00:00  145.783936   185.435257   161.761185     79\n",
       "2019-12-20 06:00:00  341.990265   431.802307   385.614502    168\n",
       "2019-12-20 07:00:00  558.070557   674.196411   601.315857    413\n",
       "2019-12-20 08:00:00  626.502991   697.305603   653.847290    625\n",
       "2019-12-20 09:00:00  559.663757   638.207397   600.990601    661\n",
       "2019-12-20 10:00:00  540.172546   624.887512   592.362976    683\n",
       "2019-12-20 11:00:00  507.165985   580.289612   541.819702    621\n",
       "2019-12-20 12:00:00  565.260742   628.406860   594.211487    590\n",
       "2019-12-20 13:00:00  641.819031   729.372314   676.458984    547\n",
       "2019-12-20 14:00:00  758.818176   847.197693   800.188538    666\n",
       "2019-12-20 15:00:00  794.869995   908.195801   845.060730    765\n",
       "2019-12-20 16:00:00  914.249695  1030.468018   968.054932    857\n",
       "2019-12-20 17:00:00  918.019287  1066.116943   987.641052    993\n",
       "2019-12-20 18:00:00  839.890381  1014.921997   942.163818   1014\n",
       "2019-12-20 19:00:00  761.284363   938.822083   840.342407   1058\n",
       "2019-12-20 20:00:00  725.497131   863.520630   784.461365    893\n",
       "2019-12-20 21:00:00  620.458618   778.719543   695.220032    787\n",
       "2019-12-20 22:00:00  549.452026   668.854736   607.428223    770\n",
       "2019-12-20 23:00:00  462.877502   568.806946   516.798645    676\n",
       "2019-12-21 00:00:00  373.169006   433.709961   400.648895    523\n",
       "2019-12-21 01:00:00  261.641998   322.628601   288.752838    396\n",
       "2019-12-21 02:00:00  209.072296   261.682281   229.734573    290\n",
       "2019-12-21 03:00:00  156.622528   211.027084   184.845535    243\n",
       "2019-12-21 04:00:00   99.832336   133.587006   114.080788    201\n",
       "2019-12-21 05:00:00  100.253914   140.508286   112.845192    108\n",
       "2019-12-21 06:00:00  167.760971   206.738525   187.142731    118\n",
       "2019-12-21 07:00:00  257.331238   328.655029   298.377563    157\n",
       "2019-12-21 08:00:00  352.614410   427.956696   392.500305    263\n",
       "2019-12-21 09:00:00  435.150452   518.785339   482.857147    358\n",
       "2019-12-21 10:00:00  528.283142   610.038330   561.465759    467\n",
       "2019-12-21 11:00:00  526.973816   639.978333   591.028748    606\n",
       "2019-12-21 12:00:00  599.986450   687.103943   635.771057    597\n",
       "2019-12-21 13:00:00  628.882751   718.590149   675.798767    647\n",
       "2019-12-21 14:00:00  696.013794   793.622925   753.493530    733\n",
       "2019-12-21 15:00:00  721.975037   824.891968   778.729858    777\n",
       "2019-12-21 16:00:00  782.711487   892.573853   840.547485    787\n",
       "2019-12-21 17:00:00  805.820374   966.420654   865.855713    830\n",
       "2019-12-21 18:00:00  789.768188   922.879517   839.013367    787\n",
       "2019-12-21 19:00:00  719.452820   869.031616   787.217102    737\n",
       "2019-12-21 20:00:00  677.880981   765.285645   721.355225    762\n",
       "2019-12-21 21:00:00  651.348267   748.219421   695.902039    647\n",
       "2019-12-21 22:00:00  599.575928   725.185791   647.712158    639\n",
       "2019-12-21 23:00:00  503.090332   586.442810   543.625488    579\n",
       "2019-12-22 00:00:00  334.274567   379.482605   358.612396    414\n",
       "2019-12-22 01:00:00  256.785492   320.649689   293.222198    362\n",
       "2019-12-22 02:00:00  220.759674   270.070679   250.582733    300\n",
       "2019-12-22 03:00:00  163.260956   217.158173   185.960281    221\n",
       "2019-12-22 04:00:00   75.149132   110.413559    89.906990    175\n",
       "2019-12-22 05:00:00   60.486969    94.884087    74.213150     85\n",
       "2019-12-22 06:00:00  112.617477   159.075745   134.563690     95\n",
       "2019-12-22 07:00:00  201.029449   258.573639   227.899185    117\n",
       "2019-12-22 08:00:00  279.998108   339.077637   309.651184    187\n",
       "2019-12-22 09:00:00  373.955231   448.092560   417.555298    284\n",
       "2019-12-22 10:00:00  470.201355   546.102661   507.953735    404\n",
       "2019-12-22 11:00:00  501.348083   588.135742   545.689331    455\n",
       "2019-12-22 12:00:00  503.078613   582.229004   542.668823    508\n",
       "2019-12-22 13:00:00  530.042664   606.810608   566.479736    565\n",
       "2019-12-22 14:00:00  558.354919   665.496094   609.247559    559\n",
       "2019-12-22 15:00:00  592.060425   691.826782   626.054321    592\n",
       "2019-12-22 16:00:00  600.648132   662.434937   627.423340    613\n",
       "2019-12-22 17:00:00  588.096741   680.280090   631.337341    648\n",
       "2019-12-22 18:00:00  541.947205   645.100586   593.872559    626\n",
       "2019-12-22 19:00:00  486.251221   591.395203   540.287476    571\n",
       "2019-12-22 20:00:00  402.119293   469.883728   431.913605    504\n",
       "2019-12-22 21:00:00  329.418671   433.747711   365.248413    459\n",
       "2019-12-22 22:00:00  239.221741   315.529785   281.473602    369\n",
       "2019-12-22 23:00:00  146.989670   210.259827   171.678375    281\n",
       "2019-12-23 00:00:00   88.484940   134.183533   118.684540    174\n",
       "2019-12-23 01:00:00   57.361664    93.229759    75.810799    113\n",
       "2019-12-23 02:00:00   52.069485    82.805069    69.211266     77\n",
       "2019-12-23 03:00:00   50.991432    80.417213    68.277756     62\n",
       "2019-12-23 04:00:00   58.483891    85.259735    69.954613     68\n",
       "2019-12-23 05:00:00  124.938293   193.579895   150.848389     63\n",
       "2019-12-23 06:00:00  298.098938   434.006775   360.124817    134\n",
       "2019-12-23 07:00:00  467.276947   635.268677   552.658142    245\n",
       "2019-12-23 08:00:00  442.202393   533.110168   479.271973    406\n",
       "2019-12-23 09:00:00  430.703857   508.979156   467.704071    571\n",
       "2019-12-23 10:00:00  431.759460   499.953491   461.030487    509\n",
       "2019-12-23 11:00:00  432.381073   512.841614   466.644135    534\n",
       "2019-12-23 12:00:00  510.220154   574.414246   526.613831    491\n",
       "2019-12-23 13:00:00  538.179321   604.114807   575.487610    548\n",
       "2019-12-23 14:00:00  605.748474   676.181946   642.537903    627\n",
       "2019-12-23 15:00:00  640.366821   723.280457   688.738953    749\n",
       "2019-12-23 16:00:00  773.989380   882.521057   835.548218    756\n",
       "2019-12-23 17:00:00  764.413086   881.161133   834.907654    816\n",
       "2019-12-23 18:00:00  669.354126   825.829468   741.925537    774\n",
       "2019-12-23 19:00:00  513.864990   655.036194   575.960999    759\n",
       "2019-12-23 20:00:00  470.903412   544.570374   514.835815    669\n",
       "2019-12-23 21:00:00  371.359497   450.728516   409.548065    577\n",
       "2019-12-23 22:00:00  250.322876   319.737915   290.510529    453\n",
       "2019-12-23 23:00:00  149.604797   213.967514   182.404312    326\n",
       "2019-12-24 00:00:00  111.747070   139.810318   124.634300    207\n",
       "2019-12-24 01:00:00   67.136902    88.543900    77.396965    150\n",
       "2019-12-24 02:00:00   54.113541    77.893814    64.059486    100\n",
       "2019-12-24 03:00:00   50.406845    73.142525    63.105865     73\n",
       "2019-12-24 04:00:00   54.814289    76.049591    64.036690     64\n",
       "2019-12-24 05:00:00  113.639816   156.219727   132.276138     42\n",
       "2019-12-24 06:00:00  287.726715   384.454315   327.503113    102\n",
       "2019-12-24 07:00:00  441.180298   579.721375   510.702637    214\n",
       "2019-12-24 08:00:00  412.132477   503.445648   442.868530    340\n",
       "2019-12-24 09:00:00  378.199005   512.691162   425.742706    439\n",
       "2019-12-24 10:00:00  392.825989   503.208771   445.814514    471\n",
       "2019-12-24 11:00:00  408.163971   506.863403   458.023010    564\n",
       "2019-12-24 12:00:00  517.057922   571.885803   553.988159    538\n",
       "2019-12-24 13:00:00  518.144043   598.440369   567.080994    650\n",
       "2019-12-24 14:00:00  597.454956   702.576904   644.559509    696\n",
       "2019-12-24 15:00:00  614.689453   739.500122   670.850708    828\n",
       "2019-12-24 16:00:00  825.556519   947.631714   873.311523    847\n",
       "2019-12-24 17:00:00  773.283264   892.223816   824.690063    862\n",
       "2019-12-24 18:00:00  692.410950   841.654053   761.742798    880\n",
       "2019-12-24 19:00:00  575.505188   731.080566   663.016663    759\n",
       "2019-12-24 20:00:00  498.543457   599.924011   545.690613    629\n",
       "2019-12-24 21:00:00  406.872162   507.425751   453.218964    583\n",
       "2019-12-24 22:00:00  325.605804   411.166901   365.119965    472\n",
       "2019-12-24 23:00:00  193.330688   244.622406   224.769089    420\n",
       "2019-12-25 00:00:00  157.848602   185.851059   169.173340    294\n",
       "2019-12-25 01:00:00   77.666321   111.242012   101.393372    225\n",
       "2019-12-25 02:00:00   61.557137    85.513504    73.729088    152\n",
       "2019-12-25 03:00:00   53.511650    72.272659    61.548897    103\n",
       "2019-12-25 04:00:00   62.490768    86.329865    73.594658     89\n",
       "2019-12-25 05:00:00  135.511475   158.481781   145.837753     45\n",
       "2019-12-25 06:00:00  288.575378   348.307343   310.043182     74\n",
       "2019-12-25 07:00:00  483.621338   563.446106   524.576294     83\n",
       "2019-12-25 08:00:00  289.408508   370.079163   337.369476    117\n",
       "2019-12-25 09:00:00  323.095490   425.840515   370.569580    138\n",
       "2019-12-25 10:00:00  401.258484   469.520264   432.148590    206\n",
       "2019-12-25 11:00:00  391.806763   488.201721   439.542755    234\n",
       "2019-12-25 12:00:00  352.493622   424.369812   388.975433    307\n",
       "2019-12-25 13:00:00  398.318665   486.453247   448.004700    280\n",
       "2019-12-25 14:00:00  472.154572   565.442871   521.794006    353\n",
       "2019-12-25 15:00:00  496.017883   625.626282   551.059998    382\n",
       "2019-12-25 16:00:00  429.330170   524.003906   487.612030    377\n",
       "2019-12-25 17:00:00  427.207581   559.024536   504.096771    391\n",
       "2019-12-25 18:00:00  454.689606   552.104553   488.113525    381\n",
       "2019-12-25 19:00:00  409.692596   510.946716   459.360016    398\n",
       "2019-12-25 20:00:00  347.158020   407.331848   380.194519    397\n",
       "2019-12-25 21:00:00  329.304810   429.403076   387.502258    392\n",
       "2019-12-25 22:00:00  324.264404   384.867493   353.240021    337\n",
       "2019-12-25 23:00:00  226.460129   272.995697   249.452408    244\n",
       "2019-12-26 00:00:00  118.241920   150.293365   131.432266    160\n",
       "2019-12-26 01:00:00   78.639442   102.835701    91.236671    102\n",
       "2019-12-26 02:00:00   54.820911    79.877419    68.995316     67\n",
       "2019-12-26 03:00:00   52.524181    71.499992    63.501060     46\n",
       "2019-12-26 04:00:00   38.415901    56.120575    48.004051     40\n",
       "2019-12-26 05:00:00  106.640953   133.090790   120.781357     35\n",
       "2019-12-26 06:00:00  243.715485   298.199341   273.409637     98\n",
       "2019-12-26 07:00:00  388.739410   492.351074   446.106079    203\n",
       "2019-12-26 08:00:00  363.000061   431.073059   394.191132    324\n",
       "2019-12-26 09:00:00  372.148499   436.722687   406.354187    391\n",
       "2019-12-26 10:00:00  394.247681   452.569427   421.210327    398\n",
       "2019-12-26 11:00:00  370.028503   432.185120   404.801941    460\n",
       "2019-12-26 12:00:00  451.701202   518.508911   481.362854    511\n",
       "2019-12-26 13:00:00  483.198639   553.844604   518.722961    479\n",
       "2019-12-26 14:00:00  516.055176   628.237244   579.185181    602\n",
       "2019-12-26 15:00:00  527.705444   648.472961   585.489624    671\n",
       "2019-12-26 16:00:00  621.999817   742.630249   656.552795    648\n",
       "2019-12-26 17:00:00  558.951416   679.017456   611.504395    720\n",
       "2019-12-26 18:00:00  488.539886   619.363770   572.355164    691\n",
       "2019-12-26 19:00:00  414.641296   545.469116   490.724426    636\n",
       "2019-12-26 20:00:00  414.867310   522.178162   457.891052    523\n",
       "2019-12-26 21:00:00  349.002563   464.029694   413.849091    428\n",
       "2019-12-26 22:00:00  320.510681   402.958649   357.643616    389\n",
       "2019-12-26 23:00:00  210.251862   300.942474   264.366272    292\n",
       "2019-12-27 00:00:00  142.126068   195.164749   158.939697    193\n",
       "2019-12-27 01:00:00   92.427963   144.647034   116.905586    133\n",
       "2019-12-27 02:00:00   76.682465   114.553093    97.380501     89\n",
       "2019-12-27 03:00:00   81.646545   111.800034    95.281334     57\n",
       "2019-12-27 04:00:00   55.147423    79.786995    68.041039     78\n",
       "2019-12-27 05:00:00  103.727249   143.335373   120.285934     59\n",
       "2019-12-27 06:00:00  187.368164   311.578705   224.487976    106\n",
       "2019-12-27 07:00:00  296.063873   453.445953   355.049011    213\n",
       "2019-12-27 08:00:00  305.543365   390.865387   353.120361    338\n",
       "2019-12-27 09:00:00  282.350647   385.469391   330.511505    433\n",
       "2019-12-27 10:00:00  297.558472   391.901550   337.096130    469\n",
       "2019-12-27 11:00:00  300.983002   385.258118   332.350525    476\n",
       "2019-12-27 12:00:00  379.100281   444.974854   415.455719    435\n",
       "2019-12-27 13:00:00  397.185394   499.923187   458.897797    452\n",
       "2019-12-27 14:00:00  469.142242   567.861877   521.183533    565\n",
       "2019-12-27 15:00:00  439.928436   562.114624   497.692688    696\n",
       "2019-12-27 16:00:00  616.266113   748.506958   681.428223    753\n",
       "2019-12-27 17:00:00  533.730774   647.426453   601.664856    768\n",
       "2019-12-27 18:00:00  496.826172   605.454956   531.227234    723\n",
       "2019-12-27 19:00:00  378.789978   506.667267   435.439575    739\n",
       "2019-12-27 20:00:00  472.131317   564.479431   521.051697    611\n",
       "2019-12-27 21:00:00  431.651794   528.167358   475.305145    529\n",
       "2019-12-27 22:00:00  390.152435   489.793488   440.187592    481\n",
       "2019-12-27 23:00:00  339.841431   408.009155   374.056610    432\n",
       "2019-12-28 00:00:00  252.091858   306.386993   279.534882    343\n",
       "2019-12-28 01:00:00  192.398499   237.373383   218.318619    303\n",
       "2019-12-28 02:00:00  155.391312   203.067657   177.588089    238\n",
       "2019-12-28 03:00:00  131.740265   167.118958   152.666183    168\n",
       "2019-12-28 04:00:00   77.401459   103.937271    85.156052    157\n",
       "2019-12-28 05:00:00   81.824013   105.014633    94.871674     73\n",
       "2019-12-28 06:00:00  129.130219   159.391632   144.233154     89\n",
       "2019-12-28 07:00:00  227.114990   258.435669   242.802475    128\n",
       "2019-12-28 08:00:00  329.364655   386.500488   347.645538    205\n",
       "2019-12-28 09:00:00  399.701843   482.568390   446.276611    317\n",
       "2019-12-28 10:00:00  465.890106   541.651794   507.462463    414\n",
       "2019-12-28 11:00:00  423.281677   526.434326   484.421906    488\n",
       "2019-12-28 12:00:00  456.657104   546.053894   509.071136    461\n",
       "2019-12-28 13:00:00  472.053192   587.095154   528.442749    539\n",
       "2019-12-28 14:00:00  526.142578   641.233032   573.701721    544\n",
       "2019-12-28 15:00:00  529.291809   653.783813   601.475830    695\n",
       "2019-12-28 16:00:00  604.561768   719.545898   670.385132    622\n",
       "2019-12-28 17:00:00  593.750183   694.481812   647.214783    658\n",
       "2019-12-28 18:00:00  581.115845   702.604553   633.704102    702\n",
       "2019-12-28 19:00:00  521.421753   642.821289   574.727722    644\n",
       "2019-12-28 20:00:00  498.946472   612.301514   559.678711    606\n",
       "2019-12-28 21:00:00  496.617981   590.326355   545.122864    567\n",
       "2019-12-28 22:00:00  448.028503   561.608215   503.263947    606\n",
       "2019-12-28 23:00:00  380.518188   452.301910   409.139618    475\n",
       "2019-12-29 00:00:00  313.653656   378.803284   349.761475    399\n",
       "2019-12-29 01:00:00  225.781723   281.388702   255.212921    348\n",
       "2019-12-29 02:00:00  182.773010   224.168564   207.690277    279\n",
       "2019-12-29 03:00:00  135.481476   179.628189   153.110703    264\n",
       "2019-12-29 04:00:00   98.054901   126.494934   113.357491    221\n",
       "2019-12-29 05:00:00   69.744263   104.057892    86.005997     95\n",
       "2019-12-29 06:00:00   94.114815   124.986115   110.654221     70\n",
       "2019-12-29 07:00:00  161.975571   199.098679   183.262695     98\n",
       "2019-12-29 08:00:00  249.960602   288.608459   266.312286    157\n",
       "2019-12-29 09:00:00  324.259033   396.780914   357.214478    251\n",
       "2019-12-29 10:00:00  398.677032   487.519775   433.044586    308\n",
       "2019-12-29 11:00:00  427.967133   511.907867   458.694550    360\n",
       "2019-12-29 12:00:00  449.001892   526.566406   474.105225    461\n",
       "2019-12-29 13:00:00  458.402863   542.933105   502.767548    487\n",
       "2019-12-29 14:00:00  508.778320   587.509949   542.185181    524\n",
       "2019-12-29 15:00:00  490.421204   597.446777   534.027832    624\n",
       "2019-12-29 16:00:00  576.612488   642.805298   601.535034    612\n",
       "2019-12-29 17:00:00  540.298767   616.177856   582.534363    565\n",
       "2019-12-29 18:00:00  494.445099   600.547607   557.978882    640\n",
       "2019-12-29 19:00:00  447.373505   539.182678   502.821350    540\n",
       "2019-12-29 20:00:00  372.631714   446.759125   411.410034    436\n",
       "2019-12-29 21:00:00  331.315613   399.686737   355.974365    390\n",
       "2019-12-29 22:00:00  256.375488   319.084442   289.467651    374\n",
       "2019-12-29 23:00:00  158.332077   213.340836   188.418045    267\n",
       "2019-12-30 00:00:00  114.943336   153.879028   130.834335    182\n",
       "2019-12-30 01:00:00   71.518715   112.928673    95.848030    125\n",
       "2019-12-30 02:00:00   72.108109    97.397980    82.692284     74\n",
       "2019-12-30 03:00:00   67.986549    90.895164    79.347206     66\n",
       "2019-12-30 04:00:00   43.803242    69.949287    60.618645     63\n",
       "2019-12-30 05:00:00   95.648628   139.790375   118.276619     62\n",
       "2019-12-30 06:00:00  205.395401   282.191711   241.210602    102\n",
       "2019-12-30 07:00:00  322.215637   452.433105   395.113220    201\n",
       "2019-12-30 08:00:00  418.243652   502.149689   460.631714    418\n",
       "2019-12-30 09:00:00  390.294952   459.062073   420.528290    501\n",
       "2019-12-30 10:00:00  401.436493   467.812897   430.379120    531\n",
       "2019-12-30 11:00:00  402.342590   471.130829   427.346924    481\n",
       "2019-12-30 12:00:00  520.786743   578.845032   542.841003    558\n",
       "2019-12-30 13:00:00  542.862244   615.338562   575.010559    558\n",
       "2019-12-30 14:00:00  620.423340   725.685364   666.004822    632\n",
       "2019-12-30 15:00:00  608.844238   712.077209   666.136719    660\n",
       "2019-12-30 16:00:00  749.988953   826.740662   786.078918    862\n",
       "2019-12-30 17:00:00  699.215881   824.938171   769.568115    808\n",
       "2019-12-30 18:00:00  598.392151   732.967102   674.885132    791\n",
       "2019-12-30 19:00:00  474.417175   592.017029   523.965942    654\n",
       "2019-12-30 20:00:00  398.819519   456.135529   423.351929    487\n",
       "2019-12-30 21:00:00  333.280090   397.833130   363.601837    435\n",
       "2019-12-30 22:00:00  252.404144   318.033997   282.609711    357\n",
       "2019-12-30 23:00:00  163.982468   211.150635   190.355408    324\n",
       "2019-12-31 00:00:00  139.430527   165.567261   155.229752    237\n",
       "2019-12-31 01:00:00   89.786247   118.653595   103.180527    170\n",
       "2019-12-31 02:00:00   67.129555    95.270805    83.075569    116\n",
       "2019-12-31 03:00:00   65.702599    86.533867    75.235252     81\n",
       "2019-12-31 04:00:00   51.088810    65.580620    57.685837     66\n",
       "2019-12-31 05:00:00   95.972000   121.111137   106.453598     59\n",
       "2019-12-31 06:00:00  214.874176   295.776123   251.114532    105\n",
       "2019-12-31 07:00:00  361.004181   478.299957   410.789032    196\n",
       "2019-12-31 08:00:00  408.001801   465.988342   430.336090    330\n",
       "2019-12-31 09:00:00  388.139740   471.577118   419.174744    418\n",
       "2019-12-31 10:00:00  388.657349   457.722168   416.137054    463\n",
       "2019-12-31 11:00:00  394.808105   450.991943   421.736542    500\n",
       "2019-12-31 12:00:00  508.777100   566.741516   534.735901    556\n",
       "2019-12-31 13:00:00  517.721069   598.235107   557.690125    656\n",
       "2019-12-31 14:00:00  580.189270   673.516052   630.302673    625\n",
       "2019-12-31 15:00:00  604.505188   700.743164   661.422668    791\n",
       "2019-12-31 16:00:00  758.910278   833.884399   795.726257    802\n",
       "2019-12-31 17:00:00  739.096863   844.749756   788.702942    840\n",
       "2019-12-31 18:00:00  638.894287   765.752625   703.856262    872\n",
       "2019-12-31 19:00:00  534.957214   650.045166   590.147522    840\n",
       "2019-12-31 20:00:00  673.310303   759.357910   725.795532    980\n",
       "2019-12-31 21:00:00  526.002197   614.086670   568.259766    901\n",
       "2019-12-31 22:00:00  389.931152   457.252563   413.418854    740\n",
       "2019-12-31 23:00:00  247.327560   300.414856   273.066620    611\n",
       "2020-01-01 00:00:00  363.445648   396.971588   382.042084    746\n",
       "2020-01-01 01:00:00  206.080887   250.019379   228.404114    747\n",
       "2020-01-01 02:00:00  125.629654   163.194672   140.192780    647\n",
       "2020-01-01 03:00:00   84.509987   108.815651    96.510323    529"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推論の結果をDataFrameに整形する\n",
    "import pandas.tseries.offsets as offsets\n",
    "\n",
    "pred_hour = 1\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "for index, prediction_entry in enumerate(pred_response['predictions']):\n",
    "    pred_start_time = test_data_info[index]['pred_start_time']\n",
    "    \n",
    "    prediction_index = pd.date_range(pred_start_time, pd.Timestamp(pred_start_time) + datetime.timedelta(hours=prediction_length-1), freq=freq)\n",
    "    df_temp = pd.DataFrame(prediction_entry['quantiles'], index=prediction_index)\n",
    "    df_result = pd.concat([df_result, df_temp])\n",
    "    \n",
    "df_result = pd.merge(df_result, df_summary, how='left', left_index=True, right_index=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7681f138d0>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result.head(100).plot(y=['count', '0.5'], figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 1468\n",
      "Count max: 1148\n",
      "Count min: 35\n",
      "r2: 0.8538059825017933\n"
     ]
    }
   ],
   "source": [
    "# 精度指標としてr2乗値を計算する\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_list = []\n",
    "\n",
    "df_temp = df_result.copy()\n",
    "df_temp['error'] = df_temp['count'] - df_temp['0.5']\n",
    "r2 = r2_score(df_temp['count'], df_temp['0.5'])\n",
    "\n",
    "print('Number of data:', df_temp['count'].shape[0])\n",
    "print('Count max:', df_temp['count'].max())\n",
    "print('Count min:', df_temp['count'].min())\n",
    "print('r2:', r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SageMaker Model Monitorを設定する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker Model Monitorの設定には、  \n",
    "1. Endpointへ投入された推論データのリアルタイムキャプチャー設定\n",
    "1. トレーニングデータからのベースラインの作成\n",
    "1. モニターのスケジュール\n",
    "\n",
    "の3つのステップがあります。順に見てきましょう  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. 推論データキャプチャーの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前のステップで作成済みの推論Endpointがあるので、このEndpointを更新します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in the following for enabling data capture\n",
    "endpoint_name = 'deepar-nyctaxi-2020-10-04-09-15-18-040'\n",
    "s3_capture_upload_path = 's3://tuki-bkt-misc/model_monitor/endpoint-data-capture/' #example: s3://bucket-name/path/to/endpoint-data-capture/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------!!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EndpointName': 'deepar-nyctaxi-2020-10-04-09-15-18-040',\n",
       " 'EndpointArn': 'arn:aws:sagemaker:ap-northeast-1:896540033301:endpoint/deepar-nyctaxi-2020-10-04-09-15-18-040',\n",
       " 'EndpointConfigName': 'deepar-nyctaxi-2020-10-04-09-15-18-040-2020-10-05-00-01-47-547',\n",
       " 'ProductionVariants': [{'VariantName': 'AllTraffic',\n",
       "   'DeployedImages': [{'SpecifiedImage': '633353088612.dkr.ecr.ap-northeast-1.amazonaws.com/forecasting-deepar:latest',\n",
       "     'ResolvedImage': '633353088612.dkr.ecr.ap-northeast-1.amazonaws.com/forecasting-deepar@sha256:ca8d7816ea2a13baadbea73a3389ed016898e0d9c509340d9abcecb6ce750c2b',\n",
       "     'ResolutionTime': datetime.datetime(2020, 10, 5, 0, 2, 21, 623000, tzinfo=tzlocal())}],\n",
       "   'CurrentWeight': 1.0,\n",
       "   'DesiredWeight': 1.0,\n",
       "   'CurrentInstanceCount': 1,\n",
       "   'DesiredInstanceCount': 1}],\n",
       " 'DataCaptureConfig': {'EnableCapture': True,\n",
       "  'CaptureStatus': 'Started',\n",
       "  'CurrentSamplingPercentage': 50,\n",
       "  'DestinationS3Uri': 's3://tuki-bkt-misc/model_monitor/endpoint-data-capture/'},\n",
       " 'EndpointStatus': 'InService',\n",
       " 'CreationTime': datetime.datetime(2020, 10, 4, 9, 24, 9, 45000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2020, 10, 5, 0, 9, 34, 560000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '851377de-8dc7-4e59-8935-94b8782ba7fc',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '851377de-8dc7-4e59-8935-94b8782ba7fc',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '977',\n",
       "   'date': 'Mon, 05 Oct 2020 00:09:50 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "from sagemaker import RealTimePredictor\n",
    "from sagemaker import session\n",
    "import boto3\n",
    "sm_session = session.Session(boto3.Session())\n",
    "\n",
    "# Change parameters as you would like - adjust sampling percentage, \n",
    "#  chose to capture request or response or both.\n",
    "#  Learn more from our documentation\n",
    "data_capture_config = DataCaptureConfig(\n",
    "                        enable_capture = True,\n",
    "                        sampling_percentage=50,\n",
    "                        destination_s3_uri=s3_capture_upload_path,\n",
    "                        kms_key_id=None,\n",
    "                        capture_options=[\"REQUEST\", \"RESPONSE\"],\n",
    "                        csv_content_types=[\"text/csv\"],\n",
    "                        json_content_types=[\"application/json\"])\n",
    "\n",
    "# Now it is time to apply the new configuration and wait for it to be applied\n",
    "predictor = RealTimePredictor(endpoint=endpoint_name)\n",
    "predictor.update_data_capture_config(data_capture_config=data_capture_config)\n",
    "sm_session.wait_for_endpoint(endpoint=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. ベースラインデータの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベースラインを作成するための入力データとして、モデル構築に利用した2019年の乗車データを利用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file to s3://tuki-bkt-misc/model_monitor/deepar_baseline_input/features-2019.json\n",
      "Baseline data uri: s3://tuki-bkt-misc/model_monitor/deepar_baseline_input/features-2019.json\n",
      "Baseline results uri: s3://tuki-bkt-misc/model_monitor/deepar_baseline/\n"
     ]
    }
   ],
   "source": [
    "baseline_data_path = f's3://{bucket}/model_monitor/deepar_baseline_input/features-2019.json'\n",
    "local_data_path = 'features-2019.json'\n",
    "write_dicts_to_file(local_data_path, training_data)\n",
    "copy_to_s3(local_data_path, baseline_data_path, override=True)\n",
    "\n",
    "baseline_results_uri = f's3://{bucket}/model_monitor/deepar_baseline/'\n",
    "\n",
    "print('Baseline data uri: {}'.format(baseline_data_path))\n",
    "print('Baseline results uri: {}'.format(baseline_results_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  baseline-suggestion-job-2020-10-05-00-21-15-697\n",
      "Inputs:  [{'InputName': 'baseline_dataset_input', 'S3Input': {'S3Uri': 's3://tuki-bkt-misc/model_monitor/deepar_baseline_input/features-2019.json', 'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'monitoring_output', 'S3Output': {'S3Uri': 's3://tuki-bkt-misc/model_monitor/deepar_baseline/', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "...........................\u001b[34m2020-10-05 00:25:32,022 - __main__ - INFO - All params:{'ProcessingJobArn': 'arn:aws:sagemaker:ap-northeast-1:896540033301:processing-job/baseline-suggestion-job-2020-10-05-00-21-15-697', 'ProcessingJobName': 'baseline-suggestion-job-2020-10-05-00-21-15-697', 'Environment': {'dataset_format': '{\"json\": {\"lines\": false}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}, 'AppSpecification': {'ImageUri': '574779866223.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-model-monitor-analyzer', 'ContainerEntrypoint': None, 'ContainerArguments': None}, 'ProcessingInputs': [{'InputName': 'baseline_dataset_input', 'S3Input': {'LocalPath': '/opt/ml/processing/input/baseline_dataset_input', 'S3Uri': 's3://tuki-bkt-misc/model_monitor/deepar_baseline_input/features-2019.json', 'S3DataDistributionType': 'FullyReplicated', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3CompressionType': 'None', 'S3DownloadMode': 'StartOfJob'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'monitoring_output', 'S3Output': {'LocalPath': '/opt/ml/processing/output', 'S3Uri': 's3://tuki-bkt-misc/model_monitor/deepar_baseline/', 'S3UploadMode': 'EndOfJob'}}], 'KmsKeyId': None}, 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge', 'VolumeSizeInGB': 20, 'VolumeKmsKeyId': None}}, 'RoleArn': 'arn:aws:iam::896540033301:role/tuki-sagemaker-general', 'StoppingCondition': {'MaxRuntimeInSeconds': 3600}}\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,022 - __main__ - INFO - Current Environment:{'dataset_format': '{\"json\": {\"lines\": false}}', 'dataset_source': '/opt/ml/processing/input/baseline_dataset_input', 'output_path': '/opt/ml/processing/output', 'publish_cloudwatch_metrics': 'Disabled'}\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,022 - DefaultDataAnalyzer - INFO - Performing analysis with input: {\"dataset_source\": \"/opt/ml/processing/input/baseline_dataset_input\", \"dataset_format\": {\"json\": {\"lines\": false}}, \"record_preprocessor_script\": null, \"post_analytics_processor_script\": null, \"baseline_constraints\": null, \"baseline_statistics\": null, \"output_path\": \"/opt/ml/processing/output\", \"start_time\": null, \"end_time\": null, \"cloudwatch_metrics_directory\": \"/opt/ml/output/metrics/cloudwatch\", \"publish_cloudwatch_metrics\": \"Disabled\", \"sagemaker_endpoint_name\": null, \"sagemaker_monitoring_schedule_name\": null, \"output_message_file\": \"/opt/ml/output/message\"}\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,022 - DefaultDataAnalyzer - INFO - Bootstrapping yarn\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,022 - bootstrap - INFO - Copy aws jars\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,081 - bootstrap - INFO - Copy cluster config\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,081 - bootstrap - INFO - Write runtime cluster config\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,082 - bootstrap - INFO - Resource Config is: {'current_host': 'algo-1', 'hosts': ['algo-1']}\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,089 - bootstrap - INFO - Finished Yarn configuration files setup.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,089 - bootstrap - INFO - Starting spark process for master node algo-1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,089 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs namenode -format -force\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.0.0/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,541 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.127.160\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.0.0\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.0.0/etc/hadoop:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/junit-4.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/hadoop-aws-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.199.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-kms-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okio-1.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-annotations-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/hadoop-auth-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/xz-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-net-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-tests.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-prefix-tree-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/joni-2.1.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-math-2.2.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-el-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-client-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/commons-csv-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-server-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jamon-runtime-2.4.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-common-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-procedure-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-protocol-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/hbase-annotations-1.2.6.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-registry-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-router-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/had\u001b[0m\n",
      "\u001b[34moop/yarn/hadoop-yarn-server-web-proxy-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-client-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-api-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0.jar:/usr/hadoop-3.0.0/share/hadoop/yarn/hadoop-yarn-common-3.0.0.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533; compiled by 'andrew' on 2017-12-08T19:16Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_252\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,548 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:32,552 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-934322e4-537e-45e7-836d-711728f1b892\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,029 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,041 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,042 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,045 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,050 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,050 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,050 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,050 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,084 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,094 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,094 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,102 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,102 INFO blockmanagement.BlockManager: The block deletion will start around 2020 Oct 05 00:25:33\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,104 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,104 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,105 INFO util.GSet: 2.0% max memory 3.1 GB = 64.3 MB\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,105 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,184 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,188 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,217 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,217 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,217 INFO util.GSet: 1.0% max memory 3.1 GB = 32.2 MB\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,217 INFO util.GSet: capacity      = 2^22 = 4194304 entries\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,219 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,219 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,219 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,219 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,223 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,227 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,227 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,227 INFO util.GSet: 0.25% max memory 3.1 GB = 8.0 MB\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,227 INFO util.GSet: capacity      = 2^20 = 1048576 entries\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,233 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,233 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,233 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,237 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,237 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,238 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,238 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,239 INFO util.GSet: 0.029999999329447746% max memory 3.1 GB = 988.0 KB\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,239 INFO util.GSet: capacity      = 2^17 = 131072 entries\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,260 INFO namenode.FSImage: Allocated new BlockPoolId: BP-2067939031-10.0.127.160-1601857533254\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,271 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,278 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,353 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 389 bytes saved in 0 seconds.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,363 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,367 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.127.160\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:33,377 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:35,422 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start namenode, return code 1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:35,422 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:37,476 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/hdfs --daemon start datanode, return code 1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:37,476 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:39,549 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start resourcemanager, return code 1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:39,549 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:41,648 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start nodemanager, return code 1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:41,648 - bootstrap - INFO - Running command: /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:43,736 - bootstrap - INFO - Failed to run /usr/hadoop-3.0.0/bin/yarn --daemon start proxyserver, return code 1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:43,736 - DefaultDataAnalyzer - INFO - Total number of hosts in the cluster: 1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:53,747 - DefaultDataAnalyzer - INFO - Running command: bin/spark-submit --master yarn --deploy-mode client --conf spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider --conf spark.serializer=org.apache.spark.serializer.KryoSerializer /opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:54 WARN  NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:54 INFO  Main:28 - Start analyzing with args: --analytics_input /tmp/spark_job_config.json\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:54 INFO  Main:31 - Analytics input path: DataAnalyzerParams(/tmp/spark_job_config.json)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:54 INFO  FileUtil:66 - Read file from path /tmp/spark_job_config.json.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  DataAnalyzer:30 - Analytics input: AnalyticsInput(/opt/ml/processing/input/baseline_dataset_input,DataSetFormat(None,Some(JSON(None)),None),None,None,None,None,/opt/ml/processing/output,None,None,/opt/ml/output/metrics/cloudwatch,Some(Disabled),None,None,/opt/ml/output/message)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SparkContext:54 - Running Spark version 2.3.1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SparkContext:54 - Submitted application: SageMakerDataAnalyzer\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 45675.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SparkEnv:54 - Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SparkEnv:54 - Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-479c43f7-b796-476f-9302-36f8cf528c3e\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  MemoryStore:54 - MemoryStore started with capacity 1458.6 MB\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SparkEnv:54 - Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:55 INFO  SparkContext:54 - Added JAR file:/opt/amazon/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar at spark://10.0.127.160:45675/jars/sagemaker-data-analyzer-1.0-jar-with-dependencies.jar with timestamp 1601857555756\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:56 INFO  RMProxy:133 - Connecting to ResourceManager at /10.0.127.160:8032\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:56 INFO  Client:54 - Requesting a new application from cluster with 1 NodeManagers\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:56 INFO  Configuration:2636 - resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:56 INFO  ResourceUtils:427 - Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:56 INFO  Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (15746 MB per container)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:56 INFO  Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:56 INFO  Client:54 - Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:56 INFO  Client:54 - Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:56 INFO  Client:54 - Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:57 WARN  Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:25:59 INFO  Client:54 - Uploading resource file:/tmp/spark-186063f1-557d-4cff-9918-64cc9ab6e4fa/__spark_libs__2909337137559799502.zip -> hdfs://10.0.127.160/user/root/.sparkStaging/application_1601857538801_0001/__spark_libs__2909337137559799502.zip\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:00 INFO  Client:54 - Uploading resource file:/tmp/spark-186063f1-557d-4cff-9918-64cc9ab6e4fa/__spark_conf__7939231212682522080.zip -> hdfs://10.0.127.160/user/root/.sparkStaging/application_1601857538801_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:00 INFO  SecurityManager:54 - Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:00 INFO  SecurityManager:54 - Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:00 INFO  SecurityManager:54 - Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:00 INFO  SecurityManager:54 - Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:00 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:00 INFO  Client:54 - Submitting application application_1601857538801_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:00 INFO  YarnClientImpl:310 - Submitted application application_1601857538801_0001\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:00 INFO  SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1601857538801_0001 and attemptId None\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:01 INFO  Client:54 - Application report for application_1601857538801_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:01 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: AM container is launched, waiting for AM container to Register with RM\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1601857560798\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1601857538801_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:02 INFO  Client:54 - Application report for application_1601857538801_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:03 INFO  Client:54 - Application report for application_1601857538801_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:04 INFO  Client:54 - Application report for application_1601857538801_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  YarnClientSchedulerBackend:54 - Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1601857538801_0001), /proxy/application_1601857538801_0001\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  Client:54 - Application report for application_1601857538801_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  Client:54 - \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.127.160\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: 0\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1601857560798\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1601857538801_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  YarnClientSchedulerBackend:54 - Application application_1601857538801_0001 has started running.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44955.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  NettyBlockTransferService:54 - Server created on 10.0.127.160:44955\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.127.160, 44955, None)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.127.160:44955 with 1458.6 MB RAM, BlockManagerId(driver, 10.0.127.160, 44955, None)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.127.160, 44955, None)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.0.127.160, 44955, None)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:05 INFO  log:192 - Logging initialized @12127ms\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:08 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.127.160:46360) with ID 1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:08 INFO  BlockManagerMasterEndpoint:54 - Registering block manager algo-1:38453 with 5.8 GB RAM, BlockManagerId(1, algo-1, 38453, None)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:25 INFO  YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:25 WARN  SparkContext:66 - Spark is not running in local mode, therefore the checkpoint directory must not be on the local filesystem. Directory '/tmp' appears to be on the local filesystem.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:26 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/usr/spark-2.3.1/spark-warehouse').\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:26 INFO  SharedState:54 - Warehouse path is 'file:/usr/spark-2.3.1/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:26 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:26 INFO  DatasetReader:90 - Files to process:List(file:///opt/ml/processing/input/baseline_dataset_input/features-2019.json)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  CodeGenerator:54 - Code generated in 162.53721 ms\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 429.4 KB, free 1458.2 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.127.160:44955 (size: 38.3 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  SparkContext:54 - Created broadcast 0 from json at DatasetReader.scala:54\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  SparkContext:54 - Starting job: json at DatasetReader.scala:54\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  DAGScheduler:54 - Got job 0 (json at DatasetReader.scala:54) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (json at DatasetReader.scala:54)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[5] at json at DatasetReader.scala:54), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.4 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.1 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.127.160:44955 (size: 5.1 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at json at DatasetReader.scala:54) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  YarnScheduler:54 - Adding task set 0.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:27 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8349 bytes)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:28 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on algo-1:38453 (size: 5.1 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on algo-1:38453 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 1705 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  YarnScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  DAGScheduler:54 - ResultStage 0 (json at DatasetReader.scala:54) finished in 1.766 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  DAGScheduler:54 - Job 0 finished: json at DatasetReader.scala:54, took 1.803304 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  FileSourceStrategy:54 - Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  FileSourceStrategy:54 - Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  FileSourceStrategy:54 - Output Data Schema: struct<start: string, target: array<bigint>>\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  FileSourceScanExec:54 - Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 429.4 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 38.3 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.0.127.160:44955 (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  SparkContext:54 - Created broadcast 2 from cache at DataAnalyzer.scala:90\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  CodeGenerator:54 - Code generated in 30.645063 ms\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  CodeGenerator:54 - Code generated in 27.143599 ms\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  SparkContext:54 - Starting job: head at DataAnalyzer.scala:93\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  DAGScheduler:54 - Got job 1 (head at DataAnalyzer.scala:93) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (head at DataAnalyzer.scala:93)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  DAGScheduler:54 - Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  DAGScheduler:54 - Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[14] at head at DataAnalyzer.scala:93), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 18.9 KB, free 1457.7 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 14\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 19\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 20\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 24\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 7\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 9\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 5\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 6\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 22\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 2\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 27\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  ContextCleaner:54 - Cleaned accumulator 0\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.8 KB, free 1457.6 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 10.0.127.160:44955 (size: 8.8 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[14] at head at DataAnalyzer.scala:93) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  YarnScheduler:54 - Adding task set 1.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8349 bytes)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on 10.0.127.160:44955 in memory (size: 38.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:29 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on algo-1:38453 in memory (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 3\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 13\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 16\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 11\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 17\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 26\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 1\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 15\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 8\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 23\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 29\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 28\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 10\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 25\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 4\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 12\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on 10.0.127.160:44955 in memory (size: 5.1 KB, free: 1458.6 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on algo-1:38453 in memory (size: 5.1 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 21\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  ContextCleaner:54 - Cleaned accumulator 18\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on algo-1:38453 (size: 8.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on algo-1:38453 (size: 38.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  BlockManagerInfo:54 - Added rdd_8_0 in memory on algo-1:38453 (size: 46.7 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 335 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  YarnScheduler:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  DAGScheduler:54 - ResultStage 1 (head at DataAnalyzer.scala:93) finished in 0.425 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  DAGScheduler:54 - Job 1 finished: head at DataAnalyzer.scala:93, took 0.433475 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  CodeGenerator:54 - Code generated in 14.233543 ms\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  SparkContext:54 - Starting job: collect at AnalysisRunner.scala:313\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  DAGScheduler:54 - Registering RDD 19 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  DAGScheduler:54 - Got job 2 (collect at AnalysisRunner.scala:313) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (collect at AnalysisRunner.scala:313)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 36.8 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 15.4 KB, free 1458.1 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 10.0.127.160:44955 (size: 15.4 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[19] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  YarnScheduler:54 - Adding task set 2.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8338 bytes)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:30 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on algo-1:38453 (size: 15.4 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 558 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  YarnScheduler:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - ShuffleMapStage 2 (collect at AnalysisRunner.scala:313) finished in 0.578 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[22] at collect at AnalysisRunner.scala:313), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 42.7 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 17.0 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on 10.0.127.160:44955 (size: 17.0 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[22] at collect at AnalysisRunner.scala:313) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  YarnScheduler:54 - Adding task set 3.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on algo-1:38453 (size: 17.0 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 10.0.127.160:46360\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 217 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  YarnScheduler:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - ResultStage 3 (collect at AnalysisRunner.scala:313) finished in 0.231 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - Job 2 finished: collect at AnalysisRunner.scala:313, took 0.826708 s\u001b[0m\n",
      "\u001b[34mUnable to map type ArrayType(LongType,true)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  SparkContext:54 - Starting job: countByKey at ColumnProfiler.scala:566\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - Registering RDD 29 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - Got job 3 (countByKey at ColumnProfiler.scala:566) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (countByKey at ColumnProfiler.scala:566)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[29] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 18.2 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 9.3 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on 10.0.127.160:44955 (size: 9.3 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[29] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  YarnScheduler:54 - Adding task set 4.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8338 bytes)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:31 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on algo-1:38453 (size: 9.3 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 904 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  YarnScheduler:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - ShuffleMapStage 4 (countByKey at ColumnProfiler.scala:566) finished in 0.922 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Submitting ResultStage 5 (ShuffledRDD[30] at countByKey at ColumnProfiler.scala:566), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 3.2 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 1919.0 B, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on 10.0.127.160:44955 (size: 1919.0 B, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (ShuffledRDD[30] at countByKey at ColumnProfiler.scala:566) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  YarnScheduler:54 - Adding task set 5.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, algo-1, executor 1, partition 0, NODE_LOCAL, 7660 bytes)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on algo-1:38453 (size: 1919.0 B, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 1 to 10.0.127.160:46360\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 47 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  YarnScheduler:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - ResultStage 5 (countByKey at ColumnProfiler.scala:566) finished in 0.059 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Job 3 finished: countByKey at ColumnProfiler.scala:566, took 0.996924 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  ConstraintGenerator:46 - Generating Constraints:\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  ConstraintGenerator:51 - Constraints: {\n",
      "  \"version\" : 0.0,\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"start\",\n",
      "    \"inferred_type\" : \"String\",\n",
      "    \"completeness\" : 1.0,\n",
      "    \"string_constraints\" : {\n",
      "      \"domains\" : [ \"2019-01-01 00:00:00\" ]\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"target\",\n",
      "    \"inferred_type\" : \"Unknown\",\n",
      "    \"completeness\" : 1.0\n",
      "  } ],\n",
      "  \"monitoring_config\" : {\n",
      "    \"evaluate_constraints\" : \"Enabled\",\n",
      "    \"emit_metrics\" : \"Enabled\",\n",
      "    \"datatype_check_threshold\" : 1.0,\n",
      "    \"domain_content_threshold\" : 1.0,\n",
      "    \"distribution_constraints\" : {\n",
      "      \"perform_comparison\" : \"Enabled\",\n",
      "      \"comparison_threshold\" : 0.1,\n",
      "      \"comparison_method\" : \"Robust\"\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  FileUtil:29 - Write to file constraints.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  StatsGenerator:67 - Generating Stats:\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  CodeGenerator:54 - Code generated in 15.718317 ms\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  CodeGenerator:54 - Code generated in 12.985774 ms\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  SparkContext:54 - Starting job: count at StatsGenerator.scala:69\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Registering RDD 35 (count at StatsGenerator.scala:69)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Got job 4 (count at StatsGenerator.scala:69) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (count at StatsGenerator.scala:69)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 6)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 6)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 6 (MapPartitionsRDD[35] at count at StatsGenerator.scala:69), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 18.5 KB, free 1458.0 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.9 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on 10.0.127.160:44955 (size: 8.9 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  SparkContext:54 - Created broadcast 8 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[35] at count at StatsGenerator.scala:69) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  YarnScheduler:54 - Adding task set 6.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, algo-1, executor 1, partition 0, PROCESS_LOCAL, 8338 bytes)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on algo-1:38453 (size: 8.9 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 100 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  YarnScheduler:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - ShuffleMapStage 6 (count at StatsGenerator.scala:69) finished in 0.110 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - looking for newly runnable stages\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - running: Set()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - waiting: Set(ResultStage 7)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - failed: Set()\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Submitting ResultStage 7 (MapPartitionsRDD[38] at count at StatsGenerator.scala:69), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 7.4 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.8 KB, free 1457.9 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on 10.0.127.160:44955 (size: 3.8 KB, free: 1458.5 MB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1039\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at count at StatsGenerator.scala:69) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  YarnScheduler:54 - Adding task set 7.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, algo-1, executor 1, partition 0, NODE_LOCAL, 7765 bytes)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on algo-1:38453 (size: 3.8 KB, free: 5.8 GB)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:32 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 2 to 10.0.127.160:46360\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 47 ms on algo-1 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  YarnScheduler:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  DAGScheduler:54 - ResultStage 7 (count at StatsGenerator.scala:69) finished in 0.063 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  DAGScheduler:54 - Job 4 finished: count at StatsGenerator.scala:69, took 0.179371 s\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  StatsGenerator:72 - Stats: {\n",
      "  \"version\" : 0.0,\n",
      "  \"dataset\" : {\n",
      "    \"item_count\" : 1\n",
      "  },\n",
      "  \"features\" : [ {\n",
      "    \"name\" : \"start\",\n",
      "    \"inferred_type\" : \"String\",\n",
      "    \"string_statistics\" : {\n",
      "      \"common\" : {\n",
      "        \"num_present\" : 1,\n",
      "        \"num_missing\" : 0\n",
      "      },\n",
      "      \"distinct_count\" : 1.0,\n",
      "      \"distribution\" : {\n",
      "        \"categorical\" : {\n",
      "          \"buckets\" : [ {\n",
      "            \"value\" : \"2019-01-01 00:00:00\",\n",
      "            \"count\" : 1\n",
      "          } ]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }, {\n",
      "    \"name\" : \"target\",\n",
      "    \"inferred_type\" : \"Unknown\"\n",
      "  } ]\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  FileUtil:29 - Write to file statistics.json at path /opt/ml/processing/output.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  YarnClientSchedulerBackend:54 - Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  YarnClientSchedulerBackend:54 - Shutting down all executors\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices\u001b[0m\n",
      "\u001b[34m(serviceOption=None,\n",
      " services=List(),\n",
      " started=false)\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  YarnClientSchedulerBackend:54 - Stopped\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  MemoryStore:54 - MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  BlockManager:54 - BlockManager stopped\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  SparkContext:54 - Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  Main:47 - Completed: Job completed successfully with no violations.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  Main:115 - Write to file /opt/ml/output/message.\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  ShutdownHookManager:54 - Shutdown hook called\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-198dd175-e93b-4fdf-aeb7-6f826d26b347\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-186063f1-557d-4cff-9918-64cc9ab6e4fa\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33,633 - DefaultDataAnalyzer - INFO - Completed spark-submit with return code : 0\u001b[0m\n",
      "\u001b[34m2020-10-05 00:26:33,633 - DefaultDataAnalyzer - INFO - Spark job completed.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.processing.ProcessingJob at 0x7f7681c76b70>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_data_path,\n",
    "    dataset_format=DatasetFormat.json(lines=False),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成されたconstraintとstatisticsを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.distribution.kll.buckets</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.c</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "      <td>Integral</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>633.360046</td>\n",
       "      <td>5.548234e+06</td>\n",
       "      <td>368.997985</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1841.00000</td>\n",
       "      <td>[{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[564.0, 580.0, 610.0, 724.0, 710.0, 817.0, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_hh</td>\n",
       "      <td>Integral</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>1.007400e+05</td>\n",
       "      <td>6.922187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 2.3, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count_m1h</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>633.403995</td>\n",
       "      <td>5.548619e+06</td>\n",
       "      <td>369.018246</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1841.00000</td>\n",
       "      <td>[{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[510.0, 564.0, 580.0, 610.0, 724.0, 710.0, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count_m2h</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>633.468265</td>\n",
       "      <td>5.549182e+06</td>\n",
       "      <td>369.085826</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1841.00000</td>\n",
       "      <td>[{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[347.0, 510.0, 564.0, 580.0, 610.0, 724.0, 71...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count_m3h</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>633.547374</td>\n",
       "      <td>5.549875e+06</td>\n",
       "      <td>369.217405</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1841.00000</td>\n",
       "      <td>[{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[200.0, 347.0, 510.0, 564.0, 580.0, 610.0, 72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>count_m4h</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>633.619292</td>\n",
       "      <td>5.550505e+06</td>\n",
       "      <td>369.346217</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1841.00000</td>\n",
       "      <td>[{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[124.0, 200.0, 347.0, 510.0, 564.0, 580.0, 61...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_m24h</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>634.476142</td>\n",
       "      <td>5.558011e+06</td>\n",
       "      <td>369.862759</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1841.00000</td>\n",
       "      <td>[{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[669.0, 587.0, 565.0, 582.0, 656.0, 826.0, 94...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_m1w</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>640.216096</td>\n",
       "      <td>5.608293e+06</td>\n",
       "      <td>370.514116</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1841.00000</td>\n",
       "      <td>[{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[561.0, 563.0, 607.0, 707.0, 683.0, 761.0, 81...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekday</td>\n",
       "      <td>Integral</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>2.997260</td>\n",
       "      <td>2.625600e+04</td>\n",
       "      <td>1.997942</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.6, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean_by_hh</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>8760</td>\n",
       "      <td>0</td>\n",
       "      <td>692.773220</td>\n",
       "      <td>6.068693e+06</td>\n",
       "      <td>317.796370</td>\n",
       "      <td>141.789474</td>\n",
       "      <td>1172.70614</td>\n",
       "      <td>[{'lower_bound': 141.78947368421052, 'upper_bo...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[832.8092105263158, 822.2379385964912, 826.21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name inferred_type  numerical_statistics.common.num_present  \\\n",
       "0           y      Integral                                     8760   \n",
       "1     time_hh      Integral                                     8760   \n",
       "2   count_m1h    Fractional                                     8760   \n",
       "3   count_m2h    Fractional                                     8760   \n",
       "4   count_m3h    Fractional                                     8760   \n",
       "5   count_m4h    Fractional                                     8760   \n",
       "6  count_m24h    Fractional                                     8760   \n",
       "7   count_m1w    Fractional                                     8760   \n",
       "8     weekday      Integral                                     8760   \n",
       "9  mean_by_hh    Fractional                                     8760   \n",
       "\n",
       "   numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                        0                 633.360046   \n",
       "1                                        0                  11.500000   \n",
       "2                                        0                 633.403995   \n",
       "3                                        0                 633.468265   \n",
       "4                                        0                 633.547374   \n",
       "5                                        0                 633.619292   \n",
       "6                                        0                 634.476142   \n",
       "7                                        0                 640.216096   \n",
       "8                                        0                   2.997260   \n",
       "9                                        0                 692.773220   \n",
       "\n",
       "   numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0              5.548234e+06                    368.997985   \n",
       "1              1.007400e+05                      6.922187   \n",
       "2              5.548619e+06                    369.018246   \n",
       "3              5.549182e+06                    369.085826   \n",
       "4              5.549875e+06                    369.217405   \n",
       "5              5.550505e+06                    369.346217   \n",
       "6              5.558011e+06                    369.862759   \n",
       "7              5.608293e+06                    370.514116   \n",
       "8              2.625600e+04                      1.997942   \n",
       "9              6.068693e+06                    317.796370   \n",
       "\n",
       "   numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                  5.000000                1841.00000   \n",
       "1                  0.000000                  23.00000   \n",
       "2                  5.000000                1841.00000   \n",
       "3                  5.000000                1841.00000   \n",
       "4                  5.000000                1841.00000   \n",
       "5                  5.000000                1841.00000   \n",
       "6                  5.000000                1841.00000   \n",
       "7                  5.000000                1841.00000   \n",
       "8                  0.000000                   6.00000   \n",
       "9                141.789474                1172.70614   \n",
       "\n",
       "       numerical_statistics.distribution.kll.buckets  \\\n",
       "0  [{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...   \n",
       "1  [{'lower_bound': 0.0, 'upper_bound': 2.3, 'cou...   \n",
       "2  [{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...   \n",
       "3  [{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...   \n",
       "4  [{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...   \n",
       "5  [{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...   \n",
       "6  [{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...   \n",
       "7  [{'lower_bound': 5.0, 'upper_bound': 188.6, 'c...   \n",
       "8  [{'lower_bound': 0.0, 'upper_bound': 0.6, 'cou...   \n",
       "9  [{'lower_bound': 141.78947368421052, 'upper_bo...   \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.c  \\\n",
       "0                                               0.64           \n",
       "1                                               0.64           \n",
       "2                                               0.64           \n",
       "3                                               0.64           \n",
       "4                                               0.64           \n",
       "5                                               0.64           \n",
       "6                                               0.64           \n",
       "7                                               0.64           \n",
       "8                                               0.64           \n",
       "9                                               0.64           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.k  \\\n",
       "0                                             2048.0           \n",
       "1                                             2048.0           \n",
       "2                                             2048.0           \n",
       "3                                             2048.0           \n",
       "4                                             2048.0           \n",
       "5                                             2048.0           \n",
       "6                                             2048.0           \n",
       "7                                             2048.0           \n",
       "8                                             2048.0           \n",
       "9                                             2048.0           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.data  \n",
       "0  [[564.0, 580.0, 610.0, 724.0, 710.0, 817.0, 81...  \n",
       "1  [[10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17...  \n",
       "2  [[510.0, 564.0, 580.0, 610.0, 724.0, 710.0, 81...  \n",
       "3  [[347.0, 510.0, 564.0, 580.0, 610.0, 724.0, 71...  \n",
       "4  [[200.0, 347.0, 510.0, 564.0, 580.0, 610.0, 72...  \n",
       "5  [[124.0, 200.0, 347.0, 510.0, 564.0, 580.0, 61...  \n",
       "6  [[669.0, 587.0, 565.0, 582.0, 656.0, 826.0, 94...  \n",
       "7  [[561.0, 563.0, 607.0, 707.0, 683.0, 761.0, 81...  \n",
       "8  [[6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0,...  \n",
       "9  [[832.8092105263158, 822.2379385964912, 826.21...  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "baseline_job = my_default_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(baseline_job.baseline_statistics().body_dict[\"features\"])\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower_bound': 5.0, 'upper_bound': 188.6, 'count': 1538.0}\n",
      "{'lower_bound': 188.6, 'upper_bound': 372.2, 'count': 937.0}\n",
      "{'lower_bound': 372.2, 'upper_bound': 555.8, 'count': 1019.0}\n",
      "{'lower_bound': 555.8, 'upper_bound': 739.4, 'count': 1789.0}\n",
      "{'lower_bound': 739.4, 'upper_bound': 923.0, 'count': 1560.0}\n",
      "{'lower_bound': 923.0, 'upper_bound': 1106.6, 'count': 943.0}\n",
      "{'lower_bound': 1106.6, 'upper_bound': 1290.2, 'count': 602.0}\n",
      "{'lower_bound': 1290.2, 'upper_bound': 1473.8, 'count': 286.0}\n",
      "{'lower_bound': 1473.8, 'upper_bound': 1657.4, 'count': 74.0}\n",
      "{'lower_bound': 1657.4, 'upper_bound': 1841.0, 'count': 12.0}\n"
     ]
    }
   ],
   "source": [
    "kll_buckets = schema_df[schema_df.name == 'count_m1h']['numerical_statistics.distribution.kll.buckets'].tolist()[0]\n",
    "for bucket in kll_buckets:\n",
    "    print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>time_hh</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count_m1h</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count_m2h</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>count_m3h</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>count_m4h</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>count_m24h</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>count_m1w</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekday</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mean_by_hh</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name inferred_type  completeness  num_constraints.is_non_negative\n",
       "0           y      Integral           1.0                             True\n",
       "1     time_hh      Integral           1.0                             True\n",
       "2   count_m1h    Fractional           1.0                             True\n",
       "3   count_m2h    Fractional           1.0                             True\n",
       "4   count_m3h    Fractional           1.0                             True\n",
       "5   count_m4h    Fractional           1.0                             True\n",
       "6  count_m24h    Fractional           1.0                             True\n",
       "7   count_m1w    Fractional           1.0                             True\n",
       "8     weekday      Integral           1.0                             True\n",
       "9  mean_by_hh    Fractional           1.0                             True"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constraints_df = pd.json_normalize(baseline_job.suggested_constraints().body_dict[\"features\"])\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. モニタースケジュールの有効化\n",
    "ここまでのステップで、推論Endpointに対してデータキャプチャーを設定し、トレーニングデータからベースラインを作成しました。この2つの設定を元に、モニタリングのスケジュールを設定することで、データドリフトの監視ができるようになります。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スケジュールは、ここではModel Monitorが提供する`CronExpressionGenerator`というライブラリーを利用して、hourlyの設定を行っています。cron形式で与えることも可能です。実際には評価したいインターバルで設定してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n",
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Monitoring Schedule with name: DEMO-XGBoost-monitor\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "from time import gmtime, strftime\n",
    "\n",
    "mon_schedule_name = 'DEMO-XGBoost-monitor'\n",
    "s3_report_path = 's3://tuki-bkt-misc/model_monitor/monitoring_report/'\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    statistics=my_default_monitor.baseline_statistics(),\n",
    "    constraints=my_default_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schedule status: Pending\n"
     ]
    }
   ],
   "source": [
    "desc_schedule_result = my_default_monitor.describe_schedule()\n",
    "print('Schedule status: {}'.format(desc_schedule_result['MonitoringScheduleStatus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleSummaries': [],\n",
       " 'ResponseMetadata': {'RequestId': '2d742ae9-7d97-4cd1-a45e-c7e9542be0c6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '2d742ae9-7d97-4cd1-a45e-c7e9542be0c6',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '34',\n",
       "   'date': 'Sun, 13 Sep 2020 20:34:44 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.list_monitoring_schedules(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作成されたスケジュールのdescribe結果を見ると、利用するベースラインのS3Uriやスケジュール間隔などがわかります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MonitoringScheduleArn': 'arn:aws:sagemaker:ap-northeast-1:896540033301:monitoring-schedule/demo-xgboost-monitor',\n",
       " 'MonitoringScheduleName': 'DEMO-XGBoost-monitor',\n",
       " 'MonitoringScheduleStatus': 'Scheduled',\n",
       " 'CreationTime': datetime.datetime(2020, 9, 13, 21, 7, 30, 139000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2020, 9, 13, 21, 17, 4, 755000, tzinfo=tzlocal()),\n",
       " 'MonitoringScheduleConfig': {'ScheduleConfig': {'ScheduleExpression': 'cron(0 * ? * * *)'},\n",
       "  'MonitoringJobDefinition': {'BaselineConfig': {'ConstraintsResource': {'S3Uri': 's3://tuki-bkt-misc/model_monitor/baseline/constraints.json'},\n",
       "    'StatisticsResource': {'S3Uri': 's3://tuki-bkt-misc/model_monitor/baseline/statistics.json'}},\n",
       "   'MonitoringInputs': [{'EndpointInput': {'EndpointName': 'DEMO-XGBoostEndpoint-2020-09-13-18-37-31',\n",
       "      'LocalPath': '/opt/ml/processing/input/endpoint',\n",
       "      'S3InputMode': 'File',\n",
       "      'S3DataDistributionType': 'FullyReplicated'}}],\n",
       "   'MonitoringOutputConfig': {'MonitoringOutputs': [{'S3Output': {'S3Uri': 's3://tuki-bkt-misc/model_monitor/monitoring_report/',\n",
       "       'LocalPath': '/opt/ml/processing/output',\n",
       "       'S3UploadMode': 'Continuous'}}]},\n",
       "   'MonitoringResources': {'ClusterConfig': {'InstanceCount': 1,\n",
       "     'InstanceType': 'ml.m5.xlarge',\n",
       "     'VolumeSizeInGB': 20}},\n",
       "   'MonitoringAppSpecification': {'ImageUri': '574779866223.dkr.ecr.ap-northeast-1.amazonaws.com/sagemaker-model-monitor-analyzer'},\n",
       "   'StoppingCondition': {'MaxRuntimeInSeconds': 3600},\n",
       "   'Environment': {'publish_cloudwatch_metrics': 'Enabled'},\n",
       "   'RoleArn': 'arn:aws:iam::896540033301:role/tuki-sagemaker-general'}},\n",
       " 'EndpointName': 'DEMO-XGBoostEndpoint-2020-09-13-18-37-31',\n",
       " 'ResponseMetadata': {'RequestId': '4ae8fafc-f2a5-434a-b44e-d98e34907341',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4ae8fafc-f2a5-434a-b44e-d98e34907341',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '1459',\n",
       "   'date': 'Sun, 13 Sep 2020 21:17:26 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_default_monitor.describe_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. モデルを運用する\n",
    "ここまでのステップが完了すると、推論Endpointを運用していけばデータがキャプチャーされ、ベースラインと比較したデータドリフトの評価が行われます。今回のblogでは、1月、2月、3月と順に推論データを投入して、データドリフトが顕在化するかどうかを見ていきましょう。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、2020年1月から2月のデータを元に推論を実行します。ここでは2ヶ月分のデータを一括して推論していますが、実際のモデル運用では時間経過に伴って順次推論のリクエストが投入されていると考えてください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_202001 = df_features[(df_features.index >= '2020-01-01') & (df_features.index < '2020-03-01')].copy()\n",
    "df_202001['pred'] = exec_prediction(df_202001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論の実行が終わったら、データキャプチャーの出力先として設定したS3のパスをチェックしてください。推論Endpointの名前をprefixとしてデータが出力されているはずです。  \n",
    "![Model Monitorの出力先として設定したS3パス](image/screenshot1_s3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Monitorによるスケジュール実行が完了すると、出力先として指定したS3パスにレポートが出力されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1月、2月分の推論データに対するModel Monitorのレポートはこのようになりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、3，4月のデータによる推論を実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_202003 = df_features[(df_features.index >= '2020-03-01') & (df_features.index < '2020-05-01')].copy()\n",
    "df_202003['pred'] = exec_prediction(df_202003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1月、2月分の推論データに対するModel Monitorのレポートはこのようになりました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後に、5,6月のデータによる推論を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_202005 = df_features[(df_features.index >= '2020-05-01') & (df_features.index < '2020-07-01')].copy()\n",
    "df_202005['pred'] = exec_prediction(df_202005)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
